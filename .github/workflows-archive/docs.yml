name: Documentation

on:
  push:
    branches: [main, develop]
    paths:
      - 'docs/**'
      - 'nlsq/**/*.py'
      - 'scripts/doc_coverage_analysis.py'
      - 'scripts/ast_analysis.py'
      - '**.md'
      - 'pyproject.toml'
      - '.github/workflows/docs.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'docs/**'
      - 'nlsq/**/*.py'
      - 'scripts/doc_coverage_analysis.py'
      - 'scripts/ast_analysis.py'
      - '**.md'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.12"

jobs:
  # Build Sphinx Documentation (Build Once, Use Everywhere)
  build-sphinx:
    name: Build Sphinx Documentation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Needed for setuptools-scm

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-dev.txt
            pyproject.toml

      - name: Cache Sphinx build
        uses: actions/cache@v4
        with:
          path: docs/_build
          key: sphinx-${{ hashFiles('docs/**', 'nlsq/**/*.py') }}
          restore-keys: |
            sphinx-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,docs]"

      - name: Build Sphinx documentation
        working-directory: docs
        run: |
          make clean
          # Build with warnings as errors to enforce documentation quality
          # -W: Treat warnings as errors
          # --keep-going: Show all warnings before failing
          make html SPHINXOPTS="-W --keep-going"

      - name: Count and report warnings
        id: warnings
        working-directory: docs
        run: |
          # Rebuild to capture warnings (previous build may have failed)
          warnings=$(make html 2>&1 | grep -c "WARNING" || echo "0")
          # Sanitize to ensure clean numeric output
          warnings_count=$(echo "$warnings" | tr -cd '0-9')
          echo "warnings=${warnings_count:-0}" >> $GITHUB_OUTPUT

          if [ "${warnings_count:-0}" -gt "0" ]; then
            echo "‚ö†Ô∏è  Found ${warnings_count} warnings in Sphinx build"
          else
            echo "‚úÖ No warnings in Sphinx build"
          fi

      - name: Verify build output
        run: |
          if [ -f "docs/_build/html/index.html" ]; then
            echo "‚úÖ Sphinx documentation built successfully"
            echo "üìÑ Generated $(find docs/_build/html -name '*.html' | wc -l) HTML files"
          else
            echo "‚ùå Sphinx build failed - index.html not found"
            exit 1
          fi

      - name: Upload Sphinx HTML
        uses: actions/upload-artifact@v4
        with:
          name: sphinx-html
          path: docs/_build/html/
          retention-days: 30

  # Documentation Coverage Analysis
  doc-coverage:
    name: Documentation Coverage Analysis
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: pyproject.toml

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,docs]"

      - name: Run AST analysis
        run: |
          if [ -f "scripts/ast_analysis.py" ]; then
            python scripts/ast_analysis.py
            echo "‚úÖ AST analysis complete"
          else
            echo "‚ÑπÔ∏è  AST analysis script not found, skipping"
          fi

      - name: Run documentation coverage analysis
        id: doc_coverage_check
        run: |
          if [ -f "scripts/doc_coverage_analysis.py" ]; then
            python scripts/doc_coverage_analysis.py | tee coverage_output.txt

            # Extract coverage percentages
            module_coverage=$(grep "API documentation coverage:" coverage_output.txt | grep -oP '\d+\.\d+' || echo "0")
            docstring_coverage=$(grep "Docstring coverage:" coverage_output.txt | grep -oP '\d+\.\d+' || echo "0")

            echo "module_coverage=$module_coverage" >> $GITHUB_OUTPUT
            echo "docstring_coverage=$docstring_coverage" >> $GITHUB_OUTPUT

            # Check thresholds
            if (( $(echo "$module_coverage < 95.0" | bc -l 2>/dev/null || echo "0") )); then
              echo "‚ö†Ô∏è  Module coverage ($module_coverage%) is below 95% threshold"
            fi

            if (( $(echo "$docstring_coverage < 95.0" | bc -l 2>/dev/null || echo "0") )); then
              echo "‚ö†Ô∏è  Docstring coverage ($docstring_coverage%) is below 95% threshold"
            fi

            echo "üìä Documentation Coverage:"
            echo "   Module coverage: $module_coverage%"
            echo "   Docstring coverage: $docstring_coverage%"
          fi

      - name: Run interrogate (alternative coverage check)
        run: |
          pip install interrogate
          interrogate nlsq/ --verbose --fail-under=0 \
            --exclude='__init__.py' \
            --ignore-init-method \
            --ignore-magic \
            --ignore-private \
            --ignore-semiprivate || true

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: documentation-coverage
          path: |
            docs/coverage_report.json
            docs/ast_analysis.json
            coverage_output.txt
          retention-days: 30

  # Validate Docstrings
  validate-docstrings:
    name: Validate Docstrings
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install validation tools
        run: |
          python -m pip install --upgrade pip
          pip install pydocstyle darglint

      - name: Check docstring style (NumPy convention)
        run: |
          pydocstyle nlsq/ --convention=numpy || \
            echo "::warning::Docstring style issues found (not blocking)"

      - name: Validate docstring arguments
        run: |
          darglint -v 2 nlsq/ || \
            echo "::warning::Docstring argument mismatches found (not blocking)"

  # Test Documentation Examples
  test-examples:
    name: Test Documentation Examples
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements-dev.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run doctest
        run: |
          pytest --doctest-modules nlsq/ -v || \
            echo "::warning::Doctest failures found (not blocking)"

      - name: Validate code examples syntax
        run: |
          python -c '
          import re
          import sys
          from pathlib import Path

          def extract_md_code_blocks(filepath):
              """Extract Python code blocks from Markdown."""
              with open(filepath, "r") as f:
                  content = f.read()
              return re.findall(r"```python\n(.*?)```", content, re.DOTALL)

          def validate_syntax(code, filepath, index):
              """Validate code syntax."""
              try:
                  compile(code, f"<{filepath}:{index}>", "exec")
                  return True, None
              except SyntaxError as e:
                  return False, str(e)

          # Test README
          readme = Path("README.md")
          if readme.exists():
              readme_blocks = extract_md_code_blocks(readme)
              print(f"README.md: {len(readme_blocks)} examples")

              errors = 0
              for i, code in enumerate(readme_blocks, 1):
                  valid, error = validate_syntax(code, "README.md", i)
                  if not valid:
                      print(f"  ‚ùå Example {i}: {error}")
                      errors += 1

              if errors == 0:
                  print("  ‚úÖ All README examples valid")
              else:
                  print(f"  ‚ùå {errors} README examples failed")

          print("\n‚úÖ Code example validation complete")
          '

  # README Validation
  validate-readme:
    name: Validate README
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"

      - name: Check README for issues
        run: |
          if grep -q "http://localhost" README.md; then
            echo "::warning::README contains localhost links"
          fi

          if grep -q "TODO" README.md; then
            echo "::warning::README contains TODO markers"
          fi

          echo "‚úÖ README validation complete"

      - name: Test README code examples
        run: |
          if [ -f "tests/test_readme_examples.py" ]; then
            pytest tests/test_readme_examples.py -v
            echo "‚úÖ README examples validated"
          else
            echo "‚ÑπÔ∏è  No README example tests found"
          fi

  # Link Checking (Reuses Sphinx Build)
  check-links:
    name: Check Documentation Links
    runs-on: ubuntu-latest
    needs: build-sphinx
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements-dev.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Check for broken links
        continue-on-error: true
        working-directory: docs
        run: |
          make linkcheck || echo "::warning::Some links may be broken - check output above"

      - name: Upload linkcheck report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: linkcheck-report
          path: docs/_build/linkcheck/
          retention-days: 30

  # Documentation Summary
  docs-summary:
    name: Documentation Quality Summary
    runs-on: ubuntu-latest
    needs:
      - build-sphinx
      - doc-coverage
      - validate-docstrings
      - test-examples
      - validate-readme
      - check-links
    if: always()
    steps:
      - name: Generate summary
        run: |
          echo "## üìö Documentation Quality Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Build status
          if [ "${{ needs.build-sphinx.result }}" == "success" ]; then
            echo "‚úÖ Sphinx documentation builds successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Sphinx build failed" >> $GITHUB_STEP_SUMMARY
          fi

          # Coverage status
          if [ "${{ needs.doc-coverage.result }}" == "success" ]; then
            echo "‚úÖ Documentation coverage analysis passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è  Documentation coverage check had issues" >> $GITHUB_STEP_SUMMARY
          fi

          # Docstring validation
          if [ "${{ needs.validate-docstrings.result }}" == "success" ]; then
            echo "‚úÖ Docstring validation passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è  Docstring validation warnings (non-blocking)" >> $GITHUB_STEP_SUMMARY
          fi

          # Examples testing
          if [ "${{ needs.test-examples.result }}" == "success" ]; then
            echo "‚úÖ Documentation examples validated" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è  Some documentation examples failed" >> $GITHUB_STEP_SUMMARY
          fi

          # README validation
          if [ "${{ needs.validate-readme.result }}" == "success" ]; then
            echo "‚úÖ README validation passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è  README validation had issues" >> $GITHUB_STEP_SUMMARY
          fi

          # Link checking
          if [ "${{ needs.check-links.result }}" == "success" ]; then
            echo "‚úÖ No broken links found" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è  Some links may be broken (check artifacts)" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üì¶ [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY

      - name: Check critical failures
        run: |
          if [[ "${{ needs.build-sphinx.result }}" != "success" ]]; then
            echo "‚ùå Documentation build failed - this is a critical error"
            exit 1
          fi

          echo "‚úÖ Documentation quality checks completed"
