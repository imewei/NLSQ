{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal-Driven Optimization\n",
    "\n",
    "> Learn how to use OptimizationGoal to control workflow behavior and tolerance settings\n",
    "\n",
    "**20 minutes** | **Level: Intermediate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand all 5 `OptimizationGoal` values and their behaviors\n",
    "- Know which internal settings each goal applies\n",
    "- Combine goals with `WorkflowTier` for fine-grained control\n",
    "- Choose the right goal for your specific use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "**You are here:** Workflow System > **Optimization Goals**\n",
    "\n",
    "```\n",
    "fit() Quickstart --> Workflow Tiers --> [You are here] --> Workflow Presets\n",
    "```\n",
    "\n",
    "**Recommended flow:**\n",
    "- **Previous:** [02_workflow_tiers.ipynb](02_workflow_tiers.ipynb) - Understanding processing tiers\n",
    "- **Next:** [04_workflow_presets.ipynb](04_workflow_presets.ipynb) - Named configurations\n",
    "\n",
    "**Alternative paths:**\n",
    "- Want global optimization details? Go to [../07_global_optimization/](../07_global_optimization/)\n",
    "- Need YAML configuration? Go to [05_yaml_configuration.ipynb](05_yaml_configuration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "**Required knowledge:**\n",
    "- Basic Python and NumPy\n",
    "- Familiarity with `curve_fit()` from [01_fit_quickstart.ipynb](01_fit_quickstart.ipynb)\n",
    "\n",
    "**Required software:**\n",
    "- NLSQ >= 0.3.4\n",
    "- Python >= 3.12\n",
    "\n",
    "**First time with NLSQ?** Start here: [01_fit_quickstart.ipynb](01_fit_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Different curve fitting scenarios require different optimization strategies:\n",
    "- **Exploratory analysis** needs speed over precision\n",
    "- **Publication-quality results** need tight tolerances and validation\n",
    "- **Memory-constrained environments** need efficient processing\n",
    "- **Complex problems** need global search capabilities\n",
    "\n",
    "`OptimizationGoal` lets you express your intent, and NLSQ automatically configures:\n",
    "- Convergence tolerances (gtol, ftol, xtol)\n",
    "- Multi-start optimization settings\n",
    "- Memory/speed tradeoffs\n",
    "\n",
    "**Common use cases:**\n",
    "- Quick exploration during development: `OptimizationGoal.FAST`\n",
    "- Production fitting with unknown problem conditioning: `OptimizationGoal.ROBUST`\n",
    "- Final publication-quality results: `OptimizationGoal.QUALITY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Start (30 seconds)\n",
    "\n",
    "See goal-driven optimization in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting (MUST come before imports)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from nlsq import fit, WorkflowConfig, OptimizationGoal\n",
    "\n",
    "# Define model and generate data\n",
    "def model(x, a, b): return a * jnp.exp(-b * x)\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = 2.5 * np.exp(-1.3 * x) + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Fit with QUALITY goal for best results\n",
    "config = WorkflowConfig(goal=OptimizationGoal.QUALITY, enable_multistart=True, n_starts=10)\n",
    "popt, pcov = fit(model, x, y, p0=[1, 1], multistart=True, n_starts=10)\n",
    "print(f\"Fitted: a={popt[0]:.3f}, b={popt[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nlsq import fit, curve_fit\n",
    "from nlsq import WorkflowConfig, WorkflowTier, OptimizationGoal\n",
    "from nlsq.workflow import calculate_adaptive_tolerances, DatasetSizeTier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Content\n",
    "\n",
    "### Section 1: The OptimizationGoal Enum\n",
    "\n",
    "NLSQ provides 5 optimization goals, each representing a different priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all OptimizationGoal values\n",
    "print(\"OptimizationGoal Values:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for goal in OptimizationGoal:\n",
    "    print(f\"  {goal.name:<20} = {goal.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal descriptions and behaviors\n",
    "goal_info = {\n",
    "    OptimizationGoal.FAST: {\n",
    "        \"description\": \"Prioritize speed with local optimization only\",\n",
    "        \"tolerances\": \"One tier looser\",\n",
    "        \"multistart\": \"Disabled\",\n",
    "        \"use_case\": \"Quick exploration, well-conditioned problems\",\n",
    "    },\n",
    "    OptimizationGoal.ROBUST: {\n",
    "        \"description\": \"Standard tolerances with multi-start for better global optimum\",\n",
    "        \"tolerances\": \"Dataset-appropriate\",\n",
    "        \"multistart\": \"Enabled\",\n",
    "        \"use_case\": \"Production use, unknown problem conditioning\",\n",
    "    },\n",
    "    OptimizationGoal.GLOBAL: {\n",
    "        \"description\": \"Synonym for ROBUST (emphasizes global optimization)\",\n",
    "        \"tolerances\": \"Dataset-appropriate\",\n",
    "        \"multistart\": \"Enabled\",\n",
    "        \"use_case\": \"Same as ROBUST, semantic clarity\",\n",
    "    },\n",
    "    OptimizationGoal.MEMORY_EFFICIENT: {\n",
    "        \"description\": \"Minimize memory usage with standard tolerances\",\n",
    "        \"tolerances\": \"Dataset-appropriate\",\n",
    "        \"multistart\": \"Disabled\",\n",
    "        \"use_case\": \"Memory-constrained environments, very large datasets\",\n",
    "    },\n",
    "    OptimizationGoal.QUALITY: {\n",
    "        \"description\": \"Highest precision/accuracy as TOP PRIORITY\",\n",
    "        \"tolerances\": \"One tier tighter\",\n",
    "        \"multistart\": \"Enabled + validation passes\",\n",
    "        \"use_case\": \"Publication-quality results, critical applications\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"\\nGoal Details:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for goal, info in goal_info.items():\n",
    "    print(f\"\\n{goal.name}:\")\n",
    "    print(f\"  Description:  {info['description']}\")\n",
    "    print(f\"  Tolerances:   {info['tolerances']}\")\n",
    "    print(f\"  Multi-start:  {info['multistart']}\")\n",
    "    print(f\"  Use case:     {info['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: How Goals Affect Tolerances\n",
    "\n",
    "Each goal adjusts convergence tolerances based on dataset size. Let's see how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show tolerance calculation for different dataset sizes and goals\n",
    "dataset_sizes = [500, 5_000, 50_000, 500_000, 5_000_000]\n",
    "goals_to_compare = [OptimizationGoal.FAST, OptimizationGoal.ROBUST, OptimizationGoal.QUALITY]\n",
    "\n",
    "print(\"Adaptive Tolerances (gtol) by Dataset Size and Goal:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Dataset Size':<15} {'FAST':<15} {'ROBUST':<15} {'QUALITY':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for n_points in dataset_sizes:\n",
    "    tols = {}\n",
    "    for goal in goals_to_compare:\n",
    "        tols[goal.name] = calculate_adaptive_tolerances(n_points, goal)['gtol']\n",
    "    \n",
    "    print(f\"{n_points:>12,}   {tols['FAST']:<15.0e} {tols['ROBUST']:<15.0e} {tols['QUALITY']:<15.0e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tolerance tiers\n",
    "print(\"\\nDatasetSizeTier Reference:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Tier':<15} {'Max Points':<15} {'Base Tolerance'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for tier in DatasetSizeTier:\n",
    "    max_pts = tier.max_points if tier.max_points != float('inf') else 'unlimited'\n",
    "    if isinstance(max_pts, float):\n",
    "        max_pts_str = 'unlimited'\n",
    "    else:\n",
    "        max_pts_str = f\"{int(max_pts):,}\"\n",
    "    print(f\"{tier.name:<15} {max_pts_str:<15} {tier.tolerance:.0e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Practical Comparison\n",
    "\n",
    "Let's compare goals on a real fitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exponential decay model\n",
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "n_samples = 1000\n",
    "x_data = np.linspace(0, 5, n_samples)\n",
    "\n",
    "# True parameters\n",
    "true_a, true_b, true_c = 3.0, 1.2, 0.5\n",
    "\n",
    "y_true = true_a * np.exp(-true_b * x_data) + true_c\n",
    "noise = 0.1 * np.random.randn(n_samples)\n",
    "y_data = y_true + noise\n",
    "\n",
    "# Initial guess and bounds\n",
    "p0 = [1.0, 0.5, 0.0]\n",
    "bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n",
    "\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "print(f\"Dataset size: {n_samples} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test each goal\n",
    "results = {}\n",
    "goals_to_test = ['fast', 'robust', 'global']\n",
    "\n",
    "print(\"\\nTesting different goals:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for goal_name in goals_to_test:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    popt, pcov = fit(\n",
    "        exponential_decay,\n",
    "        x_data,\n",
    "        y_data,\n",
    "        p0=p0,\n",
    "        bounds=bounds,\n",
    "        preset=goal_name,\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Calculate SSR\n",
    "    y_pred = exponential_decay(x_data, *popt)\n",
    "    ssr = float(jnp.sum((y_data - y_pred) ** 2))\n",
    "    \n",
    "    # Calculate parameter errors\n",
    "    param_errors = [abs(popt[i] - [true_a, true_b, true_c][i]) for i in range(3)]\n",
    "    \n",
    "    results[goal_name] = {\n",
    "        'popt': popt,\n",
    "        'ssr': ssr,\n",
    "        'time': elapsed,\n",
    "        'errors': param_errors,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{goal_name.upper()}:\")\n",
    "    print(f\"  Time:       {elapsed:.4f}s\")\n",
    "    print(f\"  SSR:        {ssr:.6f}\")\n",
    "    print(f\"  Parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "    print(f\"  Errors:     a_err={param_errors[0]:.4f}, b_err={param_errors[1]:.4f}, c_err={param_errors[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Using WorkflowConfig with Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WorkflowConfig with different goals\n",
    "print(\"WorkflowConfig with Different Goals:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for goal in [OptimizationGoal.FAST, OptimizationGoal.ROBUST, OptimizationGoal.QUALITY]:\n",
    "    config = WorkflowConfig(goal=goal)\n",
    "    print(f\"\\n{goal.name}:\")\n",
    "    print(f\"  tier:             {config.tier.name}\")\n",
    "    print(f\"  gtol:             {config.gtol}\")\n",
    "    print(f\"  enable_multistart:{config.enable_multistart}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine goal with tier override\n",
    "print(\"\\nCombining Goals with Tiers:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Quality goal with streaming tier for large datasets\n",
    "config_quality_streaming = WorkflowConfig(\n",
    "    goal=OptimizationGoal.QUALITY,\n",
    "    tier=WorkflowTier.STREAMING,\n",
    "    enable_multistart=True,\n",
    "    n_starts=20,\n",
    ")\n",
    "\n",
    "print(\"Quality + Streaming:\")\n",
    "print(f\"  tier:             {config_quality_streaming.tier.name}\")\n",
    "print(f\"  goal:             {config_quality_streaming.goal.name}\")\n",
    "print(f\"  enable_multistart:{config_quality_streaming.enable_multistart}\")\n",
    "print(f\"  n_starts:         {config_quality_streaming.n_starts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-efficient with chunked tier\n",
    "config_memory_chunked = WorkflowConfig(\n",
    "    goal=OptimizationGoal.MEMORY_EFFICIENT,\n",
    "    tier=WorkflowTier.CHUNKED,\n",
    "    chunk_size=50000,\n",
    ")\n",
    "\n",
    "print(\"\\nMemory-Efficient + Chunked:\")\n",
    "print(f\"  tier:       {config_memory_chunked.tier.name}\")\n",
    "print(f\"  goal:       {config_memory_chunked.goal.name}\")\n",
    "print(f\"  chunk_size: {config_memory_chunked.chunk_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: GLOBAL vs ROBUST\n",
    "\n",
    "Note: `GLOBAL` and `ROBUST` are functionally identical. `GLOBAL` is provided for semantic clarity when you want to emphasize global optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate GLOBAL normalization\n",
    "print(\"GLOBAL and ROBUST Equivalence:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# The normalize function converts GLOBAL to ROBUST\n",
    "normalized = OptimizationGoal.normalize(OptimizationGoal.GLOBAL)\n",
    "print(f\"  OptimizationGoal.GLOBAL normalizes to: {normalized.name}\")\n",
    "\n",
    "# Both produce same tolerances\n",
    "tols_global = calculate_adaptive_tolerances(10000, OptimizationGoal.GLOBAL)\n",
    "tols_robust = calculate_adaptive_tolerances(10000, OptimizationGoal.ROBUST)\n",
    "\n",
    "print(f\"  GLOBAL gtol: {tols_global['gtol']}\")\n",
    "print(f\"  ROBUST gtol: {tols_robust['gtol']}\")\n",
    "print(f\"  Same: {tols_global['gtol'] == tols_robust['gtol']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Colors for goals\n",
    "colors = {'fast': 'blue', 'robust': 'green', 'global': 'red'}\n",
    "\n",
    "# Top left: Tolerance comparison across dataset sizes\n",
    "ax1 = axes[0, 0]\n",
    "sizes = np.logspace(2, 8, 50).astype(int)\n",
    "\n",
    "for goal in [OptimizationGoal.FAST, OptimizationGoal.ROBUST, OptimizationGoal.QUALITY]:\n",
    "    tols = [calculate_adaptive_tolerances(n, goal)['gtol'] for n in sizes]\n",
    "    ax1.loglog(sizes, tols, label=goal.name, linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Dataset Size (points)')\n",
    "ax1.set_ylabel('gtol')\n",
    "ax1.set_title('Adaptive Tolerances by Goal')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Top right: SSR comparison\n",
    "ax2 = axes[0, 1]\n",
    "goal_names = list(results.keys())\n",
    "ssrs = [results[g]['ssr'] for g in goal_names]\n",
    "bars = ax2.bar(goal_names, ssrs, color=[colors[g] for g in goal_names])\n",
    "ax2.set_xlabel('Goal')\n",
    "ax2.set_ylabel('Sum of Squared Residuals')\n",
    "ax2.set_title('Fit Quality by Goal')\n",
    "for bar, ssr in zip(bars, ssrs):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "             f\"{ssr:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Bottom left: Time comparison\n",
    "ax3 = axes[1, 0]\n",
    "times = [results[g]['time'] for g in goal_names]\n",
    "bars = ax3.bar(goal_names, times, color=[colors[g] for g in goal_names])\n",
    "ax3.set_xlabel('Goal')\n",
    "ax3.set_ylabel('Time (seconds)')\n",
    "ax3.set_title('Computation Time by Goal')\n",
    "for bar, t in zip(bars, times):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "             f\"{t:.3f}s\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Bottom right: Parameter errors\n",
    "ax4 = axes[1, 1]\n",
    "x_pos = np.arange(len(goal_names))\n",
    "width = 0.25\n",
    "\n",
    "for i, param in enumerate(['a', 'b', 'c']):\n",
    "    errors = [results[g]['errors'][i] for g in goal_names]\n",
    "    ax4.bar(x_pos + i*width, errors, width, label=f'{param} error')\n",
    "\n",
    "ax4.set_xlabel('Goal')\n",
    "ax4.set_ylabel('Absolute Error')\n",
    "ax4.set_title('Parameter Errors by Goal')\n",
    "ax4.set_xticks(x_pos + width)\n",
    "ax4.set_xticklabels(goal_names)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/03_goal_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "After completing this notebook, remember:\n",
    "\n",
    "1. **5 Optimization Goals:**\n",
    "   - `FAST`: Speed over precision, looser tolerances\n",
    "   - `ROBUST`/`GLOBAL`: Balanced with multi-start enabled\n",
    "   - `MEMORY_EFFICIENT`: Prioritizes low memory usage\n",
    "   - `QUALITY`: Tightest tolerances, validation passes\n",
    "\n",
    "2. **Goals affect tolerances adaptively:** Tolerances scale with dataset size, and goals shift tolerances tighter (QUALITY) or looser (FAST).\n",
    "\n",
    "3. **Combine goals with tiers:** Use `WorkflowConfig(goal=..., tier=...)` for fine-grained control over both optimization priority and processing strategy.\n",
    "\n",
    "4. **GLOBAL = ROBUST:** They are functionally identical; use GLOBAL for semantic emphasis on global optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Questions\n",
    "\n",
    "**Q: Which goal should I use for exploratory analysis?**\n",
    "\n",
    "A: Use `OptimizationGoal.FAST` for quick exploration. It uses looser tolerances and disables multi-start, giving you fast results when precision isn't critical.\n",
    "\n",
    "**Q: When should I use QUALITY vs ROBUST?**\n",
    "\n",
    "A: Use `QUALITY` for final, publication-quality results where accuracy is paramount. Use `ROBUST` for production code where you want good results with reasonable computation time.\n",
    "\n",
    "**Q: Can I use different goals for the same problem?**\n",
    "\n",
    "A: Yes! A common pattern is to use `FAST` during development, then `ROBUST` for production, and `QUALITY` for final publication results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**Next steps:**\n",
    "- [04_workflow_presets.ipynb](04_workflow_presets.ipynb) - Explore named preset configurations\n",
    "- [05_yaml_configuration.ipynb](05_yaml_configuration.ipynb) - File-based configuration\n",
    "\n",
    "**Further reading:**\n",
    "- [API Documentation](https://nlsq.readthedocs.io/)\n",
    "- [GitHub Repository](https://github.com/imewei/NLSQ)\n",
    "\n",
    "**Need help?**\n",
    "- [Discussions](https://github.com/imewei/NLSQ/discussions)\n",
    "- [Report issues](https://github.com/imewei/NLSQ/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Glossary\n",
    "\n",
    "**OptimizationGoal:** An enum that specifies the optimization priority (FAST, ROBUST, GLOBAL, MEMORY_EFFICIENT, QUALITY).\n",
    "\n",
    "**Tolerance:** Convergence threshold for optimization (gtol for gradient, ftol for function, xtol for parameters).\n",
    "\n",
    "**Multi-start:** Optimization technique that evaluates multiple starting points to find global optima.\n",
    "\n",
    "**Tier:** Processing strategy (STANDARD, CHUNKED, STREAMING) based on dataset size and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "print()\n",
    "print(\"Goal recommendations:\")\n",
    "print(\"  - Exploratory analysis:    OptimizationGoal.FAST\")\n",
    "print(\"  - Production fitting:      OptimizationGoal.ROBUST\")\n",
    "print(\"  - Global search emphasis:  OptimizationGoal.GLOBAL\")\n",
    "print(\"  - Memory constraints:      OptimizationGoal.MEMORY_EFFICIENT\")\n",
    "print(\"  - Publication quality:     OptimizationGoal.QUALITY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
