{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified fit() Entry Point\n",
    "\n",
    "> Learn to use NLSQ's unified `fit()` function for automatic workflow selection\n",
    "\n",
    "**15 minutes** | **Level: Beginner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Use the `fit()` function with automatic workflow selection\n",
    "- Apply preset configurations like `preset=\"robust\"` and `preset=\"fast\"`\n",
    "- Configure `fit()` with `WorkflowConfig` for custom workflows\n",
    "- Understand when to use `fit()`, `curve_fit()`, and `curve_fit_large()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "**You are here:** Workflow System > **Unified fit() Entry Point**\n",
    "\n",
    "```\n",
    "Getting Started --> [You are here: fit() Quickstart] --> Workflow Tiers --> Presets\n",
    "```\n",
    "\n",
    "**Recommended flow:**\n",
    "- **Next:** [02_workflow_tiers.ipynb](02_workflow_tiers.ipynb) - Learn about STANDARD, CHUNKED, STREAMING tiers\n",
    "\n",
    "**Alternative paths:**\n",
    "- Want global optimization? Go to [../07_global_optimization/01_multistart_basics.ipynb](../07_global_optimization/01_multistart_basics.ipynb)\n",
    "- Need domain examples? Go to [../04_gallery/](../04_gallery/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "**Required knowledge:**\n",
    "- Basic Python and NumPy\n",
    "- Familiarity with curve fitting concepts\n",
    "\n",
    "**Required software:**\n",
    "- NLSQ >= 0.3.4\n",
    "- Python >= 3.12\n",
    "\n",
    "**First time with NLSQ?** Start here: [NLSQ Quickstart](../01_getting_started/nlsq_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "NLSQ provides three main APIs for curve fitting:\n",
    "- `curve_fit()` - Standard fitting for small datasets\n",
    "- `curve_fit_large()` - Memory-managed fitting for large datasets\n",
    "- `fit()` - **Unified entry point that automatically selects the best approach**\n",
    "\n",
    "The `fit()` function simplifies your workflow by:\n",
    "- Automatically detecting dataset size and selecting appropriate strategy\n",
    "- Providing preset configurations for common use cases\n",
    "- Offering a consistent API regardless of dataset size\n",
    "\n",
    "**Common use cases:**\n",
    "- Rapid prototyping with sensible defaults\n",
    "- Production code that handles varying dataset sizes\n",
    "- Switching between speed-optimized and accuracy-optimized workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Start (30 seconds)\n",
    "\n",
    "See NLSQ's `fit()` in action with this minimal example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting (MUST come before imports)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from nlsq import fit\n",
    "\n",
    "# Define model and generate data\n",
    "def model(x, a, b): return a * jnp.exp(-b * x)\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = 2.5 * np.exp(-1.3 * x) + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Fit with automatic workflow selection\n",
    "popt, pcov = fit(model, x, y, p0=[1, 1])\n",
    "print(f\"Fitted parameters: a={popt[0]:.3f}, b={popt[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see fitted parameters close to `a=2.5, b=1.3`, you're ready to continue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nlsq import fit, curve_fit, curve_fit_large\n",
    "from nlsq import WorkflowConfig, OptimizationGoal\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Content\n",
    "\n",
    "### Section 1: Basic fit() Usage\n",
    "\n",
    "The `fit()` function provides a unified interface for curve fitting. It automatically\n",
    "selects the appropriate backend based on dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an exponential decay model\n",
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "n_samples = 500\n",
    "x_data = np.linspace(0, 5, n_samples)\n",
    "\n",
    "# True parameters\n",
    "true_a, true_b, true_c = 3.0, 1.2, 0.5\n",
    "\n",
    "# Generate noisy observations\n",
    "y_true = true_a * np.exp(-true_b * x_data) + true_c\n",
    "noise = 0.15 * np.random.randn(n_samples)\n",
    "y_data = y_true + noise\n",
    "\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "print(f\"Dataset size: {n_samples} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic fit() - auto-selects workflow\n",
    "popt, pcov = fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],  # Initial guess\n",
    ")\n",
    "\n",
    "print(\"\\nfit() with automatic workflow selection:\")\n",
    "print(f\"  Fitted: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(f\"  True:   a={true_a:.4f}, b={true_b:.4f}, c={true_c:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Using Presets\n",
    "\n",
    "The `fit()` function supports preset configurations for common use cases:\n",
    "\n",
    "| Preset | Description | Multi-start | Use Case |\n",
    "|--------|-------------|-------------|----------|\n",
    "| `fast` | Maximum speed, single-start | No | Quick exploration |\n",
    "| `robust` | Multi-start with 5 starts | Yes | Production use |\n",
    "| `global` | Thorough search with 20 starts | Yes | Complex problems |\n",
    "| `streaming` | For large datasets | Yes | Big data |\n",
    "| `large` | Auto-detect large datasets | Yes | Variable sizes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounds for constrained optimization\n",
    "bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset: 'fast' - single-start for maximum speed\n",
    "popt_fast, _ = fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    "    preset=\"fast\",\n",
    ")\n",
    "\n",
    "print(\"preset='fast':\")\n",
    "print(f\"  Fitted: a={popt_fast[0]:.4f}, b={popt_fast[1]:.4f}, c={popt_fast[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset: 'robust' - multi-start with 5 starting points\n",
    "popt_robust, _ = fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    "    preset=\"robust\",\n",
    ")\n",
    "\n",
    "print(\"\\npreset='robust':\")\n",
    "print(f\"  Fitted: a={popt_robust[0]:.4f}, b={popt_robust[1]:.4f}, c={popt_robust[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preset: 'global' - thorough global search with 20 starts\n",
    "popt_global, _ = fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    "    preset=\"global\",\n",
    ")\n",
    "\n",
    "print(\"\\npreset='global':\")\n",
    "print(f\"  Fitted: a={popt_global[0]:.4f}, b={popt_global[1]:.4f}, c={popt_global[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Using WorkflowConfig\n",
    "\n",
    "For more control, you can create a `WorkflowConfig` object to customize the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom WorkflowConfig\n",
    "config = WorkflowConfig(\n",
    "    goal=OptimizationGoal.QUALITY,  # Prioritize accuracy\n",
    "    enable_multistart=True,\n",
    "    n_starts=15,\n",
    "    sampler=\"lhs\",\n",
    ")\n",
    "\n",
    "print(\"WorkflowConfig:\")\n",
    "print(f\"  goal: {config.goal}\")\n",
    "print(f\"  enable_multistart: {config.enable_multistart}\")\n",
    "print(f\"  n_starts: {config.n_starts}\")\n",
    "print(f\"  sampler: {config.sampler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using WorkflowConfig with fit() - pass multistart parameters directly\n",
    "popt_custom, _ = fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    "    multistart=True,\n",
    "    n_starts=15,\n",
    "    sampler=\"lhs\",\n",
    ")\n",
    "\n",
    "print(\"\\nCustom configuration result:\")\n",
    "print(f\"  Fitted: a={popt_custom[0]:.4f}, b={popt_custom[1]:.4f}, c={popt_custom[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Comparison with curve_fit() and curve_fit_large()\n",
    "\n",
    "Let's compare `fit()` with the lower-level APIs to understand when to use each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using curve_fit() - standard API\n",
    "popt_cf, pcov_cf = curve_fit(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    ")\n",
    "\n",
    "print(\"curve_fit():\")\n",
    "print(f\"  Fitted: a={popt_cf[0]:.4f}, b={popt_cf[1]:.4f}, c={popt_cf[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using curve_fit_large() - auto-detects and falls back to curve_fit for small datasets\n",
    "# For datasets > 1M points, it uses chunked processing\n",
    "popt_cfl, pcov_cfl = curve_fit_large(\n",
    "    exponential_decay,\n",
    "    x_data,\n",
    "    y_data,\n",
    "    p0=[1.0, 1.0, 0.0],\n",
    "    bounds=bounds,\n",
    ")\n",
    "\n",
    "print(\"\\ncurve_fit_large():\")\n",
    "print(f\"  Fitted: a={popt_cfl[0]:.4f}, b={popt_cfl[1]:.4f}, c={popt_cfl[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Each API\n",
    "\n",
    "| API | Best For | Dataset Size |\n",
    "|-----|----------|-------------|\n",
    "| `fit()` | General use, automatic selection | Any |\n",
    "| `curve_fit()` | Full control, SciPy compatibility | < 1M points |\n",
    "| `curve_fit_large()` | Explicit large dataset handling | > 1M points |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fits\n",
    "y_pred = exponential_decay(x_data, *popt)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: Data and fit\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(x_data, y_data, alpha=0.4, s=10, label=\"Data\")\n",
    "ax1.plot(x_data, y_true, \"k--\", linewidth=2, label=\"True function\")\n",
    "ax1.plot(x_data, y_pred, \"r-\", linewidth=2, label=\"fit() result\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_title(\"Exponential Decay Fit\")\n",
    "ax1.legend()\n",
    "\n",
    "# Right: Residuals\n",
    "ax2 = axes[1]\n",
    "residuals = y_data - y_pred\n",
    "ax2.scatter(x_data, residuals, alpha=0.5, s=10)\n",
    "ax2.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"Residual\")\n",
    "ax2.set_title(\"Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/01_fit_result.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "After completing this notebook, remember:\n",
    "\n",
    "1. **`fit()` is the unified entry point:** It automatically selects the best workflow based on dataset size and configuration.\n",
    "\n",
    "2. **Presets simplify configuration:** Use `preset=\"fast\"` for speed, `preset=\"robust\"` for production, or `preset=\"global\"` for complex problems.\n",
    "\n",
    "3. **`WorkflowConfig` provides full control:** Create custom configurations with `OptimizationGoal`, multi-start settings, and more.\n",
    "\n",
    "4. **Choose the right API:**\n",
    "   - `fit()` - General use, automatic selection\n",
    "   - `curve_fit()` - SciPy compatibility, full control\n",
    "   - `curve_fit_large()` - Explicit large dataset handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Questions\n",
    "\n",
    "**Q: When should I use `fit()` vs `curve_fit()`?**\n",
    "\n",
    "A: Use `fit()` when you want automatic workflow selection and preset configurations. Use `curve_fit()` when you need SciPy compatibility or want explicit control over all parameters.\n",
    "\n",
    "**Q: What's the default preset?**\n",
    "\n",
    "A: The default is `preset=\"fast\"` for small datasets (< 1M points) and `preset=\"large\"` for datasets exceeding the size threshold.\n",
    "\n",
    "**Q: Can I combine presets with custom parameters?**\n",
    "\n",
    "A: Yes! Custom parameters override preset defaults. For example, `fit(..., preset=\"robust\", n_starts=10)` uses the robust preset but with 10 starts instead of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**Next steps:**\n",
    "- [02_workflow_tiers.ipynb](02_workflow_tiers.ipynb) - Learn about STANDARD, CHUNKED, STREAMING tiers\n",
    "- [04_workflow_presets.ipynb](04_workflow_presets.ipynb) - Explore all available presets\n",
    "\n",
    "**Further reading:**\n",
    "- [API Documentation](https://nlsq.readthedocs.io/)\n",
    "- [GitHub Repository](https://github.com/imewei/NLSQ)\n",
    "\n",
    "**Need help?**\n",
    "- [Discussions](https://github.com/imewei/NLSQ/discussions)\n",
    "- [Report issues](https://github.com/imewei/NLSQ/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Glossary\n",
    "\n",
    "**Preset:** A named configuration that sets multiple parameters at once (e.g., 'fast', 'robust', 'global').\n",
    "\n",
    "**Workflow:** A processing strategy for curve fitting (STANDARD, CHUNKED, STREAMING).\n",
    "\n",
    "**Multi-start:** An optimization technique that evaluates multiple starting points to find the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "print()\n",
    "print(\"Results from different approaches:\")\n",
    "print(f\"  fit() auto:     a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "print(f\"  preset='fast':  a={popt_fast[0]:.4f}, b={popt_fast[1]:.4f}, c={popt_fast[2]:.4f}\")\n",
    "print(f\"  preset='robust':a={popt_robust[0]:.4f}, b={popt_robust[1]:.4f}, c={popt_robust[2]:.4f}\")\n",
    "print(f\"  curve_fit():    a={popt_cf[0]:.4f}, b={popt_cf[1]:.4f}, c={popt_cf[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
