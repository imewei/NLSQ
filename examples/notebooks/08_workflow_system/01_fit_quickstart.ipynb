{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edabe011",
   "metadata": {},
   "source": "# 01 Fit Quickstart (v0.6.3)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/08_workflow_system/01_fit_quickstart.ipynb)\n\n**The Three Workflows (v0.6.3):**\n- `workflow=\"auto\"` : Memory-aware local optimization (bounds optional)\n- `workflow=\"auto_global\"` : Memory-aware global optimization (bounds required)\n- `workflow=\"hpc\"` : auto_global + checkpointing for HPC (bounds required)\n\nFeatures demonstrated:\n- Using fit() with automatic memory-based strategy selection\n- Using workflow='auto_global' for global optimization\n- Adjusting tolerances directly (not via presets)\n- Comparing fit(), curve_fit(), and curve_fit_large()\n\nRun this example:\n    python examples/scripts/08_workflow_system/01_fit_quickstart.py"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f592b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:29.973177Z",
     "iopub.status.busy": "2026-01-06T17:53:29.972908Z",
     "iopub.status.idle": "2026-01-06T17:53:29.979572Z",
     "shell.execute_reply": "2026-01-06T17:53:29.978166Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Install NLSQ (run once in Colab)\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab - installing NLSQ...\")\n",
    "    !pip install -q nlsq\n",
    "    print(\"NLSQ installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c82deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:29.982231Z",
     "iopub.status.busy": "2026-01-06T17:53:29.981920Z",
     "iopub.status.idle": "2026-01-06T17:53:31.746899Z",
     "shell.execute_reply": "2026-01-06T17:53:31.744614Z"
    }
   },
   "outputs": [],
   "source": "from pathlib import Path\n\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom nlsq import curve_fit, curve_fit_large, fit\n\nFIG_DIR = Path.cwd() / \"figures\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf9f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:31.751309Z",
     "iopub.status.busy": "2026-01-06T17:53:31.750546Z",
     "iopub.status.idle": "2026-01-06T17:53:31.766491Z",
     "shell.execute_reply": "2026-01-06T17:53:31.766076Z"
    }
   },
   "outputs": [],
   "source": "def exponential_decay(x, a, b, c):\n    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n    return a * jnp.exp(-b * x) + c\n\n\ndef main():\n    print(\"=\" * 70)\n    print(\"Unified fit() Entry Point - Quickstart (v0.6.3)\")\n    print(\"=\" * 70)\n    print()\n\n    np.random.seed(42)\n\n    # =========================================================================\n    # 1. Generate synthetic data\n    # =========================================================================\n    print(\"1. Generating synthetic data...\")\n\n    n_samples = 500\n    x_data = np.linspace(0, 5, n_samples)\n\n    true_a, true_b, true_c = 3.0, 1.2, 0.5\n\n    y_true = true_a * np.exp(-true_b * x_data) + true_c\n    noise = 0.15 * np.random.randn(n_samples)\n    y_data = y_true + noise\n\n    print(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}\")\n    print(f\"  Dataset size: {n_samples} points\")\n\n    # =========================================================================\n    # 2. workflow='auto' - Local optimization with automatic memory strategy\n    # =========================================================================\n    print()\n    print(\"2. workflow='auto' - Local optimization (default, bounds optional)...\")\n\n    popt_auto, pcov_auto = fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        workflow=\"auto\",  # Default: automatic memory-based strategy selection\n    )\n\n    print(f\"  Fitted: a={popt_auto[0]:.4f}, b={popt_auto[1]:.4f}, c={popt_auto[2]:.4f}\")\n    print(f\"  True:   a={true_a:.4f}, b={true_b:.4f}, c={true_c:.4f}\")\n\n    # =========================================================================\n    # 3. workflow='auto' with bounds\n    # =========================================================================\n    print()\n    print(\"3. workflow='auto' with optional bounds...\")\n\n    bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n\n    popt_bounded, _ = fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n        workflow=\"auto\",  # Bounds are optional for 'auto'\n    )\n    print(f\"  Bounded fit: a={popt_bounded[0]:.4f}, b={popt_bounded[1]:.4f}, c={popt_bounded[2]:.4f}\")\n\n    # =========================================================================\n    # 4. workflow='auto_global' - Global optimization\n    # =========================================================================\n    print()\n    print(\"4. workflow='auto_global' - Global optimization (bounds required)...\")\n    print(\"   Automatically selects CMA-ES or Multi-Start based on parameter scales\")\n\n    popt_global, _ = fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n        workflow=\"auto_global\",  # Bounds required for global optimization\n        n_starts=5,  # Number of multi-start runs\n    )\n    print(f\"  Global fit: a={popt_global[0]:.4f}, b={popt_global[1]:.4f}, c={popt_global[2]:.4f}\")\n\n    # =========================================================================\n    # 5. Adjusting tolerances directly\n    # =========================================================================\n    print()\n    print(\"5. Adjusting tolerances directly (not via presets)...\")\n\n    # Looser tolerances for speed\n    popt_fast, _ = fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n        workflow=\"auto\",\n        gtol=1e-6,\n        ftol=1e-6,\n        xtol=1e-6,\n    )\n    print(f\"  Fast (gtol=1e-6): a={popt_fast[0]:.4f}, b={popt_fast[1]:.4f}, c={popt_fast[2]:.4f}\")\n\n    # Tighter tolerances for precision\n    popt_precise, _ = fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n        workflow=\"auto\",\n        gtol=1e-10,\n        ftol=1e-10,\n        xtol=1e-10,\n    )\n    print(f\"  Precise (gtol=1e-10): a={popt_precise[0]:.4f}, b={popt_precise[1]:.4f}, c={popt_precise[2]:.4f}\")\n\n    # =========================================================================\n    # 6. Comparison with curve_fit() and curve_fit_large()\n    # =========================================================================\n    print()\n    print(\"6. Comparison with other APIs...\")\n\n    popt_cf, _ = curve_fit(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n    )\n    print(f\"  curve_fit():       a={popt_cf[0]:.4f}, b={popt_cf[1]:.4f}, c={popt_cf[2]:.4f}\")\n\n    popt_cfl, _ = curve_fit_large(\n        exponential_decay,\n        x_data,\n        y_data,\n        p0=[1.0, 1.0, 0.0],\n        bounds=bounds,\n    )\n    print(f\"  curve_fit_large(): a={popt_cfl[0]:.4f}, b={popt_cfl[1]:.4f}, c={popt_cfl[2]:.4f}\")\n\n    # =========================================================================\n    # 7. Visualization\n    # =========================================================================\n    print()\n    print(\"7. Saving visualization...\")\n\n    y_pred = exponential_decay(x_data, *popt_auto)\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    ax1 = axes[0]\n    ax1.scatter(x_data, y_data, alpha=0.4, s=10, label=\"Data\")\n    ax1.plot(x_data, y_true, \"k--\", linewidth=2, label=\"True function\")\n    ax1.plot(x_data, y_pred, \"r-\", linewidth=2, label=\"fit() result\")\n    ax1.set_xlabel(\"x\")\n    ax1.set_ylabel(\"y\")\n    ax1.set_title(\"Exponential Decay Fit\")\n    ax1.legend()\n\n    ax2 = axes[1]\n    residuals = y_data - y_pred\n    ax2.scatter(x_data, residuals, alpha=0.5, s=10)\n    ax2.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.5)\n    ax2.set_xlabel(\"x\")\n    ax2.set_ylabel(\"Residual\")\n    ax2.set_title(\"Residuals\")\n\n    plt.tight_layout()\n    plt.savefig(FIG_DIR / \"01_fit_result.png\", dpi=300, bbox_inches=\"tight\")\n    plt.show()\n    print(f\"  Saved: {FIG_DIR / '01_fit_result.png'}\")\n\n    # =========================================================================\n    # Summary\n    # =========================================================================\n    print()\n    print(\"=\" * 70)\n    print(\"Summary - The Three Workflows (v0.6.3)\")\n    print(\"=\" * 70)\n    print()\n    print(\"Workflows:\")\n    print(\"  workflow='auto'        : Local optimization, bounds optional\")\n    print(\"                           Auto-selects: STANDARD / CHUNKED / STREAMING\")\n    print()\n    print(\"  workflow='auto_global' : Global optimization, bounds required\")\n    print(\"                           Auto-selects: CMA-ES or Multi-Start\")\n    print()\n    print(\"  workflow='hpc'         : auto_global + checkpointing for HPC\")\n    print()\n    print(\"Tolerance control (set directly, not via presets):\")\n    print(\"  gtol, ftol, xtol=1e-6  : Fast fitting, looser tolerances\")\n    print(\"  gtol, ftol, xtol=1e-10 : High precision fitting\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3054b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:31.768467Z",
     "iopub.status.busy": "2026-01-06T17:53:31.768338Z",
     "iopub.status.idle": "2026-01-06T17:53:42.307796Z",
     "shell.execute_reply": "2026-01-06T17:53:42.307146Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
