{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    return a * jnp.exp(-b * x) + c\ndef estimate_memory_usage(n_points, n_params, strategy):\n    \"\"\"Estimate memory usage in GB for a given strategy.\"\"\"\n    bytes_per_point = 8 * (3 + n_params)  # x, y, residual + jacobian\n    if strategy == \"standard\":\n        return n_points * bytes_per_point / 1e9\n    elif strategy == \"chunked\":\n        chunk_size = min(1_000_000, n_points)\n        return chunk_size * bytes_per_point / 1e9\n    elif strategy == \"streaming\":\n        batch_size = 50_000\n        return batch_size * bytes_per_point / 1e9\n    else:\n        return 0\ndef main():\n    print(\"=\" * 70)\n    print(\"Memory-Based Strategy Selection\")\n    print(\"=\" * 70)\n    print()\n    np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Overview of Strategies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"1. Strategy Overview\")\nprint(\"-\" * 50)\nstrategy_info = {\n    \"standard\": {\n        \"description\": \"Standard curve_fit() for small datasets\",\n        \"dataset_size\": \"When peak memory fits in available memory\",\n        \"memory\": \"O(N) - loads all data into memory\",\n    },\n    \"chunked\": {\n        \"description\": \"LargeDatasetFitter with automatic chunking\",\n        \"dataset_size\": \"When data fits but Jacobian doesn't\",\n        \"memory\": \"O(chunk_size) - processes data in chunks\",\n    },\n    \"streaming\": {\n        \"description\": \"AdaptiveHybridStreamingOptimizer for huge datasets\",\n        \"dataset_size\": \"When even data arrays exceed memory\",\n        \"memory\": \"O(batch_size) - mini-batch gradient descent\",\n    },\n}\nfor strategy, info in strategy_info.items():\n    print(f\"\\n{strategy.upper()}:\")\n    print(f\"  Description: {info['description']}\")\n    print(f\"  Use case:    {info['dataset_size']}\")\n    print(f\"  Memory:      {info['memory']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. MemoryBudget for Computing Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"2. MemoryBudget - Computing Memory Requirements\")\nprint(\"-\" * 50)\ntest_cases = [\n    (1_000, 5, \"1K\"),\n    (100_000, 5, \"100K\"),\n    (1_000_000, 5, \"1M\"),\n    (10_000_000, 5, \"10M\"),\n]\nprint(\n    f\"\\n{'Dataset':<10} {'Data (GB)':<12} {'Jacobian (GB)':<15} {'Peak (GB)':<12}\"\n)\nprint(\"-\" * 50)\nfor n_points, n_params, label in test_cases:\n    budget = MemoryBudget.compute(n_points=n_points, n_params=n_params)\n    print(\n        f\"{label:<10} {budget.data_gb:<12.4f} {budget.jacobian_gb:<15.4f} {budget.peak_gb:<12.4f}\"\n    )\navailable_memory = MemoryEstimator.get_available_memory_gb()\nprint(f\"\\nCurrent system available memory: {available_memory:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Memory Budget Details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"3. Memory Budget Details for 5M Points\")\nprint(\"-\" * 50)\nbudget = MemoryBudget.compute(n_points=5_000_000, n_params=5, safety_factor=0.75)\nprint(f\"  Available memory:  {budget.available_gb:.1f} GB\")\nprint(f\"  Threshold (75%):   {budget.threshold_gb:.1f} GB\")\nprint(f\"  Data arrays:       {budget.data_gb:.3f} GB\")\nprint(f\"  Jacobian matrix:   {budget.jacobian_gb:.3f} GB\")\nprint(f\"  Peak estimate:     {budget.peak_gb:.3f} GB\")\nprint(f\"  Fits in memory:    {budget.fits_in_memory}\")\nprint(f\"  Data fits:         {budget.data_fits}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Automatic Strategy Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"4. Automatic Strategy Selection\")\nprint(\"-\" * 50)\nselector = MemoryBudgetSelector(safety_factor=0.75)\nprint(f\"  Available memory: {available_memory:.1f} GB\")\nprint()\ntest_sizes = [1_000, 50_000, 500_000, 5_000_000, 50_000_000]\nn_params = 5\nprint(f\"{'Dataset Size':<15} {'Strategy':<15}\")\nprint(\"-\" * 30)\nfor n_points in test_sizes:\n    strategy, config = selector.select(n_points=n_points, n_params=n_params)\n    if n_points >= 1_000_000:\n        size_str = f\"{n_points / 1_000_000:.0f}M\"\n    elif n_points >= 1_000:\n        size_str = f\"{n_points / 1_000:.0f}K\"\n    else:\n        size_str = str(n_points)\n    print(f\"{size_str:<15} {strategy:<15}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Decision Tree Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"5. Saving strategy selection decision tree...\")\nfig, ax = plt.subplots(figsize=(14, 10))\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.axis(\"off\")\nax.text(\n    5,\n    9.5,\n    \"Memory-Based Strategy Selection Decision Tree\",\n    ha=\"center\",\n    fontsize=16,\n    fontweight=\"bold\",\n)\nax.add_patch(\n    plt.Rectangle(\n        (3.0, 7.8), 4, 1, fill=True, facecolor=\"lightblue\", edgecolor=\"black\"\n    )\n)\nax.text(5, 8.3, \"Compute Memory Budget\", ha=\"center\", va=\"center\", fontsize=11)\nax.text(\n    5,\n    8.0,\n    \"MemoryBudget.compute()\",\n    ha=\"center\",\n    va=\"center\",\n    fontsize=9,\n    style=\"italic\",\n)\nax.plot([5, 5], [7.8, 6.8], \"k-\", linewidth=1)\nax.add_patch(\n    plt.Rectangle(\n        (2.5, 5.8), 5, 1, fill=True, facecolor=\"lightyellow\", edgecolor=\"black\"\n    )\n)\nax.text(5, 6.3, \"data_gb > threshold_gb?\", ha=\"center\", va=\"center\", fontsize=11)\nax.plot([5.8, 8, 8], [5.8, 5.2, 4.5], \"k-\", linewidth=1)\nax.text(7.5, 5.5, \"Yes\", fontsize=9)\nax.add_patch(\n    plt.Rectangle(\n        (6.5, 3.5), 3, 1, fill=True, facecolor=\"salmon\", edgecolor=\"black\"\n    )\n)\nax.text(\n    8, 4.0, \"STREAMING\", ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\"\n)\nax.text(8, 3.7, \"Mini-batch optimizer\", ha=\"center\", va=\"center\", fontsize=8)\nax.plot([4.2, 2, 2], [5.8, 5.2, 4.5], \"k-\", linewidth=1)\nax.text(2.5, 5.5, \"No\", fontsize=9)\nax.add_patch(\n    plt.Rectangle(\n        (0.5, 3.5), 3, 1, fill=True, facecolor=\"lightyellow\", edgecolor=\"black\"\n    )\n)\nax.text(2, 4.0, \"peak_gb > threshold_gb?\", ha=\"center\", va=\"center\", fontsize=10)\nax.plot([2.8, 4, 4], [3.5, 2.8, 2.0], \"k-\", linewidth=1)\nax.text(3.5, 3.0, \"Yes\", fontsize=9)\nax.add_patch(\n    plt.Rectangle(\n        (2.5, 1.0), 3, 1, fill=True, facecolor=\"orange\", edgecolor=\"black\"\n    )\n)\nax.text(4, 1.5, \"CHUNKED\", ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\")\nax.text(4, 1.2, \"Memory-managed chunking\", ha=\"center\", va=\"center\", fontsize=8)\nax.plot([1.2, 0.5, 0.5], [3.5, 2.8, 2.0], \"k-\", linewidth=1)\nax.text(0.7, 3.0, \"No\", fontsize=9)\nax.add_patch(\n    plt.Rectangle(\n        (-0.5, 1.0), 3, 1, fill=True, facecolor=\"lightgreen\", edgecolor=\"black\"\n    )\n)\nax.text(\n    1, 1.5, \"STANDARD\", ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\"\n)\nax.text(1, 1.2, \"Full in-memory fit\", ha=\"center\", va=\"center\", fontsize=8)\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"02_strategy_decision_tree.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '02_strategy_decision_tree.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Using Different Memory Limits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"6. Strategy Selection with Different Memory Limits\")\nprint(\"-\" * 70)\nmemory_limits = [8.0, 32.0, 64.0, 128.0]  # GB\nn_points = 5_000_000  # 5M points\nn_params = 5\nprint(f\"Dataset: {n_points / 1e6:.0f}M points, {n_params} parameters\")\nprint()\nfor mem_limit in memory_limits:\n    selector_fixed = MemoryBudgetSelector(safety_factor=0.75)\n    strategy, config = selector_fixed.select(\n        n_points=n_points, n_params=n_params, memory_limit_gb=mem_limit\n    )\n    config_type = type(config).__name__ if config else \"None\"\n    print(f\"  Memory limit: {mem_limit:>6.0f} GB -> {strategy:12s} ({config_type})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Test Fit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"7. Test Fit\")\nprint(\"-\" * 50)\nn_samples = 1000\nx_data = np.linspace(0, 5, n_samples)\ntrue_a, true_b, true_c = 3.0, 1.2, 0.5\ny_true = true_a * np.exp(-true_b * x_data) + true_c\ny_data = y_true + 0.1 * np.random.randn(n_samples)\nprint(f\"  Test dataset: {n_samples} points\")\nprint(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}\")\npopt, _ = fit(\n    exponential_decay,\n    x_data,\n    y_data,\n    p0=[1.0, 1.0, 0.0],\n    workflow=\"auto\",\n)\nprint(f\"  Fitted: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Memory Usage Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"8. Saving memory usage comparison...\")\ndataset_sizes = np.logspace(3, 9, 50)  # 1K to 1B points\nn_params = 5\nmemory_standard = [\n    estimate_memory_usage(int(n), n_params, \"standard\") for n in dataset_sizes\n]\nmemory_chunked = [\n    estimate_memory_usage(int(n), n_params, \"chunked\") for n in dataset_sizes\n]\nmemory_streaming = [\n    estimate_memory_usage(int(n), n_params, \"streaming\") for n in dataset_sizes\n]\nfig, ax = plt.subplots(figsize=(12, 7))\nax.loglog(dataset_sizes, memory_standard, \"b-\", linewidth=2, label=\"standard\")\nax.loglog(dataset_sizes, memory_chunked, \"orange\", linewidth=2, label=\"chunked\")\nax.loglog(dataset_sizes, memory_streaming, \"r-\", linewidth=2, label=\"streaming\")\nax.axhline(y=16, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"16 GB limit\")\nax.axhline(y=64, color=\"gray\", linestyle=\":\", alpha=0.5, label=\"64 GB limit\")\nax.set_xlabel(\"Dataset Size (points)\")\nax.set_ylabel(\"Peak Memory Usage (GB)\")\nax.set_title(\"Memory Usage by Strategy\")\nax.legend(loc=\"upper left\")\nax.grid(True, alpha=0.3, which=\"both\")\nax.set_xlim(1e3, 1e9)\nax.set_ylim(1e-3, 1e3)\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"02_memory_comparison.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '02_memory_comparison.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. Defense Layers for Streaming (v0.3.6+)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint()\nprint(\"9. Defense Layers for Streaming (v0.3.6+)\")\nprint(\"-\" * 50)\nprint()\nprint(\n    \"The streaming strategy uses AdaptiveHybridStreamingOptimizer, which includes\"\n)\nprint(\"a 4-layer defense strategy against L-BFGS warmup divergence:\")\nprint()\nprint(\"  Layer 1 (Warm Start Detection):\")\nprint(\"    - Skips warmup if initial loss < 1% of data variance\")\nprint(\"    - Prevents overshooting when starting near the optimum\")\nprint()\nprint(\"  Layer 2 (Adaptive Step Size):\")\nprint(\"    - Scales step size based on fit quality (1e-6 to 0.001)\")\nprint()\nprint(\"  Layer 3 (Cost-Increase Guard):\")\nprint(\"    - Aborts warmup if loss increases > 5%\")\nprint(\"    - Triggers early switch to Gauss-Newton phase\")\nprint()\nprint(\"  Layer 4 (Step Clipping):\")\nprint(\"    - Limits parameter update magnitude (max norm 0.1)\")\nprint(\"    - Prevents catastrophic parameter jumps\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    print()\n    print()\n    print(\"=\" * 70)\n    print(\"Summary\")\n    print(\"=\" * 70)\n    print()\n    print(\"Strategies:\")\n    print(\"  standard:  Full in-memory computation, fastest for small datasets\")\n    print(\"  chunked:   Memory-managed chunking for large datasets\")\n    print(\"  streaming: Mini-batch optimization with defense layers\")\n    print()\n    print(\"Decision tree:\")\n    print(\"  1. data_gb > threshold_gb? \u2192 streaming (data doesn't fit)\")\n    print(\"  2. peak_gb > threshold_gb? \u2192 chunked (Jacobian doesn't fit)\")\n    print(\"  3. else \u2192 standard (everything fits)\")\n    print()\n    print(f\"Current system memory: {available_memory:.1f} GB\")\n    print()\n    print(\"Key classes:\")\n    print(\"  MemoryBudget.compute()   - Compute memory requirements\")\n    print(\"  MemoryBudgetSelector()   - Automatic strategy selection\")\nif __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
