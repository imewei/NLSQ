{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Workflow Selection Deep Dive\n",
    "\n",
    "> Master the WorkflowSelector decision logic for optimal workflow configuration\n",
    "\n",
    "**25 minutes** | **Level: Advanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand the `WorkflowSelector` decision algorithm\n",
    "- Use `auto_select_workflow()` for automatic configuration\n",
    "- Interpret `DatasetSizeTier` and `MemoryTier` classifications\n",
    "- Query memory availability with `get_total_available_memory_gb()` and `get_memory_tier()`\n",
    "- Predict which workflow tier will be selected for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "**You are here:** Workflow System > **Auto Selection**\n",
    "\n",
    "```\n",
    "fit() Quickstart --> Workflow Tiers --> Optimization Goals --> [You are here: Auto Selection]\n",
    "```\n",
    "\n",
    "**Recommended flow:**\n",
    "- **Previous:** [02_workflow_tiers.ipynb](02_workflow_tiers.ipynb) - Understanding tiers\n",
    "- **Previous:** [03_optimization_goals.ipynb](03_optimization_goals.ipynb) - Goal-based configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "**Required knowledge:**\n",
    "- Familiarity with WorkflowTier (STANDARD, CHUNKED, STREAMING)\n",
    "- Understanding of OptimizationGoal (FAST, ROBUST, QUALITY)\n",
    "- Basic knowledge of memory constraints in curve fitting\n",
    "\n",
    "**Required software:**\n",
    "- NLSQ >= 0.3.4\n",
    "- Python >= 3.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Manual workflow selection requires understanding your dataset size, available memory,\n",
    "and optimization goals. The `WorkflowSelector` encapsulates this logic, providing:\n",
    "\n",
    "- **Automatic tier selection** based on a decision matrix\n",
    "- **Memory-aware configuration** that adapts to your system\n",
    "- **Goal-driven optimization** with appropriate tolerances\n",
    "- **Runtime adaptation** - memory is re-evaluated on each call\n",
    "\n",
    "Understanding how `WorkflowSelector` works helps you:\n",
    "- Debug unexpected tier selections\n",
    "- Override when automatic selection isn't optimal\n",
    "- Configure memory limits for reproducible behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Start (30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting (MUST come before imports)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlsq.workflow import auto_select_workflow, OptimizationGoal\n",
    "\n",
    "# Automatic workflow selection for a 5M point dataset\n",
    "config = auto_select_workflow(n_points=5_000_000, n_params=5)\n",
    "print(f\"Selected config: {type(config).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "from nlsq.workflow import (\n",
    "    WorkflowSelector,\n",
    "    WorkflowTier,\n",
    "    OptimizationGoal,\n",
    "    DatasetSizeTier,\n",
    "    MemoryTier,\n",
    "    auto_select_workflow,\n",
    "    calculate_adaptive_tolerances,\n",
    ")\n",
    "from nlsq.large_dataset import MemoryEstimator, GPUMemoryEstimator, get_memory_tier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Content\n",
    "\n",
    "### Section 1: The Selection Matrix\n",
    "\n",
    "The `WorkflowSelector` uses a decision matrix that maps (dataset_size, memory_tier, goal)\n",
    "to (workflow_tier, enable_multistart, enable_checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the selection matrix\n",
    "print(\"WorkflowSelector Decision Matrix\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Dataset Size    | Low (<16GB) | Medium (16-64GB) | High (64-128GB) | Very High (>128GB)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Small (<10K)    | standard    | standard         | standard        | standard+quality\")\n",
    "print(\"Medium (10K-1M) | chunked     | standard         | standard+ms     | standard+ms\")\n",
    "print(\"Large (1M-10M)  | streaming   | chunked          | chunked+ms      | chunked+ms\")\n",
    "print(\"Huge (10M-100M) | stream+ckpt | streaming        | chunked         | chunked+ms\")\n",
    "print(\"Massive (>100M) | stream+ckpt | streaming+ckpt   | streaming       | streaming+ms\")\n",
    "print()\n",
    "print(\"Legend:\")\n",
    "print(\"  ms = multi-start enabled\")\n",
    "print(\"  ckpt = checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Dataset Size Tiers\n",
    "\n",
    "`DatasetSizeTier` classifies datasets and recommends tolerances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all dataset size tiers\n",
    "print(\"DatasetSizeTier Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Tier':<12s} | {'Max Points':<15s} | {'Tolerance':<12s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for tier in DatasetSizeTier:\n",
    "    max_pts = tier.max_points\n",
    "    tol = tier.tolerance\n",
    "    \n",
    "    if max_pts == float(\"inf\"):\n",
    "        max_str = \"unlimited\"\n",
    "    elif max_pts >= 1_000_000:\n",
    "        max_str = f\"{max_pts/1_000_000:.0f}M\"\n",
    "    elif max_pts >= 1_000:\n",
    "        max_str = f\"{max_pts/1_000:.0f}K\"\n",
    "    else:\n",
    "        max_str = str(max_pts)\n",
    "    \n",
    "    print(f\"{tier.name:<12s} | {max_str:<15s} | {tol:.0e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate tier classification\n",
    "test_sizes = [500, 5_000, 50_000, 500_000, 5_000_000, 50_000_000, 500_000_000]\n",
    "\n",
    "print(\"\\nAutomatic Size Classification\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for n_points in test_sizes:\n",
    "    tier = DatasetSizeTier.from_n_points(n_points)\n",
    "    \n",
    "    if n_points >= 1_000_000:\n",
    "        size_str = f\"{n_points/1_000_000:.0f}M\"\n",
    "    elif n_points >= 1_000:\n",
    "        size_str = f\"{n_points/1_000:.0f}K\"\n",
    "    else:\n",
    "        size_str = str(n_points)\n",
    "    \n",
    "    print(f\"{size_str:>8s} points -> {tier.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Memory Tiers\n",
    "\n",
    "`MemoryTier` classifies available system memory to inform tier selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display memory tier thresholds\n",
    "print(\"MemoryTier Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Tier':<12s} | {'Max Memory':<12s} | {'Description'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for tier in MemoryTier:\n",
    "    max_mem = tier.max_memory_gb\n",
    "    desc = tier.description\n",
    "    \n",
    "    if max_mem == float(\"inf\"):\n",
    "        max_str = \"unlimited\"\n",
    "    else:\n",
    "        max_str = f\"{max_mem:.0f} GB\"\n",
    "    \n",
    "    print(f\"{tier.name:<12s} | {max_str:<12s} | {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current system memory\n",
    "cpu_memory = MemoryEstimator.get_available_memory_gb()\n",
    "total_memory = MemoryEstimator.get_total_available_memory_gb()\n",
    "current_tier = get_memory_tier(total_memory)\n",
    "\n",
    "print(\"Current System Memory\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"CPU available:   {cpu_memory:.1f} GB\")\n",
    "\n",
    "# Check for GPU memory\n",
    "gpu_estimator = GPUMemoryEstimator()\n",
    "if gpu_estimator.has_gpu():\n",
    "    gpu_memory = gpu_estimator.get_available_gpu_memory_gb()\n",
    "    print(f\"GPU available:   {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"GPU available:   N/A (CPU only)\")\n",
    "\n",
    "print(f\"Total available: {total_memory:.1f} GB\")\n",
    "print(f\"Memory tier:     {current_tier.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate memory tier classification\n",
    "test_memories = [8.0, 24.0, 48.0, 96.0, 256.0]\n",
    "\n",
    "print(\"\\nMemory Classification Examples\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for mem_gb in test_memories:\n",
    "    tier = MemoryTier.from_available_memory_gb(mem_gb)\n",
    "    print(f\"{mem_gb:>6.0f} GB -> {tier.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: WorkflowSelector in Action\n",
    "\n",
    "Let's see how `WorkflowSelector` makes decisions for various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a selector with current system memory\n",
    "selector = WorkflowSelector()\n",
    "\n",
    "print(f\"WorkflowSelector initialized (using system memory: {total_memory:.1f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different dataset sizes\n",
    "test_scenarios = [\n",
    "    (1_000, 3, None),\n",
    "    (100_000, 5, None),\n",
    "    (1_000_000, 5, OptimizationGoal.FAST),\n",
    "    (1_000_000, 5, OptimizationGoal.QUALITY),\n",
    "    (10_000_000, 5, OptimizationGoal.ROBUST),\n",
    "    (100_000_000, 5, OptimizationGoal.MEMORY_EFFICIENT),\n",
    "]\n",
    "\n",
    "print(\"WorkflowSelector Decisions\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'n_points':<12s} | {'n_params':<8s} | {'Goal':<18s} | {'Config Type'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for n_points, n_params, goal in test_scenarios:\n",
    "    config = selector.select(n_points, n_params, goal)\n",
    "    config_type = type(config).__name__\n",
    "    \n",
    "    if n_points >= 1_000_000:\n",
    "        size_str = f\"{n_points/1_000_000:.0f}M\"\n",
    "    elif n_points >= 1_000:\n",
    "        size_str = f\"{n_points/1_000:.0f}K\"\n",
    "    else:\n",
    "        size_str = str(n_points)\n",
    "    \n",
    "    goal_str = goal.name if goal else \"None (ROBUST)\"\n",
    "    \n",
    "    print(f\"{size_str:<12s} | {n_params:<8d} | {goal_str:<18s} | {config_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate with fixed memory limits\n",
    "print(\"\\nSelection with Different Memory Limits\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "memory_limits = [8.0, 32.0, 96.0, 256.0]  # GB\n",
    "n_points = 5_000_000  # 5M points\n",
    "n_params = 5\n",
    "\n",
    "for mem_limit in memory_limits:\n",
    "    selector_fixed = WorkflowSelector(memory_limit_gb=mem_limit)\n",
    "    config = selector_fixed.select(n_points, n_params)\n",
    "    config_type = type(config).__name__\n",
    "    mem_tier = MemoryTier.from_available_memory_gb(mem_limit)\n",
    "    \n",
    "    print(f\"Memory: {mem_limit:>6.0f} GB ({mem_tier.name:<10s}) -> {config_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: The auto_select_workflow() Convenience Function\n",
    "\n",
    "For simple use cases, `auto_select_workflow()` provides a clean interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage\n",
    "config1 = auto_select_workflow(n_points=5_000, n_params=5)\n",
    "print(f\"5K points: {type(config1).__name__}\")\n",
    "\n",
    "# With goal specification\n",
    "config2 = auto_select_workflow(\n",
    "    n_points=5_000_000,\n",
    "    n_params=5,\n",
    "    goal=OptimizationGoal.QUALITY,\n",
    ")\n",
    "print(f\"5M points + QUALITY: {type(config2).__name__}\")\n",
    "\n",
    "# With memory override\n",
    "config3 = auto_select_workflow(\n",
    "    n_points=5_000_000,\n",
    "    n_params=5,\n",
    "    memory_limit_gb=8.0,\n",
    ")\n",
    "print(f\"5M points + 8GB limit: {type(config3).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Adaptive Tolerances\n",
    "\n",
    "The selector also calculates adaptive tolerances based on dataset size and goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate adaptive tolerance calculation\n",
    "print(\"Adaptive Tolerance Calculation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_configs = [\n",
    "    (1_000, None),\n",
    "    (1_000_000, None),\n",
    "    (1_000_000, OptimizationGoal.FAST),\n",
    "    (1_000_000, OptimizationGoal.QUALITY),\n",
    "    (100_000_000, OptimizationGoal.ROBUST),\n",
    "]\n",
    "\n",
    "print(f\"{'n_points':<12s} | {'Goal':<12s} | {'gtol':<12s} | {'ftol':<12s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for n_points, goal in test_configs:\n",
    "    tolerances = calculate_adaptive_tolerances(n_points, goal)\n",
    "    \n",
    "    if n_points >= 1_000_000:\n",
    "        size_str = f\"{n_points/1_000_000:.0f}M\"\n",
    "    else:\n",
    "        size_str = f\"{n_points/1_000:.0f}K\"\n",
    "    \n",
    "    goal_str = goal.name if goal else \"None\"\n",
    "    \n",
    "    print(f\"{size_str:<12s} | {goal_str:<12s} | {tolerances['gtol']:.0e} | {tolerances['ftol']:.0e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7: Visualization of the Selection Algorithm\n",
    "\n",
    "Let's visualize the complete selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive visualization of the selection algorithm\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "ax.set_xlim(0, 16)\n",
    "ax.set_ylim(0, 14)\n",
    "ax.axis('off')\n",
    "\n",
    "# Title\n",
    "ax.text(8, 13.5, \"WorkflowSelector Decision Algorithm\", ha='center', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Step 1: Input\n",
    "ax.add_patch(plt.Rectangle((0.5, 11.5), 3, 1.2, fill=True, facecolor='lightblue', edgecolor='black', linewidth=2))\n",
    "ax.text(2, 12.1, \"INPUT\", ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax.text(2, 11.7, \"n_points, n_params, goal\", ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Arrow down\n",
    "ax.annotate('', xy=(2, 10.3), xytext=(2, 11.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Step 2: Get Memory\n",
    "ax.add_patch(plt.Rectangle((0.5, 9.3), 3, 1, fill=True, facecolor='lightyellow', edgecolor='black'))\n",
    "ax.text(2, 9.8, \"1. Get Memory\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "ax.text(2, 9.5, \"get_available_memory_gb()\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Arrow down\n",
    "ax.annotate('', xy=(2, 8.1), xytext=(2, 9.3),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Step 3: Classify Memory\n",
    "ax.add_patch(plt.Rectangle((0.5, 7.1), 3, 1, fill=True, facecolor='lightyellow', edgecolor='black'))\n",
    "ax.text(2, 7.6, \"2. Classify Memory\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "ax.text(2, 7.3, \"MemoryTier.from_...()\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Arrow down\n",
    "ax.annotate('', xy=(2, 5.9), xytext=(2, 7.1),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Step 4: Classify Dataset\n",
    "ax.add_patch(plt.Rectangle((0.5, 4.9), 3, 1, fill=True, facecolor='lightyellow', edgecolor='black'))\n",
    "ax.text(2, 5.4, \"3. Classify Dataset\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "ax.text(2, 5.1, \"DatasetSizeTier.from_...()\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Arrow down\n",
    "ax.annotate('', xy=(2, 3.7), xytext=(2, 4.9),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Step 5: Apply Matrix\n",
    "ax.add_patch(plt.Rectangle((0.5, 2.7), 3, 1, fill=True, facecolor='lightgreen', edgecolor='black', linewidth=2))\n",
    "ax.text(2, 3.2, \"4. Decision Matrix\", ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "ax.text(2, 2.9, \"tier, multistart, ckpt\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Arrow down\n",
    "ax.annotate('', xy=(2, 1.5), xytext=(2, 2.7),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Step 6: Output\n",
    "ax.add_patch(plt.Rectangle((0.5, 0.5), 3, 1, fill=True, facecolor='lightsalmon', edgecolor='black', linewidth=2))\n",
    "ax.text(2, 1, \"OUTPUT\", ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "ax.text(2, 0.7, \"ConfigType\", ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Memory Tier Reference (right side)\n",
    "ax.add_patch(plt.Rectangle((5, 8), 4.5, 4.5, fill=True, facecolor='white', edgecolor='black'))\n",
    "ax.text(7.25, 12, \"MemoryTier\", ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(5.2, 11.3, \"LOW: < 16 GB\", fontsize=9)\n",
    "ax.text(5.2, 10.6, \"MEDIUM: 16-64 GB\", fontsize=9)\n",
    "ax.text(5.2, 9.9, \"HIGH: 64-128 GB\", fontsize=9)\n",
    "ax.text(5.2, 9.2, \"VERY_HIGH: > 128 GB\", fontsize=9)\n",
    "ax.text(5.2, 8.4, f\"Current: {current_tier.name}\", fontsize=9, fontweight='bold', color='blue')\n",
    "\n",
    "# Dataset Size Reference\n",
    "ax.add_patch(plt.Rectangle((10, 8), 5.5, 4.5, fill=True, facecolor='white', edgecolor='black'))\n",
    "ax.text(12.75, 12, \"DatasetSizeTier\", ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(10.2, 11.3, \"TINY: < 1K (tol=1e-12)\", fontsize=9)\n",
    "ax.text(10.2, 10.7, \"SMALL: 1K-10K (tol=1e-10)\", fontsize=9)\n",
    "ax.text(10.2, 10.1, \"MEDIUM: 10K-100K (tol=1e-9)\", fontsize=9)\n",
    "ax.text(10.2, 9.5, \"LARGE: 100K-1M (tol=1e-8)\", fontsize=9)\n",
    "ax.text(10.2, 8.9, \"VERY_LARGE: 1M-10M (tol=1e-7)\", fontsize=9)\n",
    "ax.text(10.2, 8.3, \"HUGE/MASSIVE: >10M\", fontsize=9)\n",
    "\n",
    "# Config Types Reference\n",
    "ax.add_patch(plt.Rectangle((5, 0.5), 10.5, 3, fill=True, facecolor='white', edgecolor='black'))\n",
    "ax.text(10.25, 3, \"Output Config Types\", ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(5.2, 2.3, \"GlobalOptimizationConfig: STANDARD + multistart\", fontsize=9, color='green')\n",
    "ax.text(5.2, 1.7, \"LDMemoryConfig: STANDARD or CHUNKED\", fontsize=9, color='orange')\n",
    "ax.text(5.2, 1.1, \"HybridStreamingConfig: STREAMING or STREAMING_CHECKPOINT\", fontsize=9, color='red')\n",
    "\n",
    "# Goal modifiers\n",
    "ax.add_patch(plt.Rectangle((5, 4.5), 10.5, 3, fill=True, facecolor='lavender', edgecolor='black'))\n",
    "ax.text(10.25, 7, \"Goal Modifiers\", ha='center', fontsize=11, fontweight='bold')\n",
    "ax.text(5.2, 6.3, \"FAST: Disable multistart, looser tolerances\", fontsize=9)\n",
    "ax.text(5.2, 5.7, \"ROBUST/GLOBAL: Enable multistart (if memory allows)\", fontsize=9)\n",
    "ax.text(5.2, 5.1, \"QUALITY: Enable multistart + tighter tolerances\", fontsize=9)\n",
    "ax.text(5.2, 4.7, \"MEMORY_EFFICIENT: Force streaming/chunking\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/06_selection_algorithm.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "After completing this notebook, remember:\n",
    "\n",
    "1. **WorkflowSelector uses a decision matrix** that maps (dataset_size, memory_tier, goal) to (tier, multistart, checkpoints).\n",
    "\n",
    "2. **Memory is re-evaluated on each call** - no caching, ensuring accurate adaptation to current conditions.\n",
    "\n",
    "3. **Three tier classifications:**\n",
    "   - `DatasetSizeTier`: TINY, SMALL, MEDIUM, LARGE, VERY_LARGE, HUGE, MASSIVE\n",
    "   - `MemoryTier`: LOW, MEDIUM, HIGH, VERY_HIGH\n",
    "   - `WorkflowTier`: STANDARD, CHUNKED, STREAMING, STREAMING_CHECKPOINT\n",
    "\n",
    "4. **Three output config types:**\n",
    "   - `GlobalOptimizationConfig`: For STANDARD + multistart\n",
    "   - `LDMemoryConfig`: For STANDARD or CHUNKED\n",
    "   - `HybridStreamingConfig`: For STREAMING or STREAMING_CHECKPOINT\n",
    "\n",
    "5. **Use `auto_select_workflow()` for simple cases:**\n",
    "   ```python\n",
    "   config = auto_select_workflow(n_points=5_000_000, n_params=5)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Questions\n",
    "\n",
    "**Q: Why does the same code produce different configs on different machines?**\n",
    "\n",
    "A: Memory is detected at runtime. A machine with 32GB will get different tier selections than one with 128GB. Use `memory_limit_gb` parameter for reproducibility.\n",
    "\n",
    "**Q: How do I force a specific tier?**\n",
    "\n",
    "A: Either use `WorkflowConfig(tier=WorkflowTier.STREAMING)` or set a very low `memory_limit_gb` to force streaming.\n",
    "\n",
    "**Q: What if I disagree with the automatic selection?**\n",
    "\n",
    "A: The selector provides a sensible default. Override with explicit configuration when your domain knowledge suggests otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**Prerequisites:**\n",
    "- [02_workflow_tiers.ipynb](02_workflow_tiers.ipynb) - Tier fundamentals\n",
    "- [03_optimization_goals.ipynb](03_optimization_goals.ipynb) - Goal-based configuration\n",
    "\n",
    "**Further reading:**\n",
    "- [API Documentation: workflow module](https://nlsq.readthedocs.io/api/workflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Glossary\n",
    "\n",
    "**Decision Matrix:** A lookup table mapping input conditions to output configurations.\n",
    "\n",
    "**DatasetSizeTier:** Classification of dataset size with recommended tolerances.\n",
    "\n",
    "**MemoryTier:** Classification of available system memory (CPU + GPU).\n",
    "\n",
    "**WorkflowSelector:** Class that implements the automatic workflow selection algorithm.\n",
    "\n",
    "**auto_select_workflow:** Convenience function wrapping WorkflowSelector.select()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Key Functions:\")\n",
    "print(\"  auto_select_workflow(n_points, n_params, goal)\")\n",
    "print(\"  WorkflowSelector().select(n_points, n_params, goal)\")\n",
    "print(\"  DatasetSizeTier.from_n_points(n_points)\")\n",
    "print(\"  MemoryTier.from_available_memory_gb(memory_gb)\")\n",
    "print(\"  MemoryEstimator.get_total_available_memory_gb()\")\n",
    "print(\"  get_memory_tier(memory_gb)\")\n",
    "print()\n",
    "print(f\"Current System:\")\n",
    "print(f\"  Total memory: {total_memory:.1f} GB\")\n",
    "print(f\"  Memory tier: {current_tier.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
