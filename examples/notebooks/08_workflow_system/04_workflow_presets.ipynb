{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW_PRESETS Guide\n",
    "\n",
    "> Master named workflow configurations for rapid development\n",
    "\n",
    "**15 minutes** | **Level: Beginner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand all entries in the `WORKFLOW_PRESETS` dictionary\n",
    "- Use presets for common fitting scenarios\n",
    "- Inspect preset configurations\n",
    "- Customize presets as starting points for advanced use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learning Path\n",
    "\n",
    "**You are here:** Workflow System > **Workflow Presets**\n",
    "\n",
    "```\n",
    "fit() Quickstart --> Workflow Tiers --> Optimization Goals --> [You are here]\n",
    "```\n",
    "\n",
    "**Recommended flow:**\n",
    "- **Previous:** [03_optimization_goals.ipynb](03_optimization_goals.ipynb) - Goal-driven optimization\n",
    "- **Next:** [05_yaml_configuration.ipynb](05_yaml_configuration.ipynb) - File-based configuration\n",
    "\n",
    "**Alternative paths:**\n",
    "- Need global optimization? Go to [../07_global_optimization/](../07_global_optimization/)\n",
    "- Large dataset fitting? Go to [../06_large_datasets/](../06_large_datasets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "**Required knowledge:**\n",
    "- Basic Python and NumPy\n",
    "- Familiarity with `curve_fit()` or `fit()`\n",
    "\n",
    "**Required software:**\n",
    "- NLSQ >= 0.3.4\n",
    "- Python >= 3.12\n",
    "\n",
    "**First time with NLSQ?** Start here: [01_fit_quickstart.ipynb](01_fit_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Configuring optimization parameters can be complex. Presets provide:\n",
    "- **Quick starts**: Use well-tested configurations immediately\n",
    "- **Best practices**: Expert-tuned settings for common scenarios\n",
    "- **Consistency**: Reproducible configurations across projects\n",
    "- **Customization**: Modify presets to suit your specific needs\n",
    "\n",
    "**Common use cases:**\n",
    "- Quick exploratory analysis: `preset='fast'`\n",
    "- Publication-quality results: `preset='quality'`\n",
    "- Large dataset processing: `preset='large_robust'` or `preset='streaming'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Start (30 seconds)\n",
    "\n",
    "Use a preset in three lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting (MUST come before imports)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from nlsq import fit\n",
    "\n",
    "# Define model and data\n",
    "def model(x, a, b): return a * jnp.exp(-b * x)\n",
    "x = np.linspace(0, 5, 100)\n",
    "y = 2.5 * np.exp(-1.3 * x) + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Fit using the 'quality' preset\n",
    "popt, pcov = fit(model, x, y, p0=[1, 1], preset='quality')\n",
    "print(f\"Fitted: a={popt[0]:.3f}, b={popt[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from nlsq import fit, curve_fit\n",
    "from nlsq import WorkflowConfig, WORKFLOW_PRESETS\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorial Content\n",
    "\n",
    "### Section 1: Available Presets\n",
    "\n",
    "NLSQ provides 7 built-in workflow presets for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available presets\n",
    "print(\"Available WORKFLOW_PRESETS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for preset_name in WORKFLOW_PRESETS:\n",
    "    description = WORKFLOW_PRESETS[preset_name].get('description', 'No description')\n",
    "    print(f\"  {preset_name:<20} - {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Inspecting Presets\n",
    "\n",
    "You can inspect any preset to see its full configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the 'standard' preset\n",
    "print(\"'standard' preset configuration:\")\n",
    "print(\"-\" * 40)\n",
    "pprint(WORKFLOW_PRESETS['standard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the 'quality' preset\n",
    "print(\"'quality' preset configuration:\")\n",
    "print(\"-\" * 40)\n",
    "pprint(WORKFLOW_PRESETS['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the 'streaming' preset for large datasets\n",
    "print(\"'streaming' preset configuration:\")\n",
    "print(\"-\" * 40)\n",
    "pprint(WORKFLOW_PRESETS['streaming'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Preset Comparison Table\n",
    "\n",
    "Let's create a comprehensive comparison of all presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "print(\"Preset Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Preset':<18} {'Tier':<12} {'Goal':<16} {'Multistart':<12} {'n_starts':<10} {'gtol':<12}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for name, config in WORKFLOW_PRESETS.items():\n",
    "    tier = config.get('tier', 'STANDARD')\n",
    "    goal = config.get('goal', 'ROBUST')\n",
    "    multistart = config.get('enable_multistart', False)\n",
    "    n_starts = config.get('n_starts', 0)\n",
    "    gtol = config.get('gtol', 1e-8)\n",
    "    \n",
    "    multistart_str = 'Yes' if multistart else 'No'\n",
    "    \n",
    "    print(f\"{name:<18} {tier:<12} {goal:<16} {multistart_str:<12} {n_starts:<10} {gtol:<12.0e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Using Presets with fit()\n",
    "\n",
    "The simplest way to use a preset is with the `preset` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "def exponential_model(x, a, b, c):\n",
    "    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "n_samples = 500\n",
    "x_data = np.linspace(0, 5, n_samples)\n",
    "\n",
    "# True parameters\n",
    "true_a, true_b, true_c = 3.0, 1.2, 0.5\n",
    "y_true = true_a * np.exp(-true_b * x_data) + true_c\n",
    "noise = 0.15 * np.random.randn(n_samples)\n",
    "y_data = y_true + noise\n",
    "\n",
    "# Initial guess and bounds\n",
    "p0 = [1.0, 0.5, 0.0]\n",
    "bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n",
    "\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test different presets\n",
    "presets_to_test = ['fast', 'standard', 'quality']\n",
    "results = {}\n",
    "\n",
    "print(\"\\nTesting presets:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for preset_name in presets_to_test:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    popt, pcov = fit(\n",
    "        exponential_model,\n",
    "        x_data,\n",
    "        y_data,\n",
    "        p0=p0,\n",
    "        bounds=bounds,\n",
    "        preset=preset_name,\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Calculate SSR\n",
    "    y_pred = exponential_model(x_data, *popt)\n",
    "    ssr = float(jnp.sum((y_data - y_pred) ** 2))\n",
    "    \n",
    "    results[preset_name] = {\n",
    "        'popt': popt,\n",
    "        'ssr': ssr,\n",
    "        'time': elapsed,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{preset_name.upper()}:\")\n",
    "    print(f\"  Time:       {elapsed:.4f}s\")\n",
    "    print(f\"  SSR:        {ssr:.6f}\")\n",
    "    print(f\"  Parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Creating WorkflowConfig from Presets\n",
    "\n",
    "Use `WorkflowConfig.from_preset()` to create a configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config from preset\n",
    "config = WorkflowConfig.from_preset('quality')\n",
    "\n",
    "print(\"WorkflowConfig from 'quality' preset:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  tier:              {config.tier.name}\")\n",
    "print(f\"  goal:              {config.goal.name}\")\n",
    "print(f\"  enable_multistart: {config.enable_multistart}\")\n",
    "print(f\"  n_starts:          {config.n_starts}\")\n",
    "print(f\"  gtol:              {config.gtol}\")\n",
    "print(f\"  ftol:              {config.ftol}\")\n",
    "print(f\"  xtol:              {config.xtol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the preset origin\n",
    "print(f\"\\nPreset origin: '{config.preset}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Customizing Presets\n",
    "\n",
    "Start from a preset and override specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the 'quality' preset\n",
    "base_config = WorkflowConfig.from_preset('quality')\n",
    "\n",
    "# Override specific values\n",
    "custom_config = base_config.with_overrides(\n",
    "    n_starts=30,              # More starting points\n",
    "    sampler='sobol',          # Use Sobol sampling\n",
    "    gtol=1e-12,               # Tighter tolerance\n",
    ")\n",
    "\n",
    "print(\"Customized 'quality' preset:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  Original n_starts: {base_config.n_starts}\")\n",
    "print(f\"  Custom n_starts:   {custom_config.n_starts}\")\n",
    "print(f\"  Original sampler:  {base_config.sampler}\")\n",
    "print(f\"  Custom sampler:    {custom_config.sampler}\")\n",
    "print(f\"  Original gtol:     {base_config.gtol}\")\n",
    "print(f\"  Custom gtol:       {custom_config.gtol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large dataset config from 'streaming' preset\n",
    "streaming_config = WorkflowConfig.from_preset('streaming')\n",
    "\n",
    "# Customize for memory-constrained environment\n",
    "memory_config = streaming_config.with_overrides(\n",
    "    memory_limit_gb=4.0,\n",
    "    chunk_size=10000,\n",
    ")\n",
    "\n",
    "print(\"\\nMemory-optimized streaming config:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  tier:            {memory_config.tier.name}\")\n",
    "print(f\"  memory_limit_gb: {memory_config.memory_limit_gb}\")\n",
    "print(f\"  chunk_size:      {memory_config.chunk_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7: Preset Descriptions\n",
    "\n",
    "Each preset is designed for a specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed preset documentation\n",
    "preset_docs = {\n",
    "    'standard': {\n",
    "        'summary': 'Default curve_fit() behavior',\n",
    "        'best_for': 'Well-conditioned problems with good initial guesses',\n",
    "        'tradeoffs': 'Balanced speed/accuracy, no global search',\n",
    "    },\n",
    "    'quality': {\n",
    "        'summary': 'Highest precision fitting',\n",
    "        'best_for': 'Publication results, parameter uncertainty estimation',\n",
    "        'tradeoffs': 'Slower due to multi-start and tight tolerances',\n",
    "    },\n",
    "    'fast': {\n",
    "        'summary': 'Speed-optimized fitting',\n",
    "        'best_for': 'Exploratory analysis, development, quick iterations',\n",
    "        'tradeoffs': 'May converge to local minima',\n",
    "    },\n",
    "    'large_robust': {\n",
    "        'summary': 'Chunked processing with multi-start',\n",
    "        'best_for': 'Large datasets (1M-100M points) needing global search',\n",
    "        'tradeoffs': 'Memory-efficient but slower than standard',\n",
    "    },\n",
    "    'streaming': {\n",
    "        'summary': 'Streaming for huge datasets',\n",
    "        'best_for': 'Datasets that exceed available memory (100M+ points)',\n",
    "        'tradeoffs': 'No covariance matrix, approximate convergence',\n",
    "    },\n",
    "    'hpc_distributed': {\n",
    "        'summary': 'Multi-GPU/node HPC clusters',\n",
    "        'best_for': 'PBS Pro, Slurm clusters with checkpoint recovery',\n",
    "        'tradeoffs': 'Requires HPC environment setup',\n",
    "    },\n",
    "    'memory_efficient': {\n",
    "        'summary': 'Minimize memory footprint',\n",
    "        'best_for': 'Memory-constrained systems, edge devices',\n",
    "        'tradeoffs': 'Smaller chunk sizes = more overhead',\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Preset Use Case Guide:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, doc in preset_docs.items():\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Summary:    {doc['summary']}\")\n",
    "    print(f\"  Best for:   {doc['best_for']}\")\n",
    "    print(f\"  Tradeoffs:  {doc['tradeoffs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 8: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preset characteristics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "preset_names = list(results.keys())\n",
    "colors = {'fast': 'blue', 'standard': 'green', 'quality': 'red'}\n",
    "\n",
    "# SSR comparison\n",
    "ax1 = axes[0]\n",
    "ssrs = [results[p]['ssr'] for p in preset_names]\n",
    "bars = ax1.bar(preset_names, ssrs, color=[colors[p] for p in preset_names])\n",
    "ax1.set_xlabel('Preset')\n",
    "ax1.set_ylabel('Sum of Squared Residuals')\n",
    "ax1.set_title('Fit Quality by Preset')\n",
    "for bar, ssr in zip(bars, ssrs):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "             f\"{ssr:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Time comparison\n",
    "ax2 = axes[1]\n",
    "times = [results[p]['time'] for p in preset_names]\n",
    "bars = ax2.bar(preset_names, times, color=[colors[p] for p in preset_names])\n",
    "ax2.set_xlabel('Preset')\n",
    "ax2.set_ylabel('Time (seconds)')\n",
    "ax2.set_title('Computation Time by Preset')\n",
    "for bar, t in zip(bars, times):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "             f\"{t:.3f}s\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Tolerance comparison\n",
    "ax3 = axes[2]\n",
    "tols = [WORKFLOW_PRESETS[p]['gtol'] for p in preset_names]\n",
    "bars = ax3.bar(preset_names, tols, color=[colors[p] for p in preset_names])\n",
    "ax3.set_xlabel('Preset')\n",
    "ax3.set_ylabel('gtol')\n",
    "ax3.set_title('Tolerance (gtol) by Preset')\n",
    "ax3.set_yscale('log')\n",
    "for bar, t in zip(bars, tols):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "             f\"{t:.0e}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_preset_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "After completing this notebook, remember:\n",
    "\n",
    "1. **7 Built-in Presets:** `standard`, `quality`, `fast`, `large_robust`, `streaming`, `hpc_distributed`, `memory_efficient`\n",
    "\n",
    "2. **Using presets:** Simply pass `preset='name'` to `fit()` or use `WorkflowConfig.from_preset('name')`\n",
    "\n",
    "3. **Inspecting presets:** Access configuration via `WORKFLOW_PRESETS['name']` or `print(WORKFLOW_PRESETS[name])`\n",
    "\n",
    "4. **Customization:** Use `config.with_overrides(...)` to modify preset values while keeping the base configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Questions\n",
    "\n",
    "**Q: Which preset should I use for a standard fitting problem?**\n",
    "\n",
    "A: Start with `preset='standard'`. If you need better global search, try `preset='quality'`. For quick exploration, use `preset='fast'`.\n",
    "\n",
    "**Q: How do I know if I need 'large_robust' vs 'streaming'?**\n",
    "\n",
    "A: Use `'large_robust'` for datasets up to ~100M points that fit in memory (with chunking). Use `'streaming'` for truly massive datasets that cannot fit in memory at all.\n",
    "\n",
    "**Q: Can I create my own presets?**\n",
    "\n",
    "A: Yes! Create a `WorkflowConfig` with your desired settings and save it as a dictionary. You can also use YAML configuration files (see the next tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Related Resources\n",
    "\n",
    "**Next steps:**\n",
    "- [05_yaml_configuration.ipynb](05_yaml_configuration.ipynb) - File-based configuration\n",
    "- [../07_global_optimization/](../07_global_optimization/) - Global optimization details\n",
    "\n",
    "**Further reading:**\n",
    "- [API Documentation](https://nlsq.readthedocs.io/)\n",
    "- [GitHub Repository](https://github.com/imewei/NLSQ)\n",
    "\n",
    "**Need help?**\n",
    "- [Discussions](https://github.com/imewei/NLSQ/discussions)\n",
    "- [Report issues](https://github.com/imewei/NLSQ/issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Glossary\n",
    "\n",
    "**WORKFLOW_PRESETS:** Dictionary containing named workflow configurations.\n",
    "\n",
    "**WorkflowConfig:** Configuration dataclass for workflow settings.\n",
    "\n",
    "**Preset:** Pre-defined configuration optimized for a specific use case.\n",
    "\n",
    "**with_overrides():** Method to create a modified copy of a configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Available presets:\")\n",
    "for name in WORKFLOW_PRESETS:\n",
    "    desc = WORKFLOW_PRESETS[name].get('description', '')\n",
    "    print(f\"  - {name}: {desc}\")\n",
    "print()\n",
    "print(\"Quick usage:\")\n",
    "print(\"  fit(model, x, y, preset='quality')\")\n",
    "print(\"  WorkflowConfig.from_preset('quality')\")\n",
    "print(\"  config.with_overrides(n_starts=30)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
