{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Progress Callbacks for Optimization Monitoring> Monitor optimization progress with progress bars, logging, and early stopping‚è±Ô∏è **15-20 minutes** | üìä **Level: ‚óè‚óè‚óã Intermediate** | üè∑Ô∏è **Feature Demo**---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning ObjectivesAfter this tutorial, you'll be able to:1. Use `ProgressBar` for real-time optimization monitoring2. Log optimization history with `IterationLogger`3. Prevent wasted iterations with `EarlyStopping`4. Combine multiple callbacks using `CallbackChain`5. Create custom callbacks for specialized needs---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Feature Overview**What problem does this solve?**- Long-running fits can appear frozen without feedback- Debugging requires iteration-level details- Optimization may continue unnecessarily after convergence**Available callbacks:**- `ProgressBar`: tqdm-based progress tracking- `IterationLogger`: Detailed logging to file- `EarlyStopping`: Stop when no improvement detected- `CallbackChain`: Combine multiple callbacks- `CallbackBase`: Base class for custom callbacks---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import curve_fit\n",
    "from nlsq.callbacks import (\n",
    "    CallbackBase,\n",
    "    CallbackChain,\n",
    "    EarlyStopping,\n",
    "    IterationLogger,\n",
    "    ProgressBar,\n",
    ")\n",
    "\n",
    "\n",
    "def exponential_decay(x, amplitude, rate, offset):\n",
    "    return amplitude * jnp.exp(-rate * x) + offset\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y_true = 100 * np.exp(-0.5 * x) + 10\n",
    "y = y_true + np.random.normal(0, 3, size=len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Progress BarMonitor optimization progress with a visual progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create progress bar callback\n",
    "callback = ProgressBar(max_nfev=50, desc=\"Fitting exponential\")\n",
    "\n",
    "# Fit with progress bar\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=[80, 0.4, 5],\n",
    "    callback=callback,\n",
    "    max_nfev=50)\n",
    "\n",
    "callback.close()\n",
    "\n",
    "print(f'‚úì Fitted: amplitude={popt[0]:.2f}, rate={popt[1]:.3f}, offset={popt[2]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Iteration LoggingLog detailed optimization progress to a file for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logging callback\n",
    "callback = IterationLogger(\n",
    "    filename='optimization.log',\n",
    "    mode='w',\n",
    "    log_params=True  # Include parameter values\n",
    ")\n",
    "\n",
    "# Fit with logging\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=[80, 0.4, 5],\n",
    "    callback=callback,\n",
    "    max_nfev=50)\n",
    "\n",
    "callback.close()\n",
    "\n",
    "print('‚úì Log written to optimization.log')\n",
    "print('First few lines:')\n",
    "with open('optimization.log') as f:\n",
    "    print(''.join(f.readlines()[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Early StoppingPrevent wasted iterations by stopping when optimization stalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create early stopping callback\n",
    "callback = EarlyStopping(\n",
    "    patience=10,       # Stop after 10 iterations without improvement\n",
    "    min_delta=1e-6,    # Minimum improvement threshold\n",
    "    verbose=True)\n",
    "\n",
    "# Fit with early stopping\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=[80, 0.4, 5],\n",
    "    callback=callback,\n",
    "    max_nfev=1000  # Set high, early stopping prevents waste\n",
    ")\n",
    "\n",
    "print(f'‚úì Fitted: amplitude={popt[0]:.2f}, rate={popt[1]:.3f}, offset={popt[2]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Combining Multiple CallbacksUse `CallbackChain` to combine progress bar, logging, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple callbacks\n",
    "callback = CallbackChain(\n",
    "    ProgressBar(max_nfev=50, desc=\"Optimizing\"),\n",
    "    IterationLogger('combined.log', log_params=False),\n",
    "    EarlyStopping(patience=10, verbose=False))\n",
    "\n",
    "# Fit with callback chain\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=[80, 0.4, 5],\n",
    "    callback=callback,\n",
    "    max_nfev=50)\n",
    "\n",
    "callback.close()\n",
    "\n",
    "print('‚úì All callbacks executed!')\n",
    "print('Check combined.log for iteration history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Custom CallbackCreate specialized callbacks by subclassing `CallbackBase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestParameterTracker(CallbackBase):\n",
    "    \"\"\"Custom callback to track best parameters.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.best_cost = np.inf\n",
    "        self.best_params = None\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, iteration, cost, params, info):\n",
    "        \"\"\"Track best parameters.\"\"\"\n",
    "        self.history.append({'iter': iteration, 'cost': cost})\n",
    "\n",
    "        if cost < self.best_cost:\n",
    "            self.best_cost = cost\n",
    "            self.best_params = params.copy()\n",
    "            print(f'  ‚Üí New best at iter {iteration}: cost={cost:.6f}')\n",
    "\n",
    "    def get_best(self):\n",
    "        return self.best_params, self.best_cost\n",
    "\n",
    "# Use custom callback\n",
    "tracker = BestParameterTracker()\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=[80, 0.4, 5],\n",
    "    callback=tracker,\n",
    "    max_nfev=50)\n",
    "\n",
    "best_params, best_cost = tracker.get_best()\n",
    "print(f'\\n‚úì Best cost: {best_cost:.6f}')\n",
    "print(f'‚úì Final params match best: {np.allclose(popt, best_params)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fit = exponential_decay(x, *popt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, y, 'o', alpha=0.3, label='Data')\n",
    "plt.plot(x, y_true, 'g--', label='True')\n",
    "plt.plot(x, y_fit, 'r-', linewidth=2, label='Fitted')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Exponential Decay Fit')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, y - y_fit, '.')\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Fit Quality')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Key Insights1. **Progress bars** provide real-time feedback for long-running fits2. **Iteration logging** enables detailed post-analysis and debugging3. **Early stopping** saves computation when optimization stalls4. **Callback chains** combine multiple monitoring strategies5. **Custom callbacks** enable specialized monitoring for your use case---## üìö Best Practices- Use `ProgressBar` for interactive work (notebooks, scripts)- Use `IterationLogger` for production/automated workflows- Set `patience` in `EarlyStopping` based on problem complexity- Combine callbacks with `CallbackChain` for comprehensive monitoring- Extend `CallbackBase` for custom visualization or metrics---## üéì Next Steps- Try callbacks on your own optimization problems- Create custom callbacks for domain-specific metrics- Explore callback integration with logging frameworks- Use callbacks to implement adaptive optimization strategies---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
