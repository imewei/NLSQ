{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Enhanced Error Messages in NLSQ> Intelligent, actionable error messages for faster debuggingâ±ï¸ **10-15 minutes** | ğŸ“Š **Level: â—â—‹â—‹ Beginner** | ğŸ·ï¸ **Feature Demo**---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Learning ObjectivesAfter this tutorial, you'll be able to:1. Understand NLSQ's enhanced error diagnostics2. Use error recommendations to fix optimization failures3. Implement programmatic error handling4. Appreciate the improvement over generic error messages---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Feature Overview**What problem does this solve?**Traditional optimization libraries give cryptic errors:```RuntimeError: Optimal parameters not found:CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH```NLSQ provides:- Clear failure reasons in plain English- Specific, actionable recommendations- Detailed diagnostic information- Programmatic error handling capabilities---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import curve_fit\n",
    "from nlsq.error_messages import OptimizationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Maximum Iterations ReachedSee how NLSQ explains common failures with actionable advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential(x, a, b):\n",
    "    return a * jnp.exp(-b * x)\n",
    "\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(0, 5, 50)\n",
    "y = 3 * np.exp(-0.5 * x) + np.random.normal(0, 0.1, 50)\n",
    "\n",
    "try:\n",
    "    # Force failure with very low max_nfev\n",
    "    popt, pcov = curve_fit(exponential, x, y, p0=[1, 1], max_nfev=3)\n",
    "except OptimizationError as e:\n",
    "    print('âŒ Optimization Failed!')\n",
    "    print(f'\\n{e}')\n",
    "    print('\\nğŸ“Š Diagnostic Details:')\n",
    "    for key, value in e.diagnostics.items():\n",
    "        print(f'  â€¢ {key}: {value}')\n",
    "    print('\\nğŸ’¡ Recommendations:')\n",
    "    for i, rec in enumerate(e.recommendations, 1):\n",
    "        print(f'  {i}. {rec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Applying RecommendationsShow how following recommendations leads to success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential(x, a, b):\n",
    "    return a * jnp.exp(-b * x)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 5, 50)\n",
    "y = 3 * np.exp(-0.5 * x) + np.random.normal(0, 0.1, 50)\n",
    "\n",
    "# First attempt: fails\n",
    "print('ğŸ”´ First attempt (max_nfev=3):')\n",
    "try:\n",
    "    popt, pcov = curve_fit(exponential, x, y, p0=[1, 1], max_nfev=3)\n",
    "    print('  âœ… Succeeded (unexpected)')\n",
    "except OptimizationError as e:\n",
    "    print(f'  âŒ Failed: {e.reasons[0] if e.reasons else \"Unknown\"}')\n",
    "    print(f'  ğŸ’¡ Recommendation: {e.recommendations[0] if e.recommendations else \"Increase max_nfev\"}')\n",
    "\n",
    "# Second attempt: apply recommendation\n",
    "print('\\nğŸŸ¢ Second attempt (max_nfev=100):')\n",
    "try:\n",
    "    popt, pcov = curve_fit(exponential, x, y, p0=[1, 1], max_nfev=100)\n",
    "    print(f'  âœ… Success! Fitted: a={popt[0]:.3f}, b={popt[1]:.3f}')\n",
    "    print('  ğŸ“ˆ True parameters: a=3.000, b=0.500')\n",
    "except OptimizationError as e:\n",
    "    print(f'  âŒ Still failed: {e.reasons[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Programmatic Error HandlingUse error diagnostics to implement automatic retry strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, amp, mu, sigma):\n",
    "    return amp * jnp.exp(-((x - mu)**2) / (2*sigma**2))\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = 2 * np.exp(-((x - 1)**2) / (2*0.5**2))\n",
    "\n",
    "try:\n",
    "    popt, pcov = curve_fit(gaussian, x, y, p0=[1, 0, 1], max_nfev=2)\n",
    "except OptimizationError as e:\n",
    "    print('ğŸ“Š Analyzing Error Diagnostics:')\n",
    "    print(f'  â€¢ Number of reasons: {len(e.reasons)}')\n",
    "    print(f'  â€¢ Number of recommendations: {len(e.recommendations)}')\n",
    "\n",
    "    # Programmatic decision making\n",
    "    if any('maximum' in r.lower() for r in e.reasons):\n",
    "        print('\\nğŸ”§ Auto-fix strategy: Increase max_nfev')\n",
    "        try:\n",
    "            popt, pcov = curve_fit(gaussian, x, y, p0=[1, 0, 1], max_nfev=200)\n",
    "            print('  âœ… Auto-retry succeeded!')\n",
    "            print(f'     Fitted: amp={popt[0]:.2f}, mu={popt[1]:.2f}, sigma={popt[2]:.2f}')\n",
    "        except OptimizationError:\n",
    "            print('  âŒ Auto-retry failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Before vs After ComparisonSee the dramatic improvement in error message quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difficult(x, a, b, c):\n",
    "    return a * jnp.sin(b * x) * jnp.exp(-c * x)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = 2 * np.sin(3 * x) * np.exp(-0.5 * x)\n",
    "\n",
    "print('ğŸ”´ OLD ERROR (before enhancement):')\n",
    "print('  \"RuntimeError: Optimal parameters not found:')\n",
    "print('   CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\"')\n",
    "print('\\n  ğŸ˜• Not helpful! What should I do?')\n",
    "\n",
    "print('\\nğŸŸ¢ NEW ERROR (with enhancement):')\n",
    "try:\n",
    "    popt, pcov = curve_fit(difficult, x, y, p0=[1, 1, 1], max_nfev=3)\n",
    "except OptimizationError as e:\n",
    "    print(f'\\n{e}')\n",
    "\n",
    "print('\\n  âœ… Much better! Clear diagnostics and actionable steps!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Key Insights1. **Enhanced errors** provide clear explanations instead of cryptic codes2. **Diagnostics** give detailed information about what went wrong3. **Recommendations** are specific and actionable4. **Programmatic access** enables automatic error recovery5. **Much faster debugging** compared to traditional error messages---## ğŸ“š Error Types DetectedNLSQ provides enhanced messages for:- Maximum iterations/evaluations reached- Convergence failures- Numerical instabilities- Invalid initial parameters- Singular covariance matrices- And more...---## ğŸ“ Best Practices- Always catch `OptimizationError` for robust code- Use `e.diagnostics` for detailed troubleshooting- Implement retry logic using `e.recommendations`- Log error details for debugging production issues- Share error messages when asking for help (they're now useful!)---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
