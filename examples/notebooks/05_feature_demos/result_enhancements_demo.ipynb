{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Demo: Enhanced Result Objects with Statistical Analysis\n",
        "\n",
        "This example demonstrates how to use NLSQ's enhanced CurveFitResult class\n",
        "to access statistical properties, confidence intervals, and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\nimport numpy as np\n\nfrom nlsq import curve_fit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Basic Statistical Properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example1_statistical_properties():\n    \"\"\"Demonstrate basic statistical properties of curve fit result.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 1: Statistical Properties\")\n    print(\"=\" * 70)\n\n    # Define exponential decay model\n    def exponential(x, a, b, c):\n        return a * jnp.exp(-b * x) + c\n\n    # Generate sample data\n    np.random.seed(42)\n    x = np.linspace(0, 10, 100)\n    y_true = 10 * np.exp(-0.5 * x) + 2\n    y = y_true + np.random.normal(0, 0.5, size=len(x))\n\n    # Fit model\n    result = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n\n    # Access statistical properties\n    print(\"\\nFitted parameters:\")\n    print(f\"  a = {result.popt[0]:.4f}\")\n    print(f\"  b = {result.popt[1]:.4f}\")\n    print(f\"  c = {result.popt[2]:.4f}\")\n\n    print(\"\\nGoodness of fit:\")\n    print(f\"  R² = {result.r_squared:.6f}\")\n    print(f\"  Adjusted R² = {result.adj_r_squared:.6f}\")\n    print(f\"  RMSE = {result.rmse:.6f}\")\n    print(f\"  MAE = {result.mae:.6f}\")\n\n    print(\"\\nModel selection criteria:\")\n    print(f\"  AIC = {result.aic:.2f}\")\n    print(f\"  BIC = {result.bic:.2f}\")\n\n    print(\"\\n✓ Statistical properties accessed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Backward Compatibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example2_backward_compatibility():\n    \"\"\"Demonstrate backward compatibility with tuple unpacking.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 2: Backward Compatibility\")\n    print(\"=\" * 70)\n\n    def linear(x, a, b):\n        return a * x + b\n\n    np.random.seed(42)\n    x = np.linspace(0, 10, 50)\n    y = 2 * x + 1 + np.random.normal(0, 0.5, size=len(x))\n\n    # Pattern 1: Traditional tuple unpacking (backward compatible)\n    popt, pcov = curve_fit(linear, x, y, p0=[1, 1])\n    print(\"\\nPattern 1 (tuple unpacking):\")\n    print(f\"  popt = {popt}\")\n    print(f\"  pcov shape = {pcov.shape}\")\n\n    # Pattern 2: Enhanced result object\n    result = curve_fit(linear, x, y, p0=[1, 1])\n    print(\"\\nPattern 2 (enhanced result):\")\n    print(f\"  result.popt = {result.popt}\")\n    print(f\"  result.r_squared = {result.r_squared:.6f}\")\n\n    # Pattern 3: Can still unpack enhanced result\n    popt2, pcov2 = result\n    print(\"\\nPattern 3 (unpack enhanced result):\")\n    print(f\"  popt = {popt2}\")\n    print(f\"  Same as Pattern 1? {np.allclose(popt, popt2)}\")\n\n    print(\"\\n✓ All usage patterns work seamlessly!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Confidence Intervals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example3_confidence_intervals():\n    \"\"\"Demonstrate parameter confidence intervals.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 3: Confidence Intervals\")\n    print(\"=\" * 70)\n\n    def power_law(x, a, b):\n        return a * x**b\n\n    np.random.seed(42)\n    x = np.linspace(1, 10, 50)\n    y = 2 * x**1.5 + np.random.normal(0, 2, size=len(x))\n\n    # Fit model\n    result = curve_fit(power_law, x, y, p0=[2, 1.5])\n\n    # Get confidence intervals\n    ci_95 = result.confidence_intervals(alpha=0.95)\n    ci_99 = result.confidence_intervals(alpha=0.99)\n\n    print(\"\\nFitted parameters with confidence intervals:\")\n    print(\"\\nParameter    Value       95% CI                    99% CI\")\n    print(\"-\" * 70)\n    for i, (val, ci95, ci99) in enumerate(zip(result.popt, ci_95, ci_99, strict=False)):\n        print(\n            f\"p{i:<11} {val:>8.4f}    [{ci95[0]:>7.4f}, {ci95[1]:>7.4f}]    \"\n            f\"[{ci99[0]:>7.4f}, {ci99[1]:>7.4f}]\"\n        )\n\n    print(\"\\n✓ Confidence intervals computed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Prediction Intervals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example4_prediction_intervals():\n    \"\"\"Demonstrate prediction intervals.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 4: Prediction Intervals\")\n    print(\"=\" * 70)\n\n    def quadratic(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    np.random.seed(42)\n    x = np.linspace(0, 5, 30)\n    y = 0.5 * x**2 - 2 * x + 1 + np.random.normal(0, 0.3, size=len(x))\n\n    # Fit model\n    result = curve_fit(quadratic, x, y, p0=[1, -2, 1])\n\n    # Get prediction intervals at fitted x values\n    pi = result.prediction_interval()\n\n    print(\"\\nPrediction intervals at first 5 data points:\")\n    print(\"\\n  x       y_data    y_pred    Lower     Upper\")\n    print(\"  \" + \"-\" * 50)\n    for i in range(5):\n        print(\n            f\"  {x[i]:.2f}    {y[i]:>6.3f}    {result.predictions[i]:>6.3f}    \"\n            f\"{pi[i, 0]:>6.3f}    {pi[i, 1]:>6.3f}\"\n        )\n\n    # Get prediction intervals at new x values\n    x_new = np.array([1.5, 3.0, 4.5])\n    pi_new = result.prediction_interval(x=x_new)\n\n    print(\"\\nPrediction intervals at new x values:\")\n    print(\"\\n  x_new    y_pred    Lower     Upper    Width\")\n    print(\"  \" + \"-\" * 50)\n    for i, x_val in enumerate(x_new):\n        width = pi_new[i, 1] - pi_new[i, 0]\n        y_pred = result.model(x_val, *result.popt)\n        print(\n            f\"  {x_val:.2f}     {y_pred:>6.3f}    {pi_new[i, 0]:>6.3f}    \"\n            f\"{pi_new[i, 1]:>6.3f}    {width:>6.3f}\"\n        )\n\n    print(\"\\n✓ Prediction intervals computed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 5: Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example5_visualization():\n    \"\"\"Demonstrate built-in plotting functionality.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 5: Visualization\")\n    print(\"=\" * 70)\n\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        print(\"\\n⚠ matplotlib not installed - skipping visualization example\")\n        return\n\n    def gaussian(x, a, mu, sigma):\n        return a * jnp.exp(-((x - mu) ** 2) / (2 * sigma**2))\n\n    np.random.seed(42)\n    x = np.linspace(-5, 5, 100)\n    y = 10 * np.exp(-((x - 1) ** 2) / (2 * 1.5**2)) + np.random.normal(\n        0, 0.5, size=len(x)\n    )\n\n    # Fit model\n    result = curve_fit(gaussian, x, y, p0=[10, 1, 1.5])\n\n    # Plot with residuals\n    print(\"\\nGenerating plot with residuals...\")\n    result.plot(show_residuals=True)\n    plt.savefig(\"curve_fit_result.png\", dpi=150, bbox_inches=\"tight\")\n    print(\"  ✓ Plot saved to 'curve_fit_result.png'\")\n\n    # Plot without residuals\n    print(\"\\nGenerating plot without residuals...\")\n    fig, ax = plt.subplots(figsize=(8, 6))\n    result.plot(ax=ax, show_residuals=False, color=\"blue\", alpha=0.5)\n    plt.savefig(\"curve_fit_result_no_residuals.png\", dpi=150, bbox_inches=\"tight\")\n    print(\"  ✓ Plot saved to 'curve_fit_result_no_residuals.png'\")\n\n    plt.close(\"all\")\n    print(\"\\n✓ Visualization completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 6: Summary Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example6_summary_report():\n    \"\"\"Demonstrate statistical summary report.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 6: Summary Report\")\n    print(\"=\" * 70)\n\n    def exponential(x, a, b, c):\n        return a * jnp.exp(-b * x) + c\n\n    np.random.seed(42)\n    x = np.linspace(0, 10, 100)\n    y_true = 10 * np.exp(-0.5 * x) + 2\n    y = y_true + np.random.normal(0, 0.5, size=len(x))\n\n    # Fit model\n    result = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n\n    # Print summary\n    print(\"\\nGenerating statistical summary report...\\n\")\n    result.summary()\n\n    print(\"\\n✓ Summary report generated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 7: Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example7_model_comparison():\n    \"\"\"Demonstrate comparing multiple models using AIC/BIC.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 7: Model Comparison\")\n    print(\"=\" * 70)\n\n    # Generate data with exponential decay\n    np.random.seed(42)\n    x = np.linspace(0, 10, 100)\n    y_true = 10 * np.exp(-0.5 * x) + 2\n    y = y_true + np.random.normal(0, 0.5, size=len(x))\n\n    # Model 1: Exponential (correct model)\n    def exponential(x, a, b, c):\n        return a * jnp.exp(-b * x) + c\n\n    # Model 2: Linear (wrong model)\n    def linear(x, a, b):\n        return a * x + b\n\n    # Model 3: Quadratic (overfitted)\n    def quadratic(x, a, b, c):\n        return a * x**2 + b * x + c\n\n    # Fit all models\n    result_exp = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n    result_lin = curve_fit(linear, x, y, p0=[-1, 10])\n    result_quad = curve_fit(quadratic, x, y, p0=[0, -1, 10])\n\n    # Compare models\n    print(\"\\nModel Comparison:\")\n    print(\n        f\"\\n{'Model':<15} {'Params':<8} {'R²':<10} {'RMSE':<10} {'AIC':<10} {'BIC':<10}\"\n    )\n    print(\"-\" * 70)\n\n    models = [\n        (\"Exponential\", result_exp),\n        (\"Linear\", result_lin),\n        (\"Quadratic\", result_quad),\n    ]\n\n    for name, res in models:\n        print(\n            f\"{name:<15} {len(res.popt):<8} {res.r_squared:<10.6f} \"\n            f\"{res.rmse:<10.6f} {res.aic:<10.2f} {res.bic:<10.2f}\"\n        )\n\n    print(\"\\nBest model (lowest AIC): \", end=\"\")\n    best_idx = np.argmin([r.aic for _, r in models])\n    print(f\"{models[best_idx][0]}\")\n\n    print(\"\\n✓ Model comparison completed!\")\n    print(\"✓ Exponential model has the lowest AIC/BIC (correct model)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 8: Accessing Residuals and Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def example8_residuals_predictions():\n    \"\"\"Demonstrate accessing residuals and predictions.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Example 8: Residuals and Predictions\")\n    print(\"=\" * 70)\n\n    def sine_wave(x, a, f, phi):\n        return a * jnp.sin(2 * jnp.pi * f * x + phi)\n\n    np.random.seed(42)\n    x = np.linspace(0, 2, 50)\n    y = 3 * np.sin(2 * np.pi * 2 * x + 0.5) + np.random.normal(0, 0.3, size=len(x))\n\n    # Fit model\n    result = curve_fit(sine_wave, x, y, p0=[3, 2, 0.5])\n\n    # Access residuals\n    residuals = result.residuals\n    print(\"\\nResiduals:\")\n    print(f\"  Mean: {np.mean(residuals):.6f} (should be ~0)\")\n    print(f\"  Std:  {np.std(residuals):.6f}\")\n    print(f\"  Min:  {np.min(residuals):.6f}\")\n    print(f\"  Max:  {np.max(residuals):.6f}\")\n\n    # Access predictions\n    predictions = result.predictions\n    print(\"\\nPredictions:\")\n    print(f\"  Shape: {predictions.shape}\")\n    print(f\"  Correlation with data: {np.corrcoef(predictions, y)[0, 1]:.6f}\")\n\n    # Verify residuals = data - predictions\n    manual_residuals = y - predictions\n    print(\"\\nVerification:\")\n    print(\n        f\"  Residuals match (data - predictions)? \"\n        f\"{np.allclose(residuals, manual_residuals)}\"\n    )\n\n    print(\"\\n✓ Residuals and predictions accessed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Demo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n    \"\"\"Run all result enhancement examples.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"NLSQ Result Object Enhancements Demo\")\n    print(\"=\" * 70)\n    print(\"\\nDemonstrating enhanced CurveFitResult with statistical analysis,\")\n    print(\"confidence intervals, and visualization capabilities.\\n\")\n\n    # Run examples\n    example1_statistical_properties()\n    example2_backward_compatibility()\n    example3_confidence_intervals()\n    example4_prediction_intervals()\n    example5_visualization()\n    example6_summary_report()\n    example7_model_comparison()\n    example8_residuals_predictions()\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"Demo Complete!\")\n    print(\"=\" * 70)\n    print(\"\\nKey Features:\")\n    print(\"  • Statistical properties: R², RMSE, MAE, AIC, BIC\")\n    print(\"  • Confidence intervals: Parameter uncertainty quantification\")\n    print(\"  • Prediction intervals: Future data point uncertainty\")\n    print(\"  • Visualization: Built-in plot() method with residuals\")\n    print(\"  • Summary reports: Comprehensive fit statistics\")\n    print(\"  • Model comparison: AIC/BIC for selecting best model\")\n    print(\"  • Backward compatible: Supports tuple unpacking\")\n    print(\"\\nUsage:\")\n    print(\"  # Traditional usage (still works)\")\n    print(\"  popt, pcov = curve_fit(f, x, y)\")\n    print()\n    print(\"  # Enhanced usage\")\n    print(\"  result = curve_fit(f, x, y)\")\n    print(\"  print(f'R² = {result.r_squared:.4f}')\")\n    print(\"  result.plot()\")\n    print(\"  result.summary()\")\n    print(\"=\" * 70 + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}