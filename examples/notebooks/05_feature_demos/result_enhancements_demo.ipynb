{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Enhanced Result Objects with Statistical Analysis> Access R¬≤, confidence intervals, and visualization with enhanced CurveFitResult‚è±Ô∏è **20-25 minutes** | üìä **Level: ‚óè‚óè‚óã Intermediate** | üè∑Ô∏è **Feature Demo**---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning ObjectivesAfter this tutorial, you'll be able to:1. Access statistical properties (R¬≤, RMSE, MAE, AIC, BIC)2. Compute confidence and prediction intervals3. Use backward-compatible result objects4. Generate summary reports and visualizations5. Compare multiple models systematically---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Feature Overview**What problem does this solve?**- Manual calculation of goodness-of-fit metrics is tedious- Confidence intervals require complex statistical code- Model comparison lacks standardized metrics- Visualization requires repetitive plotting code**Enhanced CurveFitResult provides:**- Statistical properties: R¬≤, RMSE, MAE, AIC, BIC- Confidence/prediction intervals- Built-in visualization with residual plots- Summary reports- Full backward compatibility with tuple unpacking---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:16.436159Z",
     "iopub.status.busy": "2025-11-18T22:10:16.435884Z",
     "iopub.status.idle": "2025-11-18T22:10:16.700152Z",
     "shell.execute_reply": "2025-11-18T22:10:16.699300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:16.702604Z",
     "iopub.status.busy": "2025-11-18T22:10:16.702418Z",
     "iopub.status.idle": "2025-11-18T22:10:19.114544Z",
     "shell.execute_reply": "2025-11-18T22:10:19.113462Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nlsq import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Statistical PropertiesAccess common goodness-of-fit metrics directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:19.116675Z",
     "iopub.status.busy": "2025-11-18T22:10:19.116347Z",
     "iopub.status.idle": "2025-11-18T22:10:20.717322Z",
     "shell.execute_reply": "2025-11-18T22:10:20.716418Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential(x, a, b, c):\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y_true = 10 * np.exp(-0.5 * x) + 2\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n",
    "\n",
    "print('Fitted parameters:')\n",
    "print(f'  a = {result.popt[0]:.4f}')\n",
    "print(f'  b = {result.popt[1]:.4f}')\n",
    "print(f'  c = {result.popt[2]:.4f}')\n",
    "\n",
    "print('\\nGoodness of fit:')\n",
    "print(f'  R¬≤ = {result.r_squared:.6f}')\n",
    "print(f'  Adjusted R¬≤ = {result.adj_r_squared:.6f}')\n",
    "print(f'  RMSE = {result.rmse:.6f}')\n",
    "print(f'  MAE = {result.mae:.6f}')\n",
    "\n",
    "print('\\nModel selection criteria:')\n",
    "print(f'  AIC = {result.aic:.2f}')\n",
    "print(f'  BIC = {result.bic:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Backward CompatibilityResult objects support both modern and traditional usage patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:20.719093Z",
     "iopub.status.busy": "2025-11-18T22:10:20.718935Z",
     "iopub.status.idle": "2025-11-18T22:10:22.215018Z",
     "shell.execute_reply": "2025-11-18T22:10:22.214169Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 50)\n",
    "y = 2 * x + 1 + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Pattern 1: Traditional tuple unpacking (backward compatible)\n",
    "popt, pcov = curve_fit(linear, x, y, p0=[1, 1])\n",
    "print('Pattern 1 (tuple unpacking):')\n",
    "print(f'  popt = {popt}')\n",
    "\n",
    "# Pattern 2: Enhanced result object\n",
    "result = curve_fit(linear, x, y, p0=[1, 1])\n",
    "print('\\nPattern 2 (enhanced result):')\n",
    "print(f'  result.popt = {result.popt}')\n",
    "print(f'  result.r_squared = {result.r_squared:.6f}')\n",
    "\n",
    "# Pattern 3: Unpack enhanced result\n",
    "popt2, pcov2 = result\n",
    "print('\\nPattern 3 (unpack enhanced result):')\n",
    "print(f'  popt = {popt2}')\n",
    "print(f'  Same as Pattern 1? {np.allclose(popt, popt2)}')\n",
    "\n",
    "print('\\n‚úì All usage patterns work seamlessly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Confidence IntervalsQuantify parameter uncertainty with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:22.216846Z",
     "iopub.status.busy": "2025-11-18T22:10:22.216601Z",
     "iopub.status.idle": "2025-11-18T22:10:23.099416Z",
     "shell.execute_reply": "2025-11-18T22:10:23.098236Z"
    }
   },
   "outputs": [],
   "source": [
    "def power_law(x, a, b):\n",
    "    return a * x**b\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(1, 10, 50)\n",
    "y = 2 * x**1.5 + np.random.normal(0, 2, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(power_law, x, y, p0=[2, 1.5])\n",
    "\n",
    "# Get confidence intervals\n",
    "ci_95 = result.confidence_intervals(alpha=0.95)\n",
    "ci_99 = result.confidence_intervals(alpha=0.99)\n",
    "\n",
    "print('Fitted parameters with confidence intervals:')\n",
    "print('\\nParameter    Value       95% CI                    99% CI')\n",
    "print('-' * 70)\n",
    "for i, (val, ci95, ci99) in enumerate(zip(result.popt, ci_95, ci_99)):\n",
    "    print(f'p{i:<11} {val:>8.4f}    [{ci95[0]:>7.4f}, {ci95[1]:>7.4f}]    [{ci99[0]:>7.4f}, {ci99[1]:>7.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Prediction IntervalsEstimate uncertainty for future observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:23.101154Z",
     "iopub.status.busy": "2025-11-18T22:10:23.101022Z",
     "iopub.status.idle": "2025-11-18T22:10:23.862881Z",
     "shell.execute_reply": "2025-11-18T22:10:23.861610Z"
    }
   },
   "outputs": [],
   "source": [
    "def quadratic(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 5, 30)\n",
    "y = 0.5 * x**2 - 2 * x + 1 + np.random.normal(0, 0.3, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(quadratic, x, y, p0=[1, -2, 1])\n",
    "\n",
    "# Get prediction intervals at fitted x values\n",
    "pi = result.prediction_interval()\n",
    "\n",
    "print('Prediction intervals at first 5 data points:')\n",
    "print('\\n  x       y_data    y_pred    Lower     Upper')\n",
    "print('  ' + '-'*50)\n",
    "for i in range(5):\n",
    "    print(f'  {x[i]:.2f}    {y[i]:>6.3f}    {result.predictions[i]:>6.3f}    {pi[i,0]:>6.3f}    {pi[i,1]:>6.3f}')\n",
    "\n",
    "# Get prediction intervals at new x values\n",
    "x_new = np.array([1.5, 3.0, 4.5])\n",
    "pi_new = result.prediction_interval(x=x_new)\n",
    "\n",
    "print('\\nPrediction intervals at new x values:')\n",
    "print('\\n  x_new    y_pred    Lower     Upper    Width')\n",
    "print('  ' + '-'*50)\n",
    "for i, x_val in enumerate(x_new):\n",
    "    width = pi_new[i,1] - pi_new[i,0]\n",
    "    y_pred = result.model(x_val, *result.popt)\n",
    "    print(f'  {x_val:.2f}     {y_pred:>6.3f}    {pi_new[i,0]:>6.3f}    {pi_new[i,1]:>6.3f}    {width:>6.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Built-in VisualizationGenerate professional plots with one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:23.865848Z",
     "iopub.status.busy": "2025-11-18T22:10:23.865615Z",
     "iopub.status.idle": "2025-11-18T22:10:24.938567Z",
     "shell.execute_reply": "2025-11-18T22:10:24.937778Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian(x, a, mu, sigma):\n",
    "    return a * jnp.exp(-((x - mu)**2) / (2*sigma**2))\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = 10 * np.exp(-((x - 1)**2) / (2*1.5**2)) + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(gaussian, x, y, p0=[10, 1, 1.5])\n",
    "\n",
    "# Plot with residuals\n",
    "result.plot(show_residuals=True)\n",
    "plt.savefig('curve_fit_result.png', dpi=150, bbox_inches='tight')\n",
    "print('‚úì Plot saved to curve_fit_result.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Summary ReportGet comprehensive statistical summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:24.940597Z",
     "iopub.status.busy": "2025-11-18T22:10:24.940479Z",
     "iopub.status.idle": "2025-11-18T22:10:25.569154Z",
     "shell.execute_reply": "2025-11-18T22:10:25.568503Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential(x, a, b, c):\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y_true = 10 * np.exp(-0.5 * x) + 2\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n",
    "\n",
    "# Print summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Model ComparisonUse AIC/BIC to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:25.571486Z",
     "iopub.status.busy": "2025-11-18T22:10:25.571371Z",
     "iopub.status.idle": "2025-11-18T22:10:27.436272Z",
     "shell.execute_reply": "2025-11-18T22:10:27.435732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate exponential decay data\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y_true = 10 * np.exp(-0.5 * x) + 2\n",
    "y = y_true + np.random.normal(0, 0.5, size=len(x))\n",
    "\n",
    "# Model 1: Exponential (correct)\n",
    "def exponential(x, a, b, c):\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "# Model 2: Linear (wrong)\n",
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Model 3: Quadratic (overfitted)\n",
    "def quadratic(x, a, b, c):\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "# Fit all models\n",
    "result_exp = curve_fit(exponential, x, y, p0=[10, 0.5, 2])\n",
    "result_lin = curve_fit(linear, x, y, p0=[-1, 10])\n",
    "result_quad = curve_fit(quadratic, x, y, p0=[0, -1, 10])\n",
    "\n",
    "# Compare\n",
    "print('Model Comparison:')\n",
    "print(f\"\\n{'Model':<15} {'Params':<8} {'R¬≤':<10} {'RMSE':<10} {'AIC':<10} {'BIC':<10}\")\n",
    "print('-'*70)\n",
    "\n",
    "models = [\n",
    "    ('Exponential', result_exp),\n",
    "    ('Linear', result_lin),\n",
    "    ('Quadratic', result_quad)\n",
    "]\n",
    "\n",
    "for name, res in models:\n",
    "    print(f'{name:<15} {len(res.popt):<8} {res.r_squared:<10.6f} {res.rmse:<10.6f} {res.aic:<10.2f} {res.bic:<10.2f}')\n",
    "\n",
    "best_idx = np.argmin([r.aic for _, r in models])\n",
    "print(f'\\nBest model (lowest AIC): {models[best_idx][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Accessing ResidualsResiduals and predictions are directly accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T22:10:27.437867Z",
     "iopub.status.busy": "2025-11-18T22:10:27.437750Z",
     "iopub.status.idle": "2025-11-18T22:10:28.091032Z",
     "shell.execute_reply": "2025-11-18T22:10:28.090469Z"
    }
   },
   "outputs": [],
   "source": [
    "def sine_wave(x, a, f, phi):\n",
    "    return a * jnp.sin(2 * jnp.pi * f * x + phi)\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 2, 50)\n",
    "y = 3 * np.sin(2*np.pi*2*x + 0.5) + np.random.normal(0, 0.3, size=len(x))\n",
    "\n",
    "# Fit model\n",
    "result = curve_fit(sine_wave, x, y, p0=[3, 2, 0.5])\n",
    "\n",
    "# Access residuals\n",
    "residuals = result.residuals\n",
    "print('Residuals:')\n",
    "print(f'  Mean: {np.mean(residuals):.6f} (should be ~0)')\n",
    "print(f'  Std:  {np.std(residuals):.6f}')\n",
    "print(f'  Min:  {np.min(residuals):.6f}')\n",
    "print(f'  Max:  {np.max(residuals):.6f}')\n",
    "\n",
    "# Access predictions\n",
    "predictions = result.predictions\n",
    "print('\\nPredictions:')\n",
    "print(f'  Shape: {predictions.shape}')\n",
    "print(f'  Correlation with data: {np.corrcoef(predictions, y)[0,1]:.6f}')\n",
    "\n",
    "# Verify\n",
    "manual_residuals = y - predictions\n",
    "print('\\nVerification:')\n",
    "print(f'  Residuals match (data - predictions)? {np.allclose(residuals, manual_residuals)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Key Insights1. **Enhanced results** provide instant access to statistical metrics2. **Confidence intervals** quantify parameter uncertainty3. **Prediction intervals** estimate uncertainty for new observations4. **Built-in visualization** saves repetitive plotting code5. **Model comparison** with AIC/BIC for systematic selection6. **Fully backward compatible** with existing code---## üìö Available Properties**Goodness of Fit:**- `r_squared`: Coefficient of determination (R¬≤)- `adj_r_squared`: Adjusted R¬≤ (penalizes extra parameters)- `rmse`: Root mean squared error- `mae`: Mean absolute error- `chi_squared`: Chi-squared statistic**Model Selection:**- `aic`: Akaike Information Criterion- `bic`: Bayesian Information Criterion**Data Access:**- `residuals`: Fit residuals (y - ≈∑)- `predictions`: Fitted values (≈∑)- `popt`: Optimal parameters- `pcov`: Covariance matrix**Methods:**- `confidence_intervals(alpha)`: Parameter confidence intervals- `prediction_interval(x, alpha)`: Prediction intervals- `plot(show_residuals)`: Visualization- `summary()`: Statistical summary report---## üéì Next Steps- Use enhanced results in your fitting workflows- Compare models with AIC/BIC- Report confidence intervals in publications- Create publication-quality plots with `.plot()`- Explore prediction intervals for forecasting---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
