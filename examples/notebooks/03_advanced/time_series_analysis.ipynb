{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\nConverted from time_series_analysis.ipynb\n\nThis script was automatically generated from a Jupyter notebook.\nPlots are saved to the figures/ directory instead of displayed inline.\n\"\"\"\n\n# ======================================================================\n# # Time Series Analysis with NLSQ\n#\n# **Level**: Intermediate to Advanced\n# **Time**: 35-45 minutes\n# **Prerequisites**: NLSQ Quickstart\n#\n# ## Overview\n#\n# Time series analysis involves fitting models to sequential data with temporal dependencies. While traditional approaches use ARIMA or state-space models, **NLSQ excels at fitting parametric trend and seasonal components** with physical interpretations.\n#\n# ### What You'll Learn\n#\n# 1. **Trend Fitting**: Polynomial, exponential, and logistic growth models\n# 2. **Seasonal Decomposition**: Fourier series for periodic components\n# 3. **Combined Models**: Trend + seasonality + noise\n# 4. **Forecasting**: Extrapolation with uncertainty quantification\n# 5. **Autocorrelation**: Checking residual independence\n#\n# ### When to Use NLSQ for Time Series\n#\n# **NLSQ is ideal when:**\n# - You have a **physical or mechanistic model** for the process (e.g., exponential growth, damped oscillations)\n# - You need **interpretable parameters** (e.g., growth rate, decay constant, period)\n# - Data exhibits **strong deterministic trends** or **periodic patterns**\n# - You want to **leverage JAX's speed** for large datasets or batch fitting\n#\n# **Use traditional time series methods (ARIMA, Prophet) when:**\n# - Data is dominated by **stochastic processes** without clear parametric form\n# - You need **complex autoregressive structures**\n# - **Missing data** or **irregular sampling** is common\n#\n# ### Applications\n#\n# - **Scientific**: Radioactive decay, population dynamics, chemical kinetics\n# - **Engineering**: Sensor drift, system response, degradation models\n# - **Environmental**: Temperature cycles, tidal patterns, climate trends\n# - **Business**: Product lifecycle, seasonal sales (with physical constraints)\n# ======================================================================\n# Configure matplotlib for inline plotting in VS Code/Jupyter\n# MUST come before importing matplotlib\nimport warnings\nfrom pathlib import Path\n\nimport jax.numpy as jnp\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom nlsq import CurveFit\n\n# Plotting configuration\nplt.rcParams[\"figure.figsize\"] = (12, 6)\nplt.rcParams[\"font.size\"] = 10\n\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"\u2713 Imports successful\")\n\n\n# ======================================================================\n# ## Part 1: Trend Fitting\n#\n# We'll explore different growth models commonly found in time series data.\n# ======================================================================\n\n\n# Generate synthetic growth data (logistic curve)\n\n# Time points (days)\nt_data = np.linspace(0, 100, 150)\n\n# True logistic growth parameters\nL_true = 1000.0  # Carrying capacity\nk_true = 0.08  # Growth rate\nt0_true = 40.0  # Inflection point\n\n\ndef logistic_growth(t, L, k, t0):\n    \"\"\"Logistic growth model (S-curve).\n\n    Common in population dynamics, product adoption, epidemic spread.\n\n    Parameters\n    ----------\n    t : array_like\n        Time\n    L : float\n        Carrying capacity (asymptotic maximum)\n    k : float\n        Growth rate\n    t0 : float\n        Inflection point (time of maximum growth rate)\n\n    Returns\n    -------\n    y : array_like\n        Population/quantity at time t\n    \"\"\"\n    return L / (1.0 + jnp.exp(-k * (t - t0)))\n\n\n# Generate clean signal\ny_true = logistic_growth(t_data, L_true, k_true, t0_true)\n\n# Add noise (proportional to signal level)\nnp.random.seed(42)\nnoise = np.random.normal(0, 30, len(t_data))\ny_observed = y_true + noise\n\nprint(\"\u2713 Generated logistic growth data\")\nprint(f\"  Time range: {t_data.min():.0f} - {t_data.max():.0f} days\")\nprint(f\"  True parameters: L={L_true}, k={k_true}, t0={t0_true}\")\n\n\n# Fit logistic growth model\n\ncf = CurveFit()\n\n# Initial guess (from visual inspection)\np0 = [900.0, 0.1, 45.0]  # L, k, t0\n\n# Bounds (physical constraints)\nbounds = ([0, 0, 0], [2000, 1.0, 100])  # L, k, t0 must be positive\n\n# Fit\npopt, pcov = cf.curve_fit(\n    logistic_growth, jnp.array(t_data), jnp.array(y_observed), p0=p0, bounds=bounds\n)\n\nL_fit, k_fit, t0_fit = popt\nL_err, k_err, t0_err = np.sqrt(np.diag(pcov))\n\nprint(\"Fitted Parameters:\")\nprint(f\"  Carrying capacity (L): {L_fit:.1f} \u00b1 {L_err:.1f} (true: {L_true})\")\nprint(f\"  Growth rate (k): {k_fit:.3f} \u00b1 {k_err:.3f} (true: {k_true})\")\nprint(f\"  Inflection point (t0): {t0_fit:.1f} \u00b1 {t0_err:.1f} days (true: {t0_true})\")\n\n# Calculate derived quantities\nmax_growth_rate = k_fit * L_fit / 4  # dN/dt at t0\nprint(\"\\nDerived:\")\nprint(f\"  Maximum growth rate: {max_growth_rate:.1f} units/day\")\nprint(f\"  Doubling time (early phase): {np.log(2) / k_fit:.1f} days\")\n\n\n# Visualize growth fit with forecast\n\n# Extended time for forecasting\nt_extended = np.linspace(0, 150, 300)\ny_fit = logistic_growth(jnp.array(t_extended), L_fit, k_fit, t0_fit)\n\n_, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Main plot: data + fit + forecast\nax1.plot(t_data, y_observed, \"o\", alpha=0.5, label=\"Observed data\", ms=4)\nax1.plot(t_extended, y_fit, \"r-\", lw=2, label=\"Fitted logistic model\")\nax1.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1, label=\"Forecast boundary\")\nax1.axhline(\n    L_fit, color=\"green\", ls=\":\", lw=1.5, label=f\"Carrying capacity: {L_fit:.0f}\"\n)\nax1.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=f\"Inflection: {t0_fit:.0f} d\")\n\nax1.set_xlabel(\"Time (days)\")\nax1.set_ylabel(\"Population / Quantity\")\nax1.set_title(\"Logistic Growth Fitting and Forecasting\")\nax1.legend()\nax1.grid(alpha=0.3)\n\n# Growth rate plot\ngrowth_rate = k_fit * y_fit * (1 - y_fit / L_fit)  # dN/dt\nax2.plot(t_extended, growth_rate, \"b-\", lw=2)\nax2.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=\"Maximum growth rate\")\nax2.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1)\nax2.set_xlabel(\"Time (days)\")\nax2.set_ylabel(\"Growth Rate (dN/dt)\")\nax2.set_title(\"Instantaneous Growth Rate\")\nax2.legend()\nax2.grid(alpha=0.3)\n\nplt.tight_layout()\n# Save figure to file\nfig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_01.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"\u2713 Growth trend analysis complete\")\n\n\n# ======================================================================\n# ## Part 2: Seasonal Decomposition with Fourier Series\n#\n# Many time series exhibit periodic patterns (daily, weekly, annual cycles). We can model these using Fourier series.\n# ======================================================================\n\n\n# Generate seasonal data (temperature with annual cycle)\n\n# Daily temperature over 3 years\ndays = np.linspace(0, 3 * 365, 3 * 365)\n\n# True components\nannual_mean = 15.0  # \u00b0C\nannual_amplitude = 10.0  # \u00b0C\nannual_period = 365.25  # days\ntrend_slope = 0.01  # \u00b0C/day (climate warming)\n\n# Generate signal: trend + annual cycle + noise\ntrend_component = annual_mean + trend_slope * days\nseasonal_component = annual_amplitude * np.sin(2 * np.pi * days / annual_period)\ntemp_true = trend_component + seasonal_component\n\n# Add weather noise\nnp.random.seed(123)\ntemp_observed = temp_true + np.random.normal(0, 2.0, len(days))\n\nprint(\"\u2713 Generated seasonal temperature data\")\nprint(f\"  Duration: {len(days)} days ({len(days) / 365:.1f} years)\")\nprint(f\"  True parameters: mean={annual_mean}\u00b0C, amplitude={annual_amplitude}\u00b0C\")\nprint(f\"  Warming trend: {trend_slope * 365:.2f}\u00b0C/year\")\n\n\n# Fit trend + seasonal model\n\n\ndef trend_seasonal_model(t, mean, trend, amplitude, period, phase):\n    \"\"\"Combined linear trend and sinusoidal seasonal component.\n\n    Parameters\n    ----------\n    t : array_like\n        Time (days)\n    mean : float\n        Baseline level\n    trend : float\n        Linear trend (units per day)\n    amplitude : float\n        Seasonal amplitude\n    period : float\n        Seasonal period (days)\n    phase : float\n        Phase shift (radians)\n\n    Returns\n    -------\n    y : array_like\n        Modeled values\n    \"\"\"\n    trend_part = mean + trend * t\n    seasonal_part = amplitude * jnp.sin(2 * jnp.pi * t / period + phase)\n    return trend_part + seasonal_part\n\n\n# Initial guess\np0_seasonal = [15.0, 0.0, 8.0, 365.0, 0.0]  # mean, trend, amplitude, period, phase\n\n# Bounds (constrain period to be near annual)\nbounds_seasonal = (\n    [-50, -0.1, 0, 300, -2 * np.pi],  # Lower\n    [50, 0.1, 20, 400, 2 * np.pi],  # Upper\n)\n\n# Fit\npopt_seasonal, pcov_seasonal = cf.curve_fit(\n    trend_seasonal_model,\n    jnp.array(days),\n    jnp.array(temp_observed),\n    p0=p0_seasonal,\n    bounds=bounds_seasonal,\n)\n\nmean_fit, trend_fit, amp_fit, period_fit, phase_fit = popt_seasonal\nerrors = np.sqrt(np.diag(pcov_seasonal))\n\nprint(\"Fitted Seasonal Parameters:\")\nprint(f\"  Baseline: {mean_fit:.2f} \u00b1 {errors[0]:.2f} \u00b0C\")\nprint(\n    f\"  Trend: {trend_fit:.4f} \u00b1 {errors[1]:.4f} \u00b0C/day = {trend_fit * 365:.2f} \u00b0C/year\"\n)\nprint(f\"  Amplitude: {amp_fit:.2f} \u00b1 {errors[2]:.2f} \u00b0C\")\nprint(f\"  Period: {period_fit:.1f} \u00b1 {errors[3]:.1f} days\")\nprint(f\"  Phase: {phase_fit:.3f} \u00b1 {errors[4]:.3f} rad\")\n\n\n# Decompose time series into components\n\n# Fitted components\ntrend_fitted = mean_fit + trend_fit * days\nseasonal_fitted = amp_fit * np.sin(2 * np.pi * days / period_fit + phase_fit)\ntotal_fitted = trend_fitted + seasonal_fitted\nresiduals = temp_observed - total_fitted\n\n# Plot decomposition\nfig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n\n# Original data\naxes[0].plot(days / 365, temp_observed, \"o\", alpha=0.3, ms=2, label=\"Observed\")\naxes[0].plot(days / 365, total_fitted, \"r-\", lw=1.5, label=\"Fitted model\")\naxes[0].set_ylabel(\"Temperature (\u00b0C)\")\naxes[0].set_title(\"Original Time Series\")\naxes[0].legend()\naxes[0].grid(alpha=0.3)\n\n# Trend component\naxes[1].plot(days / 365, trend_fitted, \"b-\", lw=2)\naxes[1].set_ylabel(\"Trend (\u00b0C)\")\naxes[1].set_title(f\"Trend Component (slope: {trend_fit * 365:.3f} \u00b0C/year)\")\naxes[1].grid(alpha=0.3)\n\n# Seasonal component\naxes[2].plot(days / 365, seasonal_fitted, \"g-\", lw=1.5)\naxes[2].set_ylabel(\"Seasonal (\u00b0C)\")\naxes[2].set_title(\n    f\"Seasonal Component (period: {period_fit:.1f} days, amplitude: {amp_fit:.1f} \u00b0C)\"\n)\naxes[2].grid(alpha=0.3)\n\n# Residuals\naxes[3].plot(days / 365, residuals, \"o\", alpha=0.4, ms=2, color=\"gray\")\naxes[3].axhline(0, color=\"k\", ls=\"--\", lw=1)\naxes[3].set_ylabel(\"Residual (\u00b0C)\")\naxes[3].set_xlabel(\"Time (years)\")\naxes[3].set_title(f\"Residuals (std: {np.std(residuals):.2f} \u00b0C, should be white noise)\")\naxes[3].grid(alpha=0.3)\n\nplt.tight_layout()\n# Save figure to file\nfig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_02.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"\u2713 Seasonal decomposition complete\")\n\n\n# ======================================================================\n# ## Part 3: Forecasting with Uncertainty\n#\n# Extrapolate the fitted model into the future with prediction intervals.\n# ======================================================================\n\n\n# Generate forecast with uncertainty bands\n\n# Forecast horizon: 1 additional year\ndays_forecast = np.linspace(0, 4 * 365, 4 * 365)\nforecast_boundary = 3 * 365\n\n# Point forecast\ntemp_forecast = trend_seasonal_model(jnp.array(days_forecast), *popt_seasonal)\n\n# Uncertainty from parameter covariance (simplified)\n# Full approach: Monte Carlo sampling from parameter distribution\nn_samples = 200\nparam_samples = np.random.multivariate_normal(\n    popt_seasonal, pcov_seasonal, size=n_samples\n)\n\nforecast_samples = np.array(\n    [\n        trend_seasonal_model(jnp.array(days_forecast), *params)\n        for params in param_samples\n    ]\n)\n\n# Calculate prediction intervals\nforecast_mean = np.mean(forecast_samples, axis=0)\nforecast_std = np.std(forecast_samples, axis=0)\nforecast_lower = np.percentile(forecast_samples, 2.5, axis=0)  # 95% PI\nforecast_upper = np.percentile(forecast_samples, 97.5, axis=0)\n\n# Add residual uncertainty\nresidual_std = np.std(residuals)\nforecast_lower_total = forecast_lower - 2 * residual_std\nforecast_upper_total = forecast_upper + 2 * residual_std\n\nprint(f\"\u2713 Generated {len(days_forecast) - len(days)} day forecast\")\nprint(\n    f\"  Forecast period: {len(days) / 365:.1f} - {len(days_forecast) / 365:.1f} years\"\n)\nprint(f\"  Prediction interval width: {2 * residual_std:.1f} \u00b0C (\u00b11\u03c3 residuals)\")\n\n\n# Visualize forecast with prediction intervals\n\nfig, ax = plt.subplots(figsize=(14, 6))\n\n# Historical data\nax.plot(\n    days / 365, temp_observed, \"o\", alpha=0.3, ms=2, color=\"steelblue\", label=\"Observed\"\n)\n\n# Fitted model (historical)\nax.plot(\n    days / 365,\n    total_fitted,\n    \"r-\",\n    lw=2,\n    label=\"Fitted model\",\n    alpha=0.8,\n)\n\n# Forecast (future)\nforecast_mask = days_forecast > forecast_boundary\nax.plot(\n    days_forecast[forecast_mask] / 365,\n    forecast_mean[forecast_mask],\n    \"r--\",\n    lw=2,\n    label=\"Forecast\",\n)\n\n# Prediction intervals (parameter uncertainty only)\nax.fill_between(\n    days_forecast[forecast_mask] / 365,\n    forecast_lower[forecast_mask],\n    forecast_upper[forecast_mask],\n    alpha=0.3,\n    color=\"red\",\n    label=\"95% PI (parameter)\",\n)\n\n# Total prediction intervals (parameter + residual uncertainty)\nax.fill_between(\n    days_forecast[forecast_mask] / 365,\n    forecast_lower_total[forecast_mask],\n    forecast_upper_total[forecast_mask],\n    alpha=0.15,\n    color=\"orange\",\n    label=\"95% PI (total)\",\n)\n\n# Forecast boundary\nax.axvline(forecast_boundary / 365, color=\"gray\", ls=\"--\", lw=2, label=\"Forecast start\")\n\nax.set_xlabel(\"Time (years)\", fontsize=12)\nax.set_ylabel(\"Temperature (\u00b0C)\", fontsize=12)\nax.set_title(\"Time Series Forecast with Uncertainty Quantification\", fontsize=14)\nax.legend(loc=\"upper left\")\nax.grid(alpha=0.3)\n\nplt.tight_layout()\n# Save figure to file\nfig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_03.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"\u2713 Forecast visualization complete\")\n\n\n# ======================================================================\n# ## Part 4: Residual Diagnostics (Autocorrelation)\n#\n# For valid inference, residuals should be uncorrelated (white noise). We check this with autocorrelation analysis.\n# ======================================================================\n\n\n# Calculate and plot autocorrelation of residuals\n\n\ndef autocorrelation(x, max_lag=50):\n    \"\"\"Calculate autocorrelation function (ACF).\n\n    Parameters\n    ----------\n    x : array_like\n        Time series (residuals)\n    max_lag : int\n        Maximum lag to compute\n\n    Returns\n    -------\n    lags : array\n        Lag values\n    acf : array\n        Autocorrelation values\n    \"\"\"\n    x_centered = x - np.mean(x)\n    c0 = np.dot(x_centered, x_centered) / len(x)\n\n    lags = np.arange(0, max_lag + 1)\n    acf = np.zeros(len(lags))\n\n    for i, lag in enumerate(lags):\n        if lag == 0:\n            acf[i] = 1.0\n        else:\n            c_lag = np.dot(x_centered[:-lag], x_centered[lag:]) / len(x)\n            acf[i] = c_lag / c0\n\n    return lags, acf\n\n\n# Calculate ACF\nlags, acf_values = autocorrelation(residuals, max_lag=60)\n\n# Significance bounds (95% confidence for white noise)\nconf_bound = 1.96 / np.sqrt(len(residuals))\n\n# Plot\nfig, ax = plt.subplots(figsize=(10, 5))\n\nax.stem(lags, acf_values, basefmt=\" \", linefmt=\"C0-\", markerfmt=\"C0o\")\nax.axhline(0, color=\"k\", lw=1)\nax.axhline(conf_bound, color=\"r\", ls=\"--\", lw=1.5, label=\"95% confidence\")\nax.axhline(-conf_bound, color=\"r\", ls=\"--\", lw=1.5)\nax.fill_between(\n    lags, -conf_bound, conf_bound, alpha=0.2, color=\"red\", label=\"White noise region\"\n)\n\nax.set_xlabel(\"Lag (days)\")\nax.set_ylabel(\"Autocorrelation\")\nax.set_title(\"Autocorrelation Function (ACF) of Residuals\")\nax.set_xlim(-1, max(lags) + 1)\nax.legend()\nax.grid(alpha=0.3)\n\nplt.tight_layout()\n# Save figure to file\nfig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_04.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\n# Check for significant autocorrelation\nsignificant_lags = np.sum(np.abs(acf_values[1:]) > conf_bound)  # Exclude lag 0\nprint(\"\u2713 Autocorrelation analysis complete\")\nprint(\n    f\"  Significant lags (95% level): {significant_lags} / {len(lags) - 1} ({significant_lags / (len(lags) - 1) * 100:.1f}%)\"\n)\nif significant_lags / (len(lags) - 1) < 0.05:\n    print(\"  \u2713 Residuals consistent with white noise (good fit)\")\nelse:\n    print(\n        \"  \u26a0 Significant autocorrelation detected: consider more complex model or autoregressive errors\"\n    )\n\n\n# ======================================================================\n# ## Summary and Best Practices\n#\n# ### When to Use NLSQ for Time Series\n#\n# | **Use Case** | **NLSQ Strength** | **Alternative** |\n# |--------------|-------------------|------------------|\n# | Physical growth models (exponential, logistic) | \u2705 Excellent (interpretable parameters) | ARIMA (less interpretable) |\n# | Periodic data with known/unknown period | \u2705 Good (Fourier series) | Seasonal decomposition (STL, Prophet) |\n# | Trend + seasonality | \u2705 Good (combined parametric model) | Prophet, TBATS |\n# | Autoregressive processes (ARMA) | \u274c Poor (not designed for this) | ARIMA, SARIMA |\n# | Irregular sampling | \u2705 Excellent (handles any time grid) | Interpolation + ARIMA |\n# | Large datasets (millions of points) | \u2705 Excellent (JAX GPU acceleration) | Dask + statsmodels |\n#\n# ### Key Takeaways\n#\n# 1. **Model Selection**: Choose parametric forms based on domain knowledge\n#    - Growth: Exponential, logistic, Gompertz\n#    - Decay: Exponential, power-law\n#    - Periodic: Fourier series (sum of sines/cosines)\n#\n# 2. **Forecasting Uncertainty**\n#    - **Parameter uncertainty**: From covariance matrix (Monte Carlo sampling)\n#    - **Model uncertainty**: Residual standard deviation\n#    - **Total**: Combine both sources for realistic prediction intervals\n#\n# 3. **Diagnostics**\n#    - **Residuals**: Should be centered at zero, no trend\n#    - **Autocorrelation**: Should be within confidence bounds (white noise)\n#    - **Heteroscedasticity**: Check if residual variance changes over time\n#\n# 4. **Multi-Seasonal Data**\n#    - Use multiple sinusoids: `amp1 * sin(2\u03c0 t / P1) + amp2 * sin(2\u03c0 t / P2)`\n#    - Example: Daily + weekly cycles in energy consumption\n#\n# ### Production Code Template\n#\n# ```python\n# from nlsq import CurveFit\n# import jax.numpy as jnp\n#\n# def forecast_time_series(t, y, forecast_days=30):\n#     \"\"\"Fit trend+seasonal model and forecast.\"\"\"\n#\n#     # Model\n#     def model(t, mean, trend, amp, period, phase):\n#         return mean + trend * t + amp * jnp.sin(2 * jnp.pi * t / period + phase)\n#\n#     # Fit\n#     cf = CurveFit()\n#     p0 = [jnp.mean(y), 0.0, jnp.std(y) / 2, 365.0, 0.0]\n#     popt, pcov = cf.curve_fit(model, jnp.array(t), jnp.array(y), p0=p0)\n#\n#     # Forecast\n#     t_future = jnp.arange(t[-1] + 1, t[-1] + 1 + forecast_days)\n#     y_forecast = model(t_future, *popt)\n#\n#     # Uncertainty (simplified)\n#     residual_std = jnp.std(y - model(jnp.array(t), *popt))\n#     forecast_uncertainty = residual_std\n#\n#     return t_future, y_forecast, forecast_uncertainty\n# ```\n#\n# ### Next Steps\n#\n# - **Advanced Seasonality**: Multi-frequency Fourier series for complex cycles\n# - **State-Space Models**: Kalman filtering with NLSQ parameter estimation\n# - **Batch Processing**: Fit thousands of time series in parallel with `jax.vmap`\n# - **Hybrid Models**: Combine NLSQ (trend/seasonal) with ARIMA (residual modeling)\n#\n# ### References\n#\n# 1. **Time Series Analysis**: Chatfield, *The Analysis of Time Series* (2004)\n# 2. **Forecasting**: Hyndman & Athanasopoulos, *Forecasting: Principles and Practice* (2021)\n# 3. **Related Examples**:\n#    - `gallery/biology/growth_curves.py` - Bacterial growth fitting\n#    - `gallery/physics/damped_oscillation.py` - Oscillatory time series\n#    - `advanced_features_demo.ipynb` - Robustness for outliers in time series\n# ======================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
