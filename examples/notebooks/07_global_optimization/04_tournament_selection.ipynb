{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tournament Selection for Streaming Global Optimization\n",
    "\n",
    "This tutorial demonstrates tournament selection for memory-efficient global optimization\n",
    "on large/streaming datasets where evaluating all candidates on all data is infeasible.\n",
    "\n",
    "**Features demonstrated:**\n",
    "- `TournamentSelector` for progressive elimination\n",
    "- Tournament selection for memory-efficient global optimization\n",
    "- Configuration: `tournament_size`, `selection_pressure`, `memory_limit_gb`\n",
    "- Streaming candidate processing\n",
    "- Visualization of tournament progression\n",
    "\n",
    "**Level: Advanced** | **Duration: 30 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting (MUST come before imports)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import GlobalOptimizationConfig\n",
    "from nlsq.global_optimization import (\n",
    "    TournamentSelector,\n",
    "    latin_hypercube_sample,\n",
    "    scale_samples_to_bounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. The Challenge: Multi-Start on Large Datasets\n",
    "\n",
    "Multi-start optimization evaluates many starting points to find the global optimum.\n",
    "For large/streaming datasets, fully evaluating all candidates is expensive:\n",
    "\n",
    "- **Memory:** Cannot load entire dataset at once\n",
    "- **Time:** Evaluating N candidates on M data points = O(N * M)\n",
    "- **Streaming:** Data arrives in batches, not all at once\n",
    "\n",
    "**Tournament selection** solves this by progressively eliminating poor candidates\n",
    "based on performance on data batches, keeping only the best for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Tournament Selection Algorithm\n",
    "\n",
    "The tournament proceeds in rounds:\n",
    "\n",
    "1. **Start:** N candidates\n",
    "2. **Round 1:** Evaluate on batch 1, eliminate worst (1 - elimination_fraction) * N\n",
    "3. **Round 2:** Evaluate survivors on batch 2, eliminate again\n",
    "4. **...continue until top M candidates remain**\n",
    "\n",
    "This reduces evaluation cost from O(N * total_batches) to O(N * batches_per_round * rounds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a multimodal model for demonstration\n",
    "def multimodal_model(x, a, b, c):\n",
    "    \"\"\"Sinusoidal model with multiple local minima.\n",
    "    \n",
    "    y = a * sin(b * x) + c\n",
    "    \"\"\"\n",
    "    return a * jnp.sin(b * x) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters for synthetic data\n",
    "true_a, true_b, true_c = 2.5, 1.8, 1.0\n",
    "\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Generate Candidate Starting Points\n",
    "\n",
    "We generate candidate starting points using Latin Hypercube Sampling (LHS)\n",
    "to ensure good coverage of the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter bounds\n",
    "lb = np.array([0.5, 0.5, -2.0])  # Lower bounds: a, b, c\n",
    "ub = np.array([5.0, 4.0, 5.0])   # Upper bounds: a, b, c\n",
    "\n",
    "# Number of candidate starting points\n",
    "n_candidates = 20\n",
    "n_params = 3\n",
    "\n",
    "# Generate candidates using LHS\n",
    "key = jax.random.PRNGKey(42)\n",
    "lhs_samples = latin_hypercube_sample(n_candidates, n_params, rng_key=key)\n",
    "candidates = scale_samples_to_bounds(lhs_samples, lb, ub)\n",
    "\n",
    "print(f\"Generated {n_candidates} candidates in {n_params}D parameter space\")\n",
    "print(f\"Candidate shape: {candidates.shape}\")\n",
    "print(f\"\\nFirst 5 candidates:\")\n",
    "for i in range(5):\n",
    "    print(f\"  Candidate {i}: a={candidates[i,0]:.2f}, b={candidates[i,1]:.2f}, c={candidates[i,2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Configure Tournament Selection\n",
    "\n",
    "Tournament parameters in `GlobalOptimizationConfig`:\n",
    "\n",
    "- `elimination_rounds`: Number of elimination rounds (default: 3)\n",
    "- `elimination_fraction`: Fraction to eliminate each round (default: 0.5 = 50%)\n",
    "- `batches_per_round`: Number of data batches per round (default: 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure tournament parameters\n",
    "config = GlobalOptimizationConfig(\n",
    "    n_starts=n_candidates,\n",
    "    sampler=\"lhs\",\n",
    "    elimination_rounds=3,         # 3 elimination rounds\n",
    "    elimination_fraction=0.5,     # Eliminate 50% each round\n",
    "    batches_per_round=10,         # Evaluate on 10 batches per round\n",
    ")\n",
    "\n",
    "print(\"Tournament Configuration:\")\n",
    "print(f\"  n_starts:             {config.n_starts}\")\n",
    "print(f\"  elimination_rounds:   {config.elimination_rounds}\")\n",
    "print(f\"  elimination_fraction: {config.elimination_fraction}\")\n",
    "print(f\"  batches_per_round:    {config.batches_per_round}\")\n",
    "\n",
    "# Calculate expected progression\n",
    "expected_survivors = n_candidates\n",
    "print(f\"\\nExpected tournament progression:\")\n",
    "print(f\"  Start: {expected_survivors} candidates\")\n",
    "for r in range(config.elimination_rounds):\n",
    "    expected_survivors = max(1, int(expected_survivors * (1 - config.elimination_fraction)))\n",
    "    print(f\"  After round {r+1}: {expected_survivors} survivors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Create TournamentSelector\n",
    "\n",
    "The `TournamentSelector` class manages the progressive elimination process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TournamentSelector\n",
    "selector = TournamentSelector(candidates=candidates, config=config)\n",
    "\n",
    "print(f\"TournamentSelector initialized:\")\n",
    "print(f\"  n_candidates: {selector.n_candidates}\")\n",
    "print(f\"  n_params:     {selector.n_params}\")\n",
    "print(f\"  n_survivors:  {selector.n_survivors}\")\n",
    "print(f\"  current_round: {selector.current_round}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Streaming Data Generator\n",
    "\n",
    "In streaming scenarios, data arrives in batches. We simulate this with a generator\n",
    "that yields (x_batch, y_batch) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_batch_generator(n_batches=100, batch_size=500, noise_level=0.3):\n",
    "    \"\"\"Generator that yields streaming data batches.\n",
    "    \n",
    "    Simulates a streaming scenario where data arrives in batches\n",
    "    rather than being available all at once.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_batches : int\n",
    "        Total number of batches to generate\n",
    "    batch_size : int\n",
    "        Number of points per batch\n",
    "    noise_level : float\n",
    "        Standard deviation of Gaussian noise\n",
    "    \n",
    "    Yields\n",
    "    ------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        (x_batch, y_batch) data pairs\n",
    "    \"\"\"\n",
    "    for batch_idx in range(n_batches):\n",
    "        # Generate random x values for this batch\n",
    "        x_batch = np.random.uniform(0, 4 * np.pi, batch_size)\n",
    "        \n",
    "        # Generate y values with true parameters + noise\n",
    "        y_true = true_a * np.sin(true_b * x_batch) + true_c\n",
    "        noise = noise_level * np.random.randn(batch_size)\n",
    "        y_batch = y_true + noise\n",
    "        \n",
    "        yield x_batch, y_batch\n",
    "\n",
    "\n",
    "# Test the generator\n",
    "test_gen = create_data_batch_generator(n_batches=3, batch_size=100)\n",
    "for i, (x, y) in enumerate(test_gen):\n",
    "    print(f\"Batch {i}: x shape={x.shape}, y shape={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Run Tournament Selection\n",
    "\n",
    "The `run_tournament` method processes data batches and progressively eliminates\n",
    "poor-performing candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh selector and data generator\n",
    "selector = TournamentSelector(candidates=candidates, config=config)\n",
    "\n",
    "# Need enough batches for all rounds\n",
    "total_batches_needed = config.elimination_rounds * config.batches_per_round + 10\n",
    "data_gen = create_data_batch_generator(n_batches=total_batches_needed, batch_size=500)\n",
    "\n",
    "print(\"Running tournament selection...\")\n",
    "print(f\"Total batches available: {total_batches_needed}\")\n",
    "print()\n",
    "\n",
    "# Run tournament and get top candidate\n",
    "best_candidates = selector.run_tournament(\n",
    "    data_batch_iterator=data_gen,\n",
    "    model=multimodal_model,\n",
    "    top_m=3,  # Return top 3 candidates\n",
    ")\n",
    "\n",
    "print(f\"\\nTournament complete!\")\n",
    "print(f\"Top 3 candidates:\")\n",
    "for i, params in enumerate(best_candidates):\n",
    "    print(f\"  {i+1}. a={params[0]:.3f}, b={params[1]:.3f}, c={params[2]:.3f}\")\n",
    "\n",
    "print(f\"\\nTrue parameters: a={true_a}, b={true_b}, c={true_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Tournament Diagnostics\n",
    "\n",
    "The selector provides detailed diagnostics about the tournament process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tournament diagnostics\n",
    "diagnostics = selector.get_diagnostics()\n",
    "\n",
    "print(\"Tournament Diagnostics:\")\n",
    "print(f\"  Initial candidates: {diagnostics['n_candidates_initial']}\")\n",
    "print(f\"  Final survivors:    {diagnostics['n_survivors']}\")\n",
    "print(f\"  Elimination rate:   {diagnostics['elimination_rate']:.1%}\")\n",
    "print(f\"  Rounds completed:   {diagnostics['rounds_completed']}\")\n",
    "print(f\"  Total batches:      {diagnostics['total_batches_evaluated']}\")\n",
    "print(f\"  Numerical failures: {diagnostics['numerical_failures']}\")\n",
    "\n",
    "if diagnostics['mean_survivor_loss'] is not None:\n",
    "    print(f\"  Mean survivor loss: {diagnostics['mean_survivor_loss']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round-by-round history\n",
    "print(\"\\nRound History:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Round':<8} {'Before':<10} {'After':<10} {'Eliminated':<12} {'Mean Loss':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for round_info in diagnostics['round_history']:\n",
    "    print(\n",
    "        f\"{round_info['round']:<8} \"\n",
    "        f\"{round_info['n_survivors_before']:<10} \"\n",
    "        f\"{round_info['n_survivors_after']:<10} \"\n",
    "        f\"{round_info['n_eliminated']:<12} \"\n",
    "        f\"{round_info['mean_loss']:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 9. Visualize Tournament Progression\n",
    "\n",
    "Let's visualize how candidates are eliminated through the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract round history for plotting\n",
    "rounds = [0] + [r['round'] + 1 for r in diagnostics['round_history']]\n",
    "survivors = [diagnostics['n_candidates_initial']] + [r['n_survivors_after'] for r in diagnostics['round_history']]\n",
    "mean_losses = [None] + [r['mean_loss'] for r in diagnostics['round_history']]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Survivor count over rounds\n",
    "ax1 = axes[0]\n",
    "ax1.plot(rounds, survivors, 'bo-', linewidth=2, markersize=10)\n",
    "ax1.fill_between(rounds, survivors, alpha=0.3)\n",
    "ax1.set_xlabel('Tournament Round')\n",
    "ax1.set_ylabel('Number of Candidates')\n",
    "ax1.set_title('Tournament Elimination: Candidate Survival')\n",
    "ax1.set_xticks(rounds)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "for r, s in zip(rounds, survivors):\n",
    "    ax1.annotate(str(s), (r, s), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
    "\n",
    "# Right: Mean loss evolution\n",
    "ax2 = axes[1]\n",
    "valid_rounds = [r for r, m in zip(rounds, mean_losses) if m is not None]\n",
    "valid_losses = [m for m in mean_losses if m is not None]\n",
    "\n",
    "if valid_losses:\n",
    "    ax2.plot(valid_rounds, valid_losses, 'ro-', linewidth=2, markersize=10)\n",
    "    ax2.set_xlabel('Tournament Round')\n",
    "    ax2.set_ylabel('Mean Survivor Loss')\n",
    "    ax2.set_title('Tournament Elimination: Loss Improvement')\n",
    "    ax2.set_xticks(valid_rounds)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_tournament_progression.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 10. Visualize Candidate Losses\n",
    "\n",
    "Let's visualize the cumulative loss of each candidate and which ones survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cumulative losses and survival status\n",
    "cumulative_losses = selector.cumulative_losses\n",
    "survival_mask = selector.survival_mask\n",
    "\n",
    "# Sort candidates by loss for visualization\n",
    "sorted_indices = np.argsort(cumulative_losses)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot bars for each candidate\n",
    "colors = ['green' if survival_mask[i] else 'red' for i in sorted_indices]\n",
    "losses_sorted = [cumulative_losses[i] for i in sorted_indices]\n",
    "\n",
    "# Cap infinite values for visualization\n",
    "max_finite_loss = max(l for l in losses_sorted if np.isfinite(l)) * 1.5\n",
    "losses_capped = [min(l, max_finite_loss) for l in losses_sorted]\n",
    "\n",
    "bars = ax.bar(range(len(sorted_indices)), losses_capped, color=colors, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Candidate (sorted by loss)')\n",
    "ax.set_ylabel('Cumulative Loss')\n",
    "ax.set_title('Tournament Results: Cumulative Loss by Candidate')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='green', alpha=0.7, label='Survivor'),\n",
    "    Patch(facecolor='red', alpha=0.7, label='Eliminated'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_candidate_losses.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 11. Compare Different Elimination Strategies\n",
    "\n",
    "Let's compare different `elimination_fraction` values to understand the tradeoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different elimination fractions\n",
    "elimination_fractions = [0.25, 0.5, 0.75]\n",
    "comparison_results = {}\n",
    "\n",
    "print(\"Comparing elimination fractions:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for elim_frac in elimination_fractions:\n",
    "    # Configure with this elimination fraction\n",
    "    config = GlobalOptimizationConfig(\n",
    "        n_starts=n_candidates,\n",
    "        elimination_rounds=3,\n",
    "        elimination_fraction=elim_frac,\n",
    "        batches_per_round=10,\n",
    "    )\n",
    "    \n",
    "    # Create fresh candidates and selector\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    lhs_samples = latin_hypercube_sample(n_candidates, n_params, rng_key=key)\n",
    "    candidates = scale_samples_to_bounds(lhs_samples, lb, ub)\n",
    "    \n",
    "    selector = TournamentSelector(candidates=candidates, config=config)\n",
    "    data_gen = create_data_batch_generator(n_batches=50, batch_size=500)\n",
    "    \n",
    "    best = selector.run_tournament(\n",
    "        data_batch_iterator=data_gen,\n",
    "        model=multimodal_model,\n",
    "        top_m=1,\n",
    "    )\n",
    "    \n",
    "    diag = selector.get_diagnostics()\n",
    "    \n",
    "    comparison_results[elim_frac] = {\n",
    "        'best_params': best[0],\n",
    "        'n_survivors': diag['n_survivors'],\n",
    "        'total_batches': diag['total_batches_evaluated'],\n",
    "        'round_history': diag['round_history'],\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nelimination_fraction = {elim_frac}:\")\n",
    "    print(f\"  Survivors: {diag['n_survivors']}\")\n",
    "    print(f\"  Batches evaluated: {diag['total_batches_evaluated']}\")\n",
    "    print(f\"  Best params: a={best[0][0]:.3f}, b={best[0][1]:.3f}, c={best[0][2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "# Plot survivor progression for each strategy\n",
    "ax1 = axes[0]\n",
    "for (elim_frac, data), color in zip(comparison_results.items(), colors):\n",
    "    rounds = [0] + [r['round'] + 1 for r in data['round_history']]\n",
    "    survivors = [n_candidates] + [r['n_survivors_after'] for r in data['round_history']]\n",
    "    ax1.plot(rounds, survivors, 'o-', color=color, linewidth=2, markersize=8,\n",
    "             label=f'elim_frac={elim_frac}')\n",
    "\n",
    "ax1.set_xlabel('Tournament Round')\n",
    "ax1.set_ylabel('Survivors')\n",
    "ax1.set_title('Survivor Count by Elimination Fraction')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart: Total batches evaluated\n",
    "ax2 = axes[1]\n",
    "fracs = list(comparison_results.keys())\n",
    "batches = [comparison_results[f]['total_batches'] for f in fracs]\n",
    "ax2.bar([str(f) for f in fracs], batches, color=colors)\n",
    "ax2.set_xlabel('Elimination Fraction')\n",
    "ax2.set_ylabel('Total Batches Evaluated')\n",
    "ax2.set_title('Computational Cost')\n",
    "\n",
    "# Bar chart: Parameter error\n",
    "ax3 = axes[2]\n",
    "true_params = np.array([true_a, true_b, true_c])\n",
    "errors = []\n",
    "for f in fracs:\n",
    "    best_p = comparison_results[f]['best_params']\n",
    "    error = np.linalg.norm(best_p - true_params)\n",
    "    errors.append(error)\n",
    "\n",
    "ax3.bar([str(f) for f in fracs], errors, color=colors)\n",
    "ax3.set_xlabel('Elimination Fraction')\n",
    "ax3.set_ylabel('Parameter Error (L2)')\n",
    "ax3.set_title('Best Candidate Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_elimination_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 12. Checkpointing for Fault Tolerance\n",
    "\n",
    "For long-running tournaments, you can save and restore the selector state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a selector and run partial tournament\n",
    "config = GlobalOptimizationConfig(\n",
    "    n_starts=n_candidates,\n",
    "    elimination_rounds=3,\n",
    "    elimination_fraction=0.5,\n",
    "    batches_per_round=10,\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "lhs_samples = latin_hypercube_sample(n_candidates, n_params, rng_key=key)\n",
    "candidates = scale_samples_to_bounds(lhs_samples, lb, ub)\n",
    "\n",
    "selector = TournamentSelector(candidates=candidates, config=config)\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint = selector.to_checkpoint()\n",
    "\n",
    "print(\"Checkpoint contents:\")\n",
    "for key, value in checkpoint.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"  {key}: ndarray shape={value.shape}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  {key}: list length={len(value)}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from checkpoint\n",
    "restored_selector = TournamentSelector.from_checkpoint(checkpoint, config)\n",
    "\n",
    "print(f\"Restored selector:\")\n",
    "print(f\"  n_candidates: {restored_selector.n_candidates}\")\n",
    "print(f\"  n_survivors:  {restored_selector.n_survivors}\")\n",
    "print(f\"  current_round: {restored_selector.current_round}\")\n",
    "\n",
    "# Can continue tournament from where it left off\n",
    "# data_gen = create_data_batch_generator(...)\n",
    "# best = restored_selector.run_tournament(data_gen, model, top_m=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways\n",
    "\n",
    "1. **Tournament selection** is memory-efficient for large/streaming datasets:\n",
    "   - Evaluates candidates on data batches, not full dataset\n",
    "   - Progressively eliminates poor performers\n",
    "   - Reduces computational cost from O(N * M) to O(N * batches * rounds)\n",
    "\n",
    "2. **Configuration parameters:**\n",
    "   - `elimination_rounds`: More rounds = more filtering, fewer survivors\n",
    "   - `elimination_fraction`: Higher = more aggressive pruning\n",
    "   - `batches_per_round`: More batches = better candidate ranking\n",
    "\n",
    "3. **Tradeoffs:**\n",
    "   - Aggressive elimination (0.75): Faster, but may eliminate good candidates early\n",
    "   - Conservative elimination (0.25): Slower, but more robust\n",
    "   - Default (0.5): Balanced approach\n",
    "\n",
    "4. **Checkpointing:** Use `to_checkpoint()` and `from_checkpoint()` for fault tolerance\n",
    "\n",
    "5. **Diagnostics:** `get_diagnostics()` provides detailed tournament statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "print()\n",
    "print(\"Tournament selection is ideal for:\")\n",
    "print(\"  - Large datasets that exceed memory\")\n",
    "print(\"  - Streaming data scenarios\")\n",
    "print(\"  - High-dimensional parameter spaces\")\n",
    "print()\n",
    "print(\"Use GlobalOptimizationConfig with:\")\n",
    "print(\"  - elimination_rounds: 2-4 (more = more filtering)\")\n",
    "print(\"  - elimination_fraction: 0.25-0.75 (higher = faster)\")\n",
    "print(\"  - batches_per_round: 10-100 (more = better ranking)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
