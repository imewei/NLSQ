{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    This model has multiple local minima due to the periodicity of sin().\n    Different combinations of (b, c) can produce similar fits.\n    \"\"\"\n    return a * jnp.sin(b * x + c) + d\ndef main():\n    print(\"=\" * 70)\n    print(\"Multi-Start Optimization Basics (v0.6.3)\")\n    print(\"=\" * 70)\n    print()\n    np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Generate synthetic data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"1. Generating synthetic data...\")\nn_samples = 200\nx_data = np.linspace(0, 4 * np.pi, n_samples)\ntrue_a, true_b, true_c, true_d = 2.0, 1.5, 0.5, 1.0\ny_true = true_a * np.sin(true_b * x_data + true_c) + true_d\nnoise = 0.2 * np.random.randn(n_samples)\ny_data = y_true + noise\nprint(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}, d={true_d}\")\nprint(f\"  Dataset: {n_samples} points\")\nprint()\nfig, ax = plt.subplots(figsize=(10, 5))\nax.scatter(x_data, y_data, alpha=0.5, s=10, label=\"Noisy data\")\nax.plot(x_data, y_true, \"r-\", linewidth=2, label=\"True function\")\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(\"Synthetic Data: Multimodal Sinusoidal Model\")\nax.legend()\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"01_data_visualization.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '01_data_visualization.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Single-start optimization with different initial guesses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint(\"2. Single-start optimization (showing sensitivity to initial guess)...\")\nbounds = ([0.5, 0.5, -np.pi, -2.0], [5.0, 3.0, np.pi, 5.0])\ninitial_guesses = [\n    [1.0, 0.8, 0.0, 0.5],  # Poor guess 1\n    [3.0, 2.5, 2.0, 2.0],  # Poor guess 2\n    [1.5, 1.2, -1.0, 0.0],  # Poor guess 3\n]\nsingle_start_results = []\nfor i, p0 in enumerate(initial_guesses):\n    try:\n        popt, pcov = fit(\n            multimodal_model,\n            x_data,\n            y_data,\n            p0=p0,\n            bounds=bounds,\n            workflow=\"auto\",  # Local optimization\n        )\n        y_pred = multimodal_model(x_data, *popt)\n        ssr = float(jnp.sum((y_data - y_pred) ** 2))\n        single_start_results.append({\"p0\": p0, \"popt\": popt, \"ssr\": ssr})\n        print(f\"  Guess {i + 1}: p0={p0}\")\n        print(\n            f\"    Result: a={popt[0]:.3f}, b={popt[1]:.3f}, c={popt[2]:.3f}, d={popt[3]:.3f}\"\n        )\n        print(f\"    SSR: {ssr:.4f}\")\n    except Exception as e:\n        print(f\"  Guess {i + 1}: Failed - {e}\")\n        single_start_results.append({\"p0\": p0, \"popt\": None, \"ssr\": float(\"inf\")})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Global optimization with fit(workflow='auto_global')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint(\"3. Global optimization with fit(workflow='auto_global')...\")\np0_poor = [1.0, 0.8, 0.0, 0.5]\nprint(\"  workflow='auto_global' automatically selects:\")\nprint(\"    - Multi-Start (default) or CMA-ES based on parameter scale ratio\")\nprint(\"    - Memory strategy based on dataset size\")\nprint()\npopt_global, pcov_global = fit(\n    multimodal_model,\n    x_data,\n    y_data,\n    p0=p0_poor,\n    bounds=bounds,\n    workflow=\"auto_global\",  # Global optimization with auto method selection\n    n_starts=10,  # Number of multi-start runs\n)\ny_pred_global = multimodal_model(x_data, *popt_global)\nssr_global = float(jnp.sum((y_data - y_pred_global) ** 2))\nprint(\"  Global optimization result:\")\nprint(\n    f\"    Parameters: a={popt_global[0]:.3f}, b={popt_global[1]:.3f}, \"\n    f\"c={popt_global[2]:.3f}, d={popt_global[3]:.3f}\"\n)\nprint(f\"    SSR: {ssr_global:.4f}\")\npopt_single, _ = fit(\n    multimodal_model,\n    x_data,\n    y_data,\n    p0=p0_poor,\n    bounds=bounds,\n    workflow=\"auto\",  # Local optimization\n)\ny_pred_single = multimodal_model(x_data, *popt_single)\nssr_single = float(jnp.sum((y_data - y_pred_single) ** 2))\nprint()\nprint(\"  Comparison (same initial guess):\")\nprint(f\"    Single-start SSR: {ssr_single:.4f}\")\nprint(f\"    Global (auto_global) SSR: {ssr_global:.4f}\")\nif ssr_global < ssr_single:\n    improvement = (1 - ssr_global / ssr_single) * 100\n    print(f\"    Improvement: {improvement:.1f}% lower SSR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Comparison visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint(\"4. Saving comparison visualization...\")\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nax1 = axes[0]\nax1.scatter(x_data, y_data, alpha=0.4, s=15, label=\"Data\", color=\"gray\")\nax1.plot(x_data, y_true, \"k--\", linewidth=2, label=\"True function\", alpha=0.7)\nax1.plot(\n    x_data,\n    y_pred_single,\n    \"b-\",\n    linewidth=2,\n    label=f\"workflow='auto' (SSR={ssr_single:.2f})\",\n)\nax1.plot(\n    x_data,\n    y_pred_global,\n    \"r-\",\n    linewidth=2,\n    label=f\"workflow='auto_global' (SSR={ssr_global:.2f})\",\n)\nax1.set_xlabel(\"x\")\nax1.set_ylabel(\"y\")\nax1.set_title(\"Local vs Global Optimization Comparison\")\nax1.legend()\nax2 = axes[1]\nresiduals_single = y_data - y_pred_single\nresiduals_global = y_data - y_pred_global\nax2.scatter(\n    x_data, residuals_single, alpha=0.5, s=15, label=\"workflow='auto'\", color=\"blue\"\n)\nax2.scatter(\n    x_data,\n    residuals_global,\n    alpha=0.5,\n    s=15,\n    label=\"workflow='auto_global'\",\n    color=\"red\",\n)\nax2.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.5)\nax2.set_xlabel(\"x\")\nax2.set_ylabel(\"Residual\")\nax2.set_title(\"Residuals Comparison\")\nax2.legend()\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"01_comparison.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '01_comparison.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Loss landscape visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint(\"5. Generating loss landscape visualization...\")\nb_range = np.linspace(0.5, 3.0, 50)\nc_range = np.linspace(-np.pi, np.pi, 50)\nB, C = np.meshgrid(b_range, c_range)\nloss_landscape = np.zeros_like(B)\nfor i in range(len(c_range)):\n    for j in range(len(b_range)):\n        y_pred = true_a * np.sin(B[i, j] * x_data + C[i, j]) + true_d\n        loss_landscape[i, j] = np.sum((y_data - y_pred) ** 2)\nloss_log = np.log10(loss_landscape + 1)\nfig, ax = plt.subplots(figsize=(10, 8))\ncontour = ax.contourf(B, C, loss_log, levels=30, cmap=\"viridis\")\nplt.colorbar(contour, ax=ax, label=\"log10(SSR + 1)\")\nax.scatter(\n    [true_b],\n    [true_c],\n    color=\"white\",\n    marker=\"*\",\n    s=200,\n    label=\"True parameters\",\n    edgecolors=\"black\",\n    linewidths=1,\n)\nax.scatter(\n    [popt_single[1]],\n    [popt_single[2]],\n    color=\"blue\",\n    marker=\"o\",\n    s=100,\n    label=\"workflow='auto'\",\n    edgecolors=\"white\",\n    linewidths=1,\n)\nax.scatter(\n    [popt_global[1]],\n    [popt_global[2]],\n    color=\"red\",\n    marker=\"s\",\n    s=100,\n    label=\"workflow='auto_global'\",\n    edgecolors=\"white\",\n    linewidths=1,\n)\nax.set_xlabel(\"b (frequency)\")\nax.set_ylabel(\"c (phase)\")\nax.set_title(\n    \"Loss Landscape (a, d fixed at true values)\\nMultiple local minima visible\"\n)\nax.legend(loc=\"upper right\")\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"01_loss_landscape.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '01_loss_landscape.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Starting point distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print()\nprint(\"6. Generating starting point distribution visualization...\")\nn_samples_viz = 20\nn_params = 4\nkey = jax.random.PRNGKey(42)\nlhs_samples = latin_hypercube_sample(n_samples_viz, n_params, rng_key=key)\nlb = np.array([0.5, 0.5, -np.pi, -2.0])\nub = np.array([5.0, 3.0, np.pi, 5.0])\nscaled_samples = scale_samples_to_bounds(lhs_samples, lb, ub)\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nax1 = axes[0]\ncontour = ax1.contourf(B, C, loss_log, levels=30, cmap=\"viridis\", alpha=0.7)\nax1.scatter(\n    scaled_samples[:, 1],\n    scaled_samples[:, 2],\n    color=\"yellow\",\n    marker=\"o\",\n    s=80,\n    label=\"LHS starting points\",\n    edgecolors=\"black\",\n    linewidths=1,\n)\nax1.scatter(\n    [true_b],\n    [true_c],\n    color=\"white\",\n    marker=\"*\",\n    s=200,\n    label=\"True parameters\",\n    edgecolors=\"black\",\n    linewidths=1,\n)\nax1.set_xlabel(\"b (frequency)\")\nax1.set_ylabel(\"c (phase)\")\nax1.set_title(\"LHS Starting Points on Loss Landscape\")\nax1.legend()\nax2 = axes[1]\nparam_names = [\"a\", \"b\", \"c\", \"d\"]\ncolors = plt.cm.tab10(np.linspace(0, 1, 6))\nplot_idx = 0\nfor i in range(n_params):\n    for j in range(i + 1, n_params):\n        ax2.scatter(\n            scaled_samples[:, i],\n            scaled_samples[:, j],\n            alpha=0.6,\n            s=30,\n            color=colors[plot_idx],\n            label=f\"{param_names[i]} vs {param_names[j]}\",\n        )\n        plot_idx += 1\nax2.set_xlabel(\"Parameter value (normalized)\")\nax2.set_ylabel(\"Parameter value (normalized)\")\nax2.set_title(\"LHS Coverage: All 2D Projections\")\nax2.legend(loc=\"upper right\", fontsize=8)\nplt.tight_layout()\nplt.savefig(FIG_DIR / \"01_starting_points.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(f\"  Saved: {FIG_DIR / '01_starting_points.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    print()\n    print(\"=\" * 70)\n    print(\"Summary - The Three Workflows (v0.6.3)\")\n    print(\"=\" * 70)\n    print()\n    print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}, d={true_d}\")\n    print()\n    print(\"workflow='auto' (local optimization):\")\n    print(\n        f\"  Parameters: a={popt_single[0]:.3f}, b={popt_single[1]:.3f}, \"\n        f\"c={popt_single[2]:.3f}, d={popt_single[3]:.3f}\"\n    )\n    print(f\"  SSR: {ssr_single:.4f}\")\n    print()\n    print(\"workflow='auto_global' (global optimization, 10 starts):\")\n    print(\n        f\"  Parameters: a={popt_global[0]:.3f}, b={popt_global[1]:.3f}, \"\n        f\"c={popt_global[2]:.3f}, d={popt_global[3]:.3f}\"\n    )\n    print(f\"  SSR: {ssr_global:.4f}\")\n    print()\n    print(\"Key takeaways:\")\n    print(\"  - workflow='auto': Local optimization, good when you have a good guess\")\n    print(\"  - workflow='auto_global': Global optimization for multi-modal problems\")\n    print(\"  - workflow='hpc': auto_global + checkpointing for long HPC jobs\")\n    print()\n    print(\"Global method auto-selection (auto_global):\")\n    print(\"  - Multi-Start: Default, explores multiple starting points\")\n    print(\"  - CMA-ES: Selected when scale_ratio > 1000 AND evosax available\")\nif __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
