{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beba09cb",
   "metadata": {},
   "source": [
    "# Example 1: Basic Fault Tolerance with Streaming Optimizer\n",
    "\n",
    "This example demonstrates the basic usage of the streaming optimizer with\n",
    "fault tolerance enabled (default behavior).\n",
    "\n",
    "Features demonstrated:\n",
    "- Automatic best parameter tracking\n",
    "- NaN/Inf detection at three validation points\n",
    "- Adaptive retry strategies for failed batches\n",
    "- Success rate validation\n",
    "- Detailed diagnostics\n",
    "\n",
    "Run this example:\n",
    "    python examples/streaming/01_basic_fault_tolerance.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f632d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:53:20.973774Z",
     "iopub.status.busy": "2025-11-17T22:53:20.973548Z",
     "iopub.status.idle": "2025-11-17T22:53:24.339451Z",
     "shell.execute_reply": "2025-11-17T22:53:24.339067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-11-17 16:53:23,458:jax._src.xla_bridge:808: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting streaming optimization with batch_size=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Adam optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Streaming Optimizer: Basic Fault Tolerance Example\n",
      "======================================================================\n",
      "\n",
      "Dataset: 10000 samples\n",
      "True parameters: a=2.5, b=0.3\n",
      "\n",
      "Configuration:\n",
      "  Batch size: 100\n",
      "  Max epochs: 10\n",
      "  Learning rate: 0.001\n",
      "  Fault tolerance: True\n",
      "  Validate numerics: True\n",
      "  Min success rate: 50%\n",
      "  Max retries per batch: 2\n",
      "\n",
      "Initial guess: a=1.0, b=0.1\n",
      "\n",
      "Starting optimization...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete: avg_loss=0.002516, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup complete. Batch padding enabled (max_shape=100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete: avg_loss=0.002582, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete: avg_loss=0.002499, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete: avg_loss=0.002369, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete: avg_loss=0.002233, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete: avg_loss=0.002101, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete: avg_loss=0.001974, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete: avg_loss=0.001853, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete: avg_loss=0.001736, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete: avg_loss=0.001626, samples=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization complete: 1000/1000 batches succeeded (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "RESULTS\n",
      "======================================================================\n",
      "Success: True\n",
      "Message: Optimization complete: 1000/1000 batches succeeded (100.0%)\n",
      "\n",
      "Best parameters found:\n",
      "  a = 1.189291 (true: 2.5)\n",
      "  b = 0.134749 (true: 0.3)\n",
      "  Best loss = 7.611412e-03\n",
      "\n",
      "DIAGNOSTICS\n",
      "======================================================================\n",
      "Batch success rate: 100.0%\n",
      "Total batches attempted: 1000\n",
      "Total retries: 0\n",
      "Convergence achieved: False\n",
      "Final epoch: 9\n",
      "Elapsed time: 0.56s\n",
      "\n",
      "Aggregate Statistics (from batch buffer):\n",
      "  Mean loss: 1.625896e-01\n",
      "  Std loss: 3.034042e-01\n",
      "  Mean gradient norm: 0.948855\n",
      "  Mean batch time: 0.44ms\n",
      "\n",
      "Recent batch statistics (last 100 batches):\n",
      "  Batch 95: SUCCESS, loss=1.803398e-02\n",
      "  Batch 96: SUCCESS, loss=1.725470e-02\n",
      "  Batch 97: SUCCESS, loss=1.732153e-02\n",
      "  Batch 98: SUCCESS, loss=1.525652e-02\n",
      "  Batch 99: SUCCESS, loss=1.644096e-02\n",
      "\n",
      "Checkpoint Information:\n",
      "  Path: checkpoints/checkpoint_iter_1000.h5\n",
      "  Saved at: 2025-11-17T16:53:24.335012\n",
      "  Batch index: 99\n",
      "\n",
      "======================================================================\n",
      "Example complete!\n",
      "\n",
      "Key takeaways:\n",
      "  - Fault tolerance enabled by default (no configuration needed)\n",
      "  - Best parameters always returned (never initial p0)\n",
      "  - NaN/Inf detection at three validation points\n",
      "  - Adaptive retry strategies for failed batches\n",
      "  - Comprehensive diagnostics for analysis\n",
      "  - Checkpoints saved automatically for recovery\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import StreamingConfig, StreamingOptimizer\n",
    "\n",
    "\n",
    "def exponential_decay(x, a, b):\n",
    "    \"\"\"Exponential decay model: y = a * exp(-b * x)\"\"\"\n",
    "    return a * jnp.exp(-b * x)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Streaming Optimizer: Basic Fault Tolerance Example\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Generate synthetic data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    x_data = np.linspace(0, 10, n_samples)\n",
    "    true_a, true_b = 2.5, 0.3\n",
    "    y_true = exponential_decay(x_data, true_a, true_b)\n",
    "    y_data = y_true + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "    print(f\"Dataset: {n_samples} samples\")\n",
    "    print(f\"True parameters: a={true_a}, b={true_b}\")\n",
    "    print()\n",
    "\n",
    "    # Configure optimizer with fault tolerance (default)\n",
    "    config = StreamingConfig(\n",
    "        batch_size=100,\n",
    "        max_epochs=10,\n",
    "        learning_rate=0.001,\n",
    "        # Fault tolerance settings (all defaults)\n",
    "        enable_fault_tolerance=True,  # Enable fault tolerance features\n",
    "        validate_numerics=True,  # Check for NaN/Inf\n",
    "        min_success_rate=0.5,  # Require 50% batch success\n",
    "        max_retries_per_batch=2,  # Max 2 retry attempts\n",
    "        # Checkpoint settings\n",
    "        checkpoint_dir=\"checkpoints\",\n",
    "        checkpoint_frequency=100,  # Save every 100 iterations\n",
    "        enable_checkpoints=True,\n",
    "    )\n",
    "\n",
    "    print(\"Configuration:\")\n",
    "    print(f\"  Batch size: {config.batch_size}\")\n",
    "    print(f\"  Max epochs: {config.max_epochs}\")\n",
    "    print(f\"  Learning rate: {config.learning_rate}\")\n",
    "    print(f\"  Fault tolerance: {config.enable_fault_tolerance}\")\n",
    "    print(f\"  Validate numerics: {config.validate_numerics}\")\n",
    "    print(f\"  Min success rate: {config.min_success_rate:.0%}\")\n",
    "    print(f\"  Max retries per batch: {config.max_retries_per_batch}\")\n",
    "    print()\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = StreamingOptimizer(config)\n",
    "\n",
    "    # Initial guess (deliberately poor to show convergence)\n",
    "    p0 = np.array([1.0, 0.1])\n",
    "    print(f\"Initial guess: a={p0[0]}, b={p0[1]}\")\n",
    "    print()\n",
    "\n",
    "    # Fit with automatic error handling\n",
    "    print(\"Starting optimization...\")\n",
    "    print(\"-\" * 70)\n",
    "    result = optimizer.fit(\n",
    "        (x_data, y_data),  # Data as tuple\n",
    "        exponential_decay,  # Model function\n",
    "        p0,  # Initial parameters\n",
    "        verbose=1,  # Show progress\n",
    "    )\n",
    "    print(\"-\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Extract results\n",
    "    best_params = result[\"x\"]\n",
    "    success = result[\"success\"]\n",
    "    message = result[\"message\"]\n",
    "    best_loss = result[\"best_loss\"]\n",
    "    diagnostics = result[\"streaming_diagnostics\"]\n",
    "\n",
    "    # Display results\n",
    "    print(\"RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Success: {success}\")\n",
    "    print(f\"Message: {message}\")\n",
    "    print()\n",
    "    print(\"Best parameters found:\")\n",
    "    print(f\"  a = {best_params[0]:.6f} (true: {true_a})\")\n",
    "    print(f\"  b = {best_params[1]:.6f} (true: {true_b})\")\n",
    "    print(f\"  Best loss = {best_loss:.6e}\")\n",
    "    print()\n",
    "\n",
    "    # Display diagnostics\n",
    "    print(\"DIAGNOSTICS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Batch success rate: {diagnostics['batch_success_rate']:.1%}\")\n",
    "    print(f\"Total batches attempted: {diagnostics['total_batches_attempted']}\")\n",
    "    print(f\"Total retries: {diagnostics['total_retries']}\")\n",
    "    print(f\"Convergence achieved: {diagnostics['convergence_achieved']}\")\n",
    "    print(f\"Final epoch: {diagnostics['final_epoch']}\")\n",
    "    print(f\"Elapsed time: {diagnostics['elapsed_time']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "    # Failed batches (if any)\n",
    "    if diagnostics[\"failed_batches\"]:\n",
    "        print(f\"Failed batches ({len(diagnostics['failed_batches'])}):\")\n",
    "        print(f\"  Indices: {diagnostics['failed_batches']}\")\n",
    "        print(f\"  Error types: {diagnostics['error_types']}\")\n",
    "        print()\n",
    "\n",
    "    # Aggregate statistics\n",
    "    agg = diagnostics[\"aggregate_stats\"]\n",
    "    print(\"Aggregate Statistics (from batch buffer):\")\n",
    "    print(f\"  Mean loss: {agg['mean_loss']:.6e}\")\n",
    "    print(f\"  Std loss: {agg['std_loss']:.6e}\")\n",
    "    print(f\"  Mean gradient norm: {agg['mean_grad_norm']:.6f}\")\n",
    "    print(f\"  Mean batch time: {agg['mean_batch_time'] * 1000:.2f}ms\")\n",
    "    print()\n",
    "\n",
    "    # Recent batch statistics\n",
    "    recent_stats = diagnostics[\"recent_batch_stats\"]\n",
    "    if recent_stats:\n",
    "        print(f\"Recent batch statistics (last {len(recent_stats)} batches):\")\n",
    "        # Show last 5 batches\n",
    "        for i, stats in enumerate(recent_stats[-5:], 1):\n",
    "            status = \"SUCCESS\" if stats[\"success\"] else \"FAILED\"\n",
    "            retry_info = (\n",
    "                f\" (retries: {stats['retry_count']})\"\n",
    "                if stats[\"retry_count\"] > 0\n",
    "                else \"\"\n",
    "            )\n",
    "            print(\n",
    "                f\"  Batch {stats['batch_idx']}: {status}, loss={stats['loss']:.6e}{retry_info}\"\n",
    "            )\n",
    "        print()\n",
    "\n",
    "    # Checkpoint information\n",
    "    if diagnostics[\"checkpoint_info\"]:\n",
    "        cp = diagnostics[\"checkpoint_info\"]\n",
    "        print(\"Checkpoint Information:\")\n",
    "        print(f\"  Path: {cp['path']}\")\n",
    "        print(f\"  Saved at: {cp['saved_at']}\")\n",
    "        print(f\"  Batch index: {cp['batch_idx']}\")\n",
    "        print()\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Example complete!\")\n",
    "    print()\n",
    "    print(\"Key takeaways:\")\n",
    "    print(\"  - Fault tolerance enabled by default (no configuration needed)\")\n",
    "    print(\"  - Best parameters always returned (never initial p0)\")\n",
    "    print(\"  - NaN/Inf detection at three validation points\")\n",
    "    print(\"  - Adaptive retry strategies for failed batches\")\n",
    "    print(\"  - Comprehensive diagnostics for analysis\")\n",
    "    print(\"  - Checkpoints saved automatically for recovery\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
